{"componentChunkName":"component---src-templates-tag-tsx","path":"/tags/운영체제-스터디/","result":{"pageContext":{"posts":[{"excerpt":"디스크와 RAID 디스크(HDD)와 구성요소 Sector - 트랙 내에서 데이터 판독의 물리적 단위 (512 Byte) Track -  Platter에서 같은 거리만큼 떨어진 섹터 집합 Cylinder - 같은 반지름을 갖는 트랙의 집합 Platter - 데이터를 기록할 수 있는 자성물질로 이뤄진 원형 금속판 Surface - Platter의 윗면,아랫면 디스크 드라이브는, 디스크 축을 회전시키며 Positioner  암을 위치시켜,  Head…","html":"<h1 id=\"디스크와-raid\" style=\"position:relative;\"><a href=\"#%EB%94%94%EC%8A%A4%ED%81%AC%EC%99%80-raid\" aria-label=\"디스크와 raid permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>디스크와 RAID</h1>\n<p><strong>디스크(HDD)와 구성요소</strong></p>\n<p>Sector - 트랙 내에서 데이터 판독의 물리적 단위 (512 Byte)</p>\n<p>Track -  Platter에서 같은 거리만큼 떨어진 섹터 집합</p>\n<p>Cylinder - 같은 반지름을 갖는 트랙의 집합</p>\n<p>Platter - 데이터를 기록할 수 있는 자성물질로 이뤄진 원형 금속판</p>\n<p>Surface - Platter의 윗면,아랫면</p>\n<p>디스크 드라이브는, 디스크 축을 회전시키며 <strong>Positioner</strong>  <strong>암</strong>을 위치시켜,  <strong>Head</strong>가 데이터를 기록하고 읽는다.</p>\n<h3 id=\"raid-redundant-arrays-of-inexpensice-disks\" style=\"position:relative;\"><a href=\"#raid-redundant-arrays-of-inexpensice-disks\" aria-label=\"raid redundant arrays of inexpensice disks permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>RAID: <strong>Redundant Arrays of Inexpensice Disks</strong></h3>\n<p>직역하면 저성능 디스크의 중복 배열입니다. 여러 개의 디스크를 묶어 대용량으로 사용한다는 의미이며,운영체제와 RAID Controller의 제어를 받습니다.  RAID버전에 따라 안정성과 성능(Access Speed)을 고려해 설계되었습니다.</p>\n<p>운영체제제가 제어하는 개념이므로, Block 단위로 데이터를 다룹니다.  또한, 디스크의 입/출력에 대한 부하가 균등하게 분배되어야 하고, 이를 통해 성능을 향상시킬 수 있습니다.\n일부 버전에서는 데이터를 중복 저장하거나 Parity로 손실을 체크하는 등, 신뢰성을 보장하기 위한 기능도 가지고 있습니다.</p>\n<p><strong>RAID 0</strong></p>\n<p><strong>Disk Striping</strong>: 데이터를 블록 단위로 분할해 각 디스크에 저장합니다.</p>\n<table>\n<thead>\n<tr>\n<th>Disk A</th>\n<th>Disk B</th>\n<th>Disk C</th>\n<th>Disk D</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>X</td>\n<td>Y</td>\n<td>Z</td>\n<td>I</td>\n</tr>\n<tr>\n<td>J</td>\n<td>K</td>\n<td>L</td>\n<td>M</td>\n</tr>\n<tr>\n<td>O</td>\n<td>P</td>\n<td>Q</td>\n<td>R</td>\n</tr>\n</tbody>\n</table>\n<p><strong>성능 측면에서</strong>, 하나의 Stripe( X, Y ,Z, I)를 한번에 접근 할 수 있으므로(병렬 접근), 매우 좋다고 할 수 있습니다.</p>\n<ul>\n<li>그러나 (X, J, O )접근같이 최악의 경우에는 병렬성이 보장되지 아예 않습니다. ( 일반적인 경우는 아님 )</li>\n</ul>\n<p><strong>안정성 측면에서는,</strong> 데이터를 중복해 저장하지 않기 때문에, 안정성이 떨어집니다. 하나의 디스크에서 장애가 발생할 경우, 데이터 손실이 발생합니다.</p>\n<p><strong>RAID1</strong></p>\n<p><strong>Mirroring</strong>:  동일한 데이터를 미러링 디스크에 동시 저장!</p>\n<table>\n<thead>\n<tr>\n<th>Disk A</th>\n<th>Disk B</th>\n<th>Disk C</th>\n<th>Disk D</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>X</td>\n<td>X</td>\n<td>Y</td>\n<td>Y</td>\n</tr>\n<tr>\n<td>Z</td>\n<td>Z</td>\n<td>I</td>\n<td>I</td>\n</tr>\n<tr>\n<td>J</td>\n<td>J</td>\n<td>K</td>\n<td>K</td>\n</tr>\n</tbody>\n</table>\n<p>RAID1은 하나의 데이터를 두 개 이상의 디스크에 중복으로 저장해 안정성을 향상시킨 방법입니다.</p>\n<p><strong>안정성 측면</strong>에서 하나(또는 이상)의 디스크에 장애가 생겨도, 다른 디스크에서 데이터를 가져올 수 있습니다.\n그러나 디스크 저장 가능 용량이 줄어든다는 단점이 있습니다.</p>\n<p><strong>성능 측면</strong>에서 단일 ****읽기/쓰기 작업은 RAID0과 큰 차이를 보이지 않습니다. 그러나 연속 읽기/쓰기 작업에서는 데이터 버스의 대역폭 관점에서 병목이 발생해, RAID0과 비교해 성능 저하가 발생합니다. 최대 대역폭의 (1 /N )만큼 제공</p>\n<p><strong>RAID3</strong></p>\n<p><strong>RAID 0 + Parity Bit:</strong> Striping에 대한 Parity를 저장.</p>\n<table>\n<thead>\n<tr>\n<th>Disk A</th>\n<th>Disk B</th>\n<th>Disk C</th>\n<th>Disk D</th>\n<th>Parity Disk</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>X</td>\n<td>Y</td>\n<td>Z</td>\n<td>I</td>\n<td>P1</td>\n</tr>\n<tr>\n<td>J</td>\n<td>K</td>\n<td>L</td>\n<td>M</td>\n<td>P2</td>\n</tr>\n<tr>\n<td>O</td>\n<td>P</td>\n<td>Q</td>\n<td>R</td>\n<td>P3</td>\n</tr>\n</tbody>\n</table>\n<p>RAID1에서는 안정성을 위해 디스크 용량을 너무 많이 차지한다는 단점이 있었습니다.\n이에 Parity Bit를 통한 복구 알고리즘을 적용해, 데이터 복구에 필요한 저장공간을 줄였습니다.</p>\n<p>또한 성능 측면에서도 RAID0과 같은 Striping 방법을 사용하므로, 병렬 처리가 가능해 우수한 성능을 보입니다.</p>\n<p>그러나 대량의 쓰기 작업 시 Parity 계산으로 인한 병목이 발생할 수 있습니다.</p>\n<p><strong>RAID3은 Byte 단위,  RAID4에서는 Block 단위로 데이터 및 패리티를 저장한다는 차이가 있습니다.</strong></p>\n<p>RAID4에서는 읽기 작업 수행 시 더 적은 I/O횟수로 데이터를 읽어올 수 있지만, 필요하지 않은 데이터를 가져올 수 도 있다는 단점이 있습니다.</p>\n<p><strong>RAID 5 (현재 자주 사용되는 버전)</strong></p>\n<p>RAID3,4에서는 Parity Disk하나가 고장나면, 손실 측정을 할 수 없는 <strong>가용성 문제</strong>가 있었습니다.\nRAID5에서는 데이터를 저장하는 디스크에 <strong>Parity정보를 분산 저장</strong>해, 안정성을 높혔습니다.</p>\n<p><strong>부하 분산측면</strong>에서도, Write가 많은 시스템의 경우, RAID3,4같이 Parity Disk를 따로 두게되면, 해당 디스크에 부하가 집중되는 문제점이 있습니다.</p>\n<table>\n<thead>\n<tr>\n<th>Disk A</th>\n<th>Disk B</th>\n<th>Disk C</th>\n<th>Disk D</th>\n<th>Disk E</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>X</td>\n<td>Y</td>\n<td>Z</td>\n<td>I</td>\n<td><strong>P1</strong></td>\n</tr>\n<tr>\n<td>J</td>\n<td>K</td>\n<td>L</td>\n<td><strong>P2</strong></td>\n<td>M</td>\n</tr>\n<tr>\n<td>O</td>\n<td>P</td>\n<td><strong>P3</strong></td>\n<td>Q</td>\n<td>R</td>\n</tr>\n<tr>\n<td>S</td>\n<td><strong>P4</strong></td>\n<td>T</td>\n<td>U</td>\n<td>V</td>\n</tr>\n<tr>\n<td><strong>P5</strong></td>\n<td>A</td>\n<td>B</td>\n<td>C</td>\n<td>D</td>\n</tr>\n</tbody>\n</table>\n<p><strong>RAID6</strong></p>\n<p>RAID6는 RAID5와 같지만, 패리티 정보를 이중으로 저장합니다.</p>\n<p>이를 통해 RAID5보다 데이터 안정적으로 데이터를 보존할 수 있습니다.</p>\n<table>\n<thead>\n<tr>\n<th>Disk A</th>\n<th>Disk B</th>\n<th>Disk C</th>\n<th>Disk D</th>\n<th>Disk E</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>X</td>\n<td>Y</td>\n<td>Z</td>\n<td><strong>P1</strong></td>\n<td><strong>P1</strong></td>\n</tr>\n<tr>\n<td>I</td>\n<td>J</td>\n<td><strong>P2</strong></td>\n<td><strong>P2</strong></td>\n<td>K</td>\n</tr>\n<tr>\n<td>L</td>\n<td><strong>P3</strong></td>\n<td><strong>P3</strong></td>\n<td>M</td>\n<td>N</td>\n</tr>\n<tr>\n<td><strong>P4</strong></td>\n<td><strong>P4</strong></td>\n<td>O</td>\n<td>P</td>\n<td>Q</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>Parity disk가 “실질적으로” 어떻게 데이터를 복구할까…??</p>\n</blockquote>\n<p><strong>XOR Parity 의 경우…</strong></p>\n<ul>\n<li>만약,  디스크가 각각 0 , 1, 1 ,0데이터를 가지고있다고 하자</li>\n<li>패리티 비트는 이 모든 값에 XOR을 취한 값 (((0^1)^1)^0) = 0</li>\n<li>마지막 디스크가 파손되어, 0 값이 사라졌다!</li>\n<li>파손된 디스크를 제외하고 패리티 비트까지 XOR을 수행하면 원래의 값이 복구된다.\n<ul>\n<li>((0^1)^1)^0 = 0</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"nested-raid\" style=\"position:relative;\"><a href=\"#nested-raid\" aria-label=\"nested raid permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Nested RAID</h2>\n<p>RAID는 중첩해서 사용할 수 있습니다.\n주로 안정성을 지원하는 RAID와 Striping을 지원하는 RAID( 보통은 RAID 0)를 통해 중첩합니다.</p>\n<p>아래에서는 RAID 0+1, RAID 1+0에 대해 다루지만, 5+0, 6+0, 심지어 1+0+0 등, 안정성과 성능 요구사항에 따라 다양하게 구성할 수 있습니다.</p>\n<p><img src=\"%E1%84%83%E1%85%B5%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%8B%E1%85%AA%20RAID%20c738ef37d2b74244957a62749b73b1e3/360px-RAID_01.svg.png\" alt=\"./360px-RAID_01.svg.png\"></p>\n<p><img src=\"%E1%84%83%E1%85%B5%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%8B%E1%85%AA%20RAID%20c738ef37d2b74244957a62749b73b1e3/440px-RAID_10_01.svg.png\" alt=\"440px-RAID_10_01.svg.png\"></p>\n<p>이미지 출처: <a href=\"https://en.wikipedia.org/wiki/Nested_RAID_levels\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://en.wikipedia.org/wiki/Nested_RAID_levels</a></p>\n<p>RAID 0+1, 1+0 두 가지 방법 모두 안정성과 병렬접근 성능을 기반으로 설계된 중복 RAID 방법입니다.</p>\n<p>RAID0+1은 이름에서 알 수 있듯, [ Striping + Mirroring ], 1+0은 [ Mirroring + Striping ] 입니다.</p>\n<p>간단히 보기에는 두 방법이 차이가 없는것 같지만, 성능이나 안정성 측면에서 차이가 존재합니다.</p>\n<p>그 전에, 그림에서 오해할 수 있는 부분이 있어 설명합니다.\nNested RAID에서는 디스크 데이터가 많아질수록 RAID 0이 다중화됩니다.\n이를 참고해, Striping대상이 2개 이상일 경우를 상상해야 둘의 차이를 이해할 수 있습니다.</p>\n<p>RAID 0+1 에서는 Striping 해야하는 데이터가 많아질수록, 가용성 측면에서 단점을 보입니다.</p>\n<p>2개의 미러링 디스크 그룹이 있다고 할 때, 각각의 디스크 그룹에서 하나씩의 손실만 발생해도 Striping을 통해 데이터를 가져오지 못하는 장애가 발생합니다.</p>\n<p>반면 RAID 1 + 0에서는 , 하나의 Mirroring 디스크 그룹에서 모두 손실이 발생하지 않는 한, 여러 Striping 그룹에서 손실이 발생하더라도, 각각의 Mirror 디스크에서 데이터를 가져올 수 있으므로, 안정성이 더 뛰어납니다.</p>\n<p>이런 이유로, 얼핏 비슷해보이는 RAID 0+1과 1+0이지만, 1+0이 실제로 더 자주 사용되는 RAID 구성 방법입니다. RAID 5+0, 6+0 등 다른 RAID를 설계할 때도, 성능/안정성/복구 측면에서 고려해 다양하게 설계할 수 있습니다.</p>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p><a href=\"%5Bhttps://pages.cs.wisc.edu/~remzi/OSTEP/%5D(https://pages.cs.wisc.edu/~remzi/OSTEP/)\">OSTEP: Operating Systems: Three Easy Pieces</a></p>\n<p>[<strong>HPC Lab. KOREATECH, OS Lecture]<a href=\"https://www.youtube.com/watch?v=r1JVA7yOPAM&#x26;\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">(</a></strong><a href=\"https://www.youtube.com/playlist?list=PLBrGAFAIyf5rby7QylRc6JxU5lzQ9c4tN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.youtube.com/watch?v=es3WGii_7mc&#x26;list=PLBrGAFAIyf5rby7QylRc6JxU5lzQ9c4tN</a><strong>)</strong></p>\n<p><a href=\"https://en.wikipedia.org/wiki/Standard_RAID_levels\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://en.wikipedia.org/wiki/Standard_RAID_levels</a></p>\n<p><a href=\"https://en.wikipedia.org/wiki/Nested_RAID_levels\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://en.wikipedia.org/wiki/Nested_RAID_levels</a></p>","id":"5dfa2596-8a5c-56c2-9bef-b35e58e3f4ef","fields":{"slug":"운영체제-디스크와-raid"},"frontmatter":{"date":"2024-10-14","title":"[운영체제] 디스크와 RAID","category":"tech","tags":["운영체제","운영체제 스터디"],"banner":null},"timeToRead":4},{"excerpt":"데드락이란? 할당받을 수 없는 자원을 요청해 더이상 실행할 수 없는 상태 프로세스 A,B는 리스소 X,Y를 가지고있어야 진행이 가능합니다. 하지만 A,B가 각각 Y,X를 점유하고 X,Y를 요청한다면, 영원히 X,Y를 동시에 획득하지 못하는 상황이 발생합니다. DeadLock drawio 운영체제에는 다양한 자원을 복잡한 방법으로 할당받아 사용하기에, 위와 같은 경우라고 해서 무조건 데드락이 발생하지는 않고, E.G 코프만 교수가 아래…","html":"<p><strong>데드락이란?</strong></p>\n<p>할당받을 수 없는 자원을 요청해 더이상 실행할 수 없는 상태</p>\n<p>프로세스 A,B는 리스소 X,Y를 가지고있어야 진행이 가능합니다. 하지만 A,B가 각각 Y,X를 점유하고 X,Y를 요청한다면, 영원히 X,Y를 동시에 획득하지 못하는 상황이 발생합니다.</p>\n<p><img src=\"https://github.com/lee95292/lee95292.github.io/assets/30853787/c99a815a-150e-4ba7-b500-9f8be5e5c88d\" alt=\"DeadLock drawio\"></p>\n<p>운영체제에는 다양한 자원을 복잡한 방법으로 할당받아 사용하기에, 위와 같은 경우라고 해서 무조건 데드락이 발생하지는 않고, E.G 코프만 교수가 아래 <strong>4가지 조건이 모두 충족</strong>되어야만 데드락이 발생함을 보였습니다.</p>\n<ol>\n<li>상호배제. Mutual Exclusion: 두 개의 프로세스가 필요로 하는 자원을 배타적으로 점유해야 한다.</li>\n<li>비선점. Non Preemption: 프로세스의 실행중, 다른 프로세스가 자원의 점유를 빼앗을 수 없다.</li>\n<li>점유 대기. Hold and Wait: 할당된 자원을 가진 상태로 다른 자원을 기다린다.</li>\n<li>환형 대기. Circular Wait: 여러 프로세스가 순환적으로 자원 할당을 기다린다.</li>\n</ol>\n<p><strong>데드락 예방 방법</strong></p>\n<p>그러므로, 데드락을 <strong>예방</strong>하는 방법은 위 네 가지중 한가지를 부정해주면 됩니다.</p>\n<ol>\n<li>상호배제조건 제거: 자원을 배타적으로 점유하는 조건을 제거, 자원 공유\n<ol>\n<li>락을 사용하지 않았을 때의 문제점이 그대로 발생한다.</li>\n</ol>\n</li>\n<li>비선점 조건 제거: 자원의 할당을 선점해올 수 있도록 방법 제공\n<ol>\n<li>구현이 매우 복잡해지며, 성능 오버헤드가 발생한다.</li>\n</ol>\n</li>\n<li>점유대기 제거: 프로세스의 시작시점에 필요한 모든 자원을 요청한다\n<ol>\n<li>사용하지 않는 자원을 점유하고있는 비용과, 기아상태로 인한 무한대기가 발생한다.</li>\n</ol>\n</li>\n<li>환형대기 제거: 자원을 선형으로 분류해 순서를 매기고, 증가하는 순서로만 자원을 요청.  (TODO Check 필요)\n<ol>\n<li>가장 현실적인 방법. 이것마저도 꽤 큰 성능 오버헤드 발생</li>\n</ol>\n</li>\n</ol>\n<p><strong>데드락 회피 방법</strong></p>\n<p>또, 데드락은 <strong>회피방법이</strong> 존재합니다. 예방방법과 달리, 운영체제가 실행중에 동작하는 방법이기에 회피방법이라 부릅니다.</p>\n<p>교착상태가 발생할 수 있는 자원 할당을 피하고, 안전한 상태에서만 자원 할당을 하는 방법입니다.</p>\n<p>앞선 예방방법에서도 비용 및 성능 오버헤드로 인한 한계점을 보았듯, 회복 방법 역시 태생적 한계점이 존재합니다.</p>\n<ol>\n<li>운영체제가 프로세스의 최대 자원 할당 수를 알고있어야 하고,</li>\n<li>프로세스의 수가 고정되어야 합니다 ( Process Create X )</li>\n<li>자원의 종류와 숫자가 고정되어야 합니다.</li>\n</ol>\n<p><strong>Banker’s Algorithm</strong></p>\n<p>TODO<strong>안전하지 않은 순서에 대한 예제 체크, 예시 고치기</strong></p>\n<p>다익스트라가 제안한것으로 유명한 은행원 알고리즘은, 대표적인 데드락 회피 방법입니다.</p>\n<p>프로세스와 프로세스의 최대 할당 자원, 현재 할당 자원을 알고있을 때, 최대 할당자원을 넘어가지 않는 안전순서열을 만들어 자원을 할당하는 방법입니다.</p>\n<p>운영체제는 총 14개의 자원을 갖고있다고 가정하겠습니다.</p>\n<table>\n<thead>\n<tr>\n<th>Process</th>\n<th>최대 할당 자원 수</th>\n<th>현재 할당 자원 수</th>\n<th>필요한 자원 수</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>A</td>\n<td>12</td>\n<td>5</td>\n<td>7</td>\n</tr>\n<tr>\n<td>B</td>\n<td>5</td>\n<td>1</td>\n<td>4</td>\n</tr>\n<tr>\n<td>C</td>\n<td>5</td>\n<td>4</td>\n<td>1</td>\n</tr>\n</tbody>\n</table>\n<ol>\n<li>현재 할당된 자원 수는 12개입니다. 가용 자원 수는 4개입니다.</li>\n<li>C에 1개의 자원을 할당해 실핼시키고, C가 종료되어 5의 자원을 반환받습니다.</li>\n<li>현재 가용 자원 수는 8개입니다. (4 -1 + 5)</li>\n<li>B에 자원 4개를 할당해 실행시키고, B가 종료되어 5의 자원을 반환받습니다.</li>\n<li>현재 가용 자원 수는 9개입니다 ( 8 - 4 + 5)</li>\n<li>A에 7개의 자원을 할당하고, 모든 프로그램을 종료합니다.</li>\n</ol>\n<p>자원을 안전하게 분배할 수 있는 순서는 C → B → A가 유일합니다. (Safe Sequence)</p>\n<p>안전순서열로 보장된 실행순서로 프로세스를 실행하면 데드락을 회피할 수 있으며, 안전하지 않은 상태에서의 실행은 데드락이 발생할 수 있는 확률이 있음을 의미합니다.</p>\n<p>은행원 알고리즘은 하나의 종류의 자원이 여러개 필요하다고 가정하고 시작한다는 한계가 있습니다. 사용된다고 하더라도, 프로세스 스케줄링 루틴은 자주 일어나는 작업인데, 낮은 빈도로 발생하는 데드락을 위해 스케줄링 과정에 프로세스를 감시해야 하므로 높은 오버헤드가 존재합니다.</p>\n<p><strong>데드락 탐지 및 복구방법</strong></p>\n<p>데드락 탐지 및 복구방법은 운영체제가 실행중에 동작하는 방법인것은 회피방법과 같지만, 이 방법은 데드락이 발생 후 처리하는 방식이라는 차이점이 있습니다.</p>\n<p>먼저, 어떤 프로세스가 데드락 상태인지 판별하기 위해 Resourse Allocation Graph를 탐색해 데드락 상태인 프로세스를 탐지합니다. 이는 RAG의 자원 대기를 나타내는 그래프의 사이클을 판별하면 됩니다.</p>\n<p><img src=\"https://github.com/lee95292/lee95292.github.io/assets/30853787/9c9597e1-5c08-4225-a435-27f3e797cad0\" alt=\"2\"></p>\n<p><em>이미지 출처: <a href=\"https://velog.io/@jerry92/OS-%EA%B5%90%EC%B0%A9%EC%83%81%ED%83%9Cdeadlock%EC%9D%98-%EC%A1%B0%EA%B1%B4%EA%B3%BC-%ED%95%B4%EA%B2%B0-%EB%B0%A9%EB%B2%95\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://velog.io/@jerry92/OS-교착상태deadlock의-조건과-해결-방법</a></em></p>\n<p>사이클 내에 존재하는 프로세스는 아래 두 가지 방법중 하나로 데드락에서 탈출해야 합니다.</p>\n<ol>\n<li>\n<p>프로세스 중단: 사이클에 속하는 하나 이상 또는 전체 프로세스를 중단합니다. 전체 프로세스를 중단하는것은 대규모 작업이 될 수도 있고, 연관된 다른 프로세스까지 종료하게 된다면, 작업 손실이 발생할 수도 있습니다.</p>\n<p>이에 프로세스 age나 우선순위 등을 고려해 한개씩 삭제하는게 좋습니다.</p>\n</li>\n<li>\n<p>자원 선점: 교착상테에 놓인 자원을 선점할 때까지 프로세스의 자원을 다른 프로세스가 선점하도록 하므로써 데드락을 탈출합니다.</p>\n</li>\n</ol>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p><a href=\"%5Bhttps://pages.cs.wisc.edu/~remzi/OSTEP/%5D(https://pages.cs.wisc.edu/~remzi/OSTEP/)\">OSTEP: Operating Systems: Three Easy Pieces</a></p>\n<p>OSTEP: Operating Systems: Three Easy Pieces - <a href=\"https://pages.cs.wisc.edu/~remzi/OSTEP/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://pages.cs.wisc.edu/~remzi/OSTEP/</a></p>\n<p><a href=\"%5Bhttps://ko.wikipedia.org/wiki/%EA%B5%90%EC%B0%A9_%EC%83%81%ED%83%9C%5D(https://ko.wikipedia.org/wiki/%EA%B5%90%EC%B0%A9_%EC%83%81%ED%83%9C)\">Wikipedia, Deadlock</a></p>\n<p><a href=\"%5Bhttps://en.wikipedia.org/wiki/Deadlock%5D(https://en.wikipedia.org/wiki/Deadlock)\">Eng Wikipedia, Deadlock</a></p>","id":"d025e9b6-ba19-5963-9469-e8cf4cca48a4","fields":{"slug":"운영체제-데드락과-예방-회피-복구"},"frontmatter":{"date":"2023-04-16","title":"운영체제 데드락과 예방,회피,복구","category":"tech","tags":["운영체제","운영체제 스터디"],"banner":null},"timeToRead":2},{"excerpt":"이번 글에서는 앞서 공부한 세마포어를 바탕으로, 대표적으로 알려진 동시성 문제를 다룹니다. 세마포어에 대해서는 이전 글을 참고해주세요. Producer-Consumer Problem Reader-Writer Problem //Dinning Philosopher’s Problem Producer-Consumer 문제 배경지식: Ring Buffer 생산자 소비자 구조에서 자주 사용되는 Ring Buffer구조는 Circular Queue…","html":"<p>이번 글에서는 앞서 공부한 세마포어를 바탕으로, 대표적으로 알려진 동시성 문제를 다룹니다. 세마포어에 대해서는 이전 글을 참고해주세요.</p>\n<ul>\n<li>Producer-Consumer Problem</li>\n<li>Reader-Writer Problem</li>\n<li>//Dinning Philosopher’s Problem</li>\n</ul>\n<h2 id=\"producer-consumer-문제\" style=\"position:relative;\"><a href=\"#producer-consumer-%EB%AC%B8%EC%A0%9C\" aria-label=\"producer consumer 문제 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Producer-Consumer 문제</h2>\n<p><strong>배경지식: Ring Buffer</strong></p>\n<p>생산자 소비자 구조에서 자주 사용되는 Ring Buffer구조는 Circular Queue자료구조입니다. 이는 배열과 head, tail에 대한 포인터를 갖고, size변수를 통해 Ring buffer의 크기를 판별합니다.</p>\n<p>Modular연산을 통해 head, tail 포인터를 정의해 삽입/삭제 시 head/tail 포인터가 배열 범위 안에서 정의되도록 합니다.</p>\n<p><img src=\"https://github.com/lee95292/lee95292.github.io/assets/30853787/05f2b93f-4e6b-48bf-aebe-123595689104\" alt=\"Producer-Consumer drawio\"></p>\n<p>생상자-소비자 문제라고도 불립니다. 이는 컴퓨터와 프린터 관계로 보면 됩니다.</p>\n<p>문서를 등록하는 컴퓨터와 프린터는 여러개입니다.</p>\n<p>컴퓨터는 프린트해야하는 문서들을 작업 큐에 등록합니다(Produce)</p>\n<p>프린터는 작업 큐에 올라온 문서를 차례로 프린트합니다. (Consume)</p>\n<p>생산자-소비자 문제는 일반적인 공유변수에서의 동기화 문제와는 달리, 데이터의 삽입/인출부분이 정해져있다는 차이점이 있습니다.</p>\n<ul>\n<li>그렇기에, Producer가 데이터를 삽입할 때 Consumer가 데이터를 인출하는 작업은 경쟁상태가 발생하지 않습니다.(다른 위치이므로)</li>\n<li>하지만 데이터가 가득 찼거나, 텅 비었을 때는 head/tail 포인터의 위치가 같습니다. 이를 고려해야 합니다.</li>\n<li>여전히 Producer끼리, Consumer끼리는 상호배제가 지켜저야 합니다.</li>\n</ul>\n<p>이를 바탕으로 Consumer와 Producer 코드를 작성해보겠습니다.</p>\n<p><strong>세마포어 변수</strong></p>\n<p>MutexP [0,1]: Binary Semaphore로, 프로듀서간 공유자원 상호배제를 달성합니다.</p>\n<p>MutexC [0,1]: 마찬가지로, 컨슈머간 상호배제를 달성합니다.</p>\n<p>NEmpty  [0 ~ N] : 링버퍼가 비어있는지에 대한 세마포어입니다.  // P(NEmpty)비어있으면 Blocking</p>\n<p>NFull [N ~ 0]: 링버퍼가 가득 차있는지에 대한 세마포어입니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"c\"><pre class=\"language-c\"><code class=\"language-c\"><span class=\"token comment\">// Producer's Code</span>\n<span class=\"token comment\">// repeat this code</span>\n<span class=\"token function\">P</span><span class=\"token punctuation\">(</span>MutexP<span class=\"token punctuation\">)</span> <span class=\"token comment\">// 2개 이상의 Producer 접근 금지, Producer간 상호배제 달성</span>\n<span class=\"token function\">P</span><span class=\"token punctuation\">(</span>NFull<span class=\"token punctuation\">)</span>  <span class=\"token comment\">// 데이터가 가득 찬 경우, NFull==0이므로, Blocking</span>\n<span class=\"token punctuation\">[</span>Data Produce<span class=\"token punctuation\">]</span>\n<span class=\"token function\">V</span><span class=\"token punctuation\">(</span>NEmpty<span class=\"token punctuation\">)</span>\n<span class=\"token function\">V</span><span class=\"token punctuation\">(</span>MutexP<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"c\"><pre class=\"language-c\"><code class=\"language-c\"><span class=\"token comment\">// Consumer's Code</span>\n<span class=\"token comment\">// repeat this code</span>\n<span class=\"token function\">P</span><span class=\"token punctuation\">(</span>MutexC<span class=\"token punctuation\">)</span> <span class=\"token comment\">// 2개 이상의 Consumer 접근금지, Consumer간 상호배제 달성</span>\n<span class=\"token function\">P</span><span class=\"token punctuation\">(</span>NEmpty<span class=\"token punctuation\">)</span> <span class=\"token comment\">// 데이터가 없는 경우, NEmpty ==0이르모, Blocking</span>\n<span class=\"token punctuation\">[</span>Data Consume<span class=\"token punctuation\">]</span>\n<span class=\"token function\">V</span><span class=\"token punctuation\">(</span>NFull<span class=\"token punctuation\">)</span>\n<span class=\"token function\">V</span><span class=\"token punctuation\">(</span>MutexC<span class=\"token punctuation\">)</span></code></pre></div>\n<p>위 예시를 살펴보면, head,tail이 겹치는 부분에서 Producer와 Consumer의 실행이 동시에 일어나지 않습니다.</p>\n<ul>\n<li>링버퍼에 데이터가 가득 찬 경우 : Consumer만 접근 가능</li>\n<li>링버퍼가 텅 빈 경우: Producer만 접근 가능</li>\n</ul>\n<p>이는 underflow, overflow를 막기 위함도 있지만, 단순히 if문을 사용하지 않고 세마포어 변수를 통해 동시 실행을 제어했으므로, 경쟁상태가 발생하지 않습니다.</p>\n<p>(만약, 공유변수인 데이터 개수를 세마포어로 통제하지 않고, 데이터개수가 0일 때 발생하는 문제점을 생각해보면 좋습니다.)</p>\n<h2 id=\"reader-writer문제\" style=\"position:relative;\"><a href=\"#reader-writer%EB%AC%B8%EC%A0%9C\" aria-label=\"reader writer문제 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reader-Writer문제</h2>\n<p>Reader-Writer문제는 읽기만 담당하는 스레드와 쓰기만 담당하는 스레드가 나뉜 상황입니다. (이하 Reader, Writer)</p>\n<p>Reader-Reader관계에는 상호배제가 필요하지 않지만,  Writer-Writer또는 Reader-Writer간에는 상호배제가 필요합니다.</p>\n<p><strong>우선권 문제</strong></p>\n<p>만약, Reader가 끊임없이 생성되어 Writer 스레드가 작업할 수 없다면 어떻게될까요? 또는, Writer가 계속 생성되어 Reader가 생성되는 경우도 마찬가지입니다.  이에 Reader,Writer에 대해 우선순위를 주도록 구현할 수 있습니다.</p>\n<p><strong>Reader Preference Solution</strong></p>\n<p>Reader 스레드 수가 0일때만 Writer가 세마포어를 획득할 수 있음, Writer는 1개의 스레드만 실행할 수 있다.</p>\n<p>일반변수:</p>\n<ul>\n<li>readCount: 읽기스레드의 개수입니다. 만약 1→0이 되면 쓰기 스레드가 접근할 수 있도록 바꿔주고, 0→1이되면 쓰기 스레드를 사용할 수 없도록 잠궈줍니다.</li>\n</ul>\n<p>세마포어:</p>\n<ul>\n<li>wMutex [1, 0] : 쓰기 스레드가 1개까지 동작할 수 있습니다.</li>\n<li>rsync [1, 0]: 읽기 스레드가 readCount를 수정합니다.</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"c\"><pre class=\"language-c\"><code class=\"language-c\"><span class=\"token macro property\"><span class=\"token directive-hash\">#</span> <span class=\"token expression\">Reader's Code</span></span>\n<span class=\"token function\">P</span><span class=\"token punctuation\">(</span>rsync<span class=\"token punctuation\">)</span>        # 읽기 스레드 카운트를 증가하고<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span>이라면 wMutex <span class=\"token operator\">-></span> <span class=\"token number\">0</span>\nreadCount<span class=\"token operator\">+=</span><span class=\"token number\">1</span>\n<span class=\"token keyword\">if</span> readCount <span class=\"token operator\">==</span> <span class=\"token number\">1</span><span class=\"token operator\">:</span>\n\t<span class=\"token function\">P</span><span class=\"token punctuation\">(</span>wMutex<span class=\"token punctuation\">)</span>\n<span class=\"token function\">V</span><span class=\"token punctuation\">(</span>rsync<span class=\"token punctuation\">)</span>\n\n<span class=\"token punctuation\">[</span>Read Data<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>    # Reader는 별도의 Mutex 필요없이 여러 스레드가 실행되어도 된다<span class=\"token punctuation\">.</span>\n\n<span class=\"token function\">P</span><span class=\"token punctuation\">(</span>rsync<span class=\"token punctuation\">)</span>        # 읽기 스레드 카운트를 줄이고<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span>이라면 wMutex<span class=\"token operator\">-></span> <span class=\"token number\">1</span>\nreadCount<span class=\"token operator\">-=</span><span class=\"token number\">1</span>\n<span class=\"token keyword\">if</span> readCount <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token operator\">:</span>\n\t<span class=\"token function\">V</span><span class=\"token punctuation\">(</span>wMutex<span class=\"token punctuation\">)</span>\n<span class=\"token function\">V</span><span class=\"token punctuation\">(</span>rsync<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"c\"><pre class=\"language-c\"><code class=\"language-c\"><span class=\"token macro property\"><span class=\"token directive-hash\">#</span> <span class=\"token expression\">Writer's Code</span></span>\n<span class=\"token function\">P</span><span class=\"token punctuation\">(</span>wMutex<span class=\"token punctuation\">)</span>\n\n<span class=\"token punctuation\">[</span>Write Data<span class=\"token punctuation\">]</span>\n\n<span class=\"token function\">V</span><span class=\"token punctuation\">(</span>wMutex<span class=\"token punctuation\">)</span></code></pre></div>\n<p>위같이 세마포어를 활용해 독자-저자 문제를 해결할 수 있습니다. readCount와 wMutex를 수정하는 작업만 배타적으로 실행되면 됩니다.</p>\n<p>하지만 Reader가 계속해 추가된다면 Writer가 Starvation에 빠져, 실행될 수 없다는 문제점이 있습니다.</p>\n<p>이외에도 Writer를 우선하는 방법과 공평하게 분배하는 알고리즘이 있습니다.</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Readers%E2%80%93writers_problem\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">EN wiki 참고: wiki/Readers–writers_problem</a></p>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p><a href=\"https://en.wikipedia.org/wiki/Readers%E2%80%93writers_problem\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">EN wiki 참고: wiki/Readers–writers_problem</a></p>\n<p>OSTEP: Operating Systems: Three Easy Pieces - <a href=\"https://pages.cs.wisc.edu/~remzi/OSTEP/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://pages.cs.wisc.edu/~remzi/OSTEP/</a></p>\n<p><a href=\"https://www.youtube.com/watch?v=CitsUz-Dx7A&#x26;list=PLBrGAFAIyf5rby7QylRc6JxU5lzQ9c4tN&#x26;index=16\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.youtube.com/watch?v=CitsUz-Dx7A&#x26;list=PLBrGAFAIyf5rby7QylRc6JxU5lzQ9c4tN&#x26;index=16</a></p>","id":"1a0e46a0-8d6f-575f-bee5-30ecb5762905","fields":{"slug":"os-독자-저자문제와-생산자-소비자-문제-및-해결"},"frontmatter":{"date":"2023-04-16","title":"OS 독자/저자문제와 생산자/소비자 문제 및 해결","category":"tech","tags":["운영체제","운영체제 스터디"],"banner":null},"timeToRead":2},{"excerpt":"앞서 TAS를 통한 Atomic한 락 설정 방법을 공부했습니다. Atomic한 락 설정을 통해 Preemption으로 인한 이상현상 없이 임계구역을 보호하기 위해 운영체제는 몇가지 방법들을 사용합니다. 세마포어 세마포어란, 다익스트라가 제안한 알고리즘으로, Busy Waiting으로 인한 성능저하 문제를 해결합니다. 기본적인 동작방법 세마포어는 세마포어변수 S와 P,V연산으로 이뤄집니다. 세마포어 변수인 S…","html":"<p>앞서 TAS를 통한 Atomic한 락 설정 방법을 공부했습니다. Atomic한 락 설정을 통해 Preemption으로 인한 이상현상 없이 임계구역을 보호하기 위해 운영체제는 몇가지 방법들을 사용합니다.</p>\n<h1 id=\"세마포어\" style=\"position:relative;\"><a href=\"#%EC%84%B8%EB%A7%88%ED%8F%AC%EC%96%B4\" aria-label=\"세마포어 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>세마포어</h1>\n<p>세마포어란, 다익스트라가 제안한 알고리즘으로, Busy Waiting으로 인한 성능저하 문제를 해결합니다.</p>\n<p><strong>기본적인 동작방법</strong></p>\n<ol>\n<li>세마포어는 세마포어변수 S와 P,V연산으로 이뤄집니다.\n<ol>\n<li>세마포어 변수인 S변수는 공유자원에 접근할 수 있는 자원의 개수를 의미합니다.</li>\n<li>P연산은 임계구역에 접근하기 전 진입가능한지를 검사하며, 가능하지 않다면 Wait Queue에 들어갑니다.</li>\n<li>V연산은 임계구역에서 나올 때 사용합니다. S변수를 원복하고, Wait Queue에서 임계구역으로 진입하려는 프로세스를 깨웁니다.</li>\n</ol>\n</li>\n<li>각 P,V연산은 하나의 instruction cycle에서 수행되어 Interrupt로 인해 끊기지 않습니다. (이를 Indivisable, 또는 Atomic하다고 합니다.)</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"c\"><pre class=\"language-c\"><code class=\"language-c\"><span class=\"token function\">Init</span><span class=\"token punctuation\">(</span>initS<span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n\tS <span class=\"token operator\">=</span> initS\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token function\">P</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n<span class=\"token keyword\">if</span> S <span class=\"token operator\">></span> <span class=\"token number\">0</span><span class=\"token operator\">:</span>\n\tS<span class=\"token operator\">-=</span><span class=\"token number\">1</span>\n<span class=\"token keyword\">else</span><span class=\"token operator\">:</span>\n\t<span class=\"token function\">sleep</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token function\">V</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n\t<span class=\"token keyword\">if</span> Waiting Process in Queue<span class=\"token operator\">:</span>\n\t\t<span class=\"token function\">wakeup</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> # 다른 프로세스가 임계구역으로 접근하므로<span class=\"token punctuation\">,</span> S변수는 그대로<span class=\"token operator\">!</span>\n\t<span class=\"token keyword\">else</span><span class=\"token operator\">:</span>\n\t\tS<span class=\"token operator\">+=</span><span class=\"token number\">1</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token function\">Action</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n\t<span class=\"token function\">P</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token comment\">//Critical Section</span>\n\t<span class=\"token function\">V</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p><strong>세마포어의 특징: 임계구역 제한방식의 차이</strong></p>\n<p>Busy Waiting와과 Sleep-Wakeup을 통한 임계구역 제한에는 분명한 차이가 있습니다.</p>\n<p>프로세스와 상태변화(<a href=\"https://blog.mglee.dev/blog/%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EC%9D%98-%EA%B0%9C%EB%85%90%EA%B3%BC-%EC%83%81%ED%83%9C-%EB%B3%80%ED%99%94/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://blog.mglee.dev/blog/프로세스의-개념과-상태-변화/</a> 참고)에 대해 이해하고 있어야합니다.</p>\n<p><img src=\"https://github.com/lee95292/lee95292.github.io/assets/30853787/65ab6312-f58f-4a4b-b8ed-7d49180d44d0\" alt=\"1\"></p>\n<p>Semaphore의 <strong>Sleep-Wakeup에서는 블로킹된 프로세스는 CPU를 잡아먹지 않습니다.</strong></p>\n<ul>\n<li>Sleep을 하면 프로세스의 상태가 Running → Asleep(이하 Waiting)상태가 됩니다.</li>\n<li>Wakeup동작은 프로세스 상태를 Waiting → Ready로 바꿔줍니다. (But, 이 과정은 순서를 보장하지 않아, 공정성 문제가 발생합니다)</li>\n</ul>\n<p><strong>Spin Lock 방식은 블로킹된 프로세스가 CPU를 점유하며 아무동작도 하지 않습니다.</strong></p>\n<ul>\n<li>블로킹된 프로세스는 Ready ↔ Running상태를 오가며 락을 획득할때까지 기다립니다.</li>\n</ul>\n<p><strong>Busy Waiting Vs Sleep Wakeup ?</strong></p>\n<p>Sleep Wakeup 방법에서는 락을 획득하지 못해 대기하는 스레드가 Running state로 들어가는 일이 없으므로, Blocking으로 인한 CPU IDLE상태가 되지 않습니다. 따라서 <strong>일반적으로 성능이 더 좋은 Sleep-Wakeup방식을 사용합니다.</strong></p>\n<p><strong>이진 세마포어와 카운팅 세마포어</strong></p>\n<p>세마포어에는 이진 세마포어, 카운팅 세마포어로 나뉩니다.</p>\n<p><strong>이진 세마포어는</strong> 세마포어변수가 1이므로, 하나의 스레드만 임계구역에 접근할 수 있어 임계구역에 대한 상호배제를 지켜주기 때문에, Mutex라고도 불립니다. (Mutual Exclusion의 약자)</p>\n<p><strong>카운팅 세마포어는</strong> S(>1)개의 스레드가 임계구역에 접근할 수 있습니다. 카운팅 세마포어는 그 자체만으로 상호배제를 달성하지는 못합니다. 그러나 카운팅 세마포어를 적절히 사용하면 운영체제에서 발생하는 여러 동시성 문제를 해결할 수 있습니다. (Producer/Consumer 문제, 식사하는 철학자 문제 등)</p>\n<h3 id=\"세마포어-summay\" style=\"position:relative;\"><a href=\"#%EC%84%B8%EB%A7%88%ED%8F%AC%EC%96%B4-summay\" aria-label=\"세마포어 summay permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>세마포어: Summay</h3>\n<ul>\n<li>세마포어는 Busy Waiting으로 인한 성능 저하를 해결한 동시성 제어 방법입니다.</li>\n<li>P를 통해 세마포어변수 S(S>0)를 줄여 락을 획득,임계구역으로 접근하고</li>\n<li>V를 통해 S를 증가, 락을 반납하고 Wait상태의 스레드를 깨워주고 임계구역에서 나갑니다.</li>\n<li>S==0일 때, 임계구역에 진입할 수 없어  Blocking된 스레드는 Wait상태에 접어들고, 다른 스레드의 V연산을 통해 Wakeup 합니다.</li>\n<li>Counting Semapore는 세마포어변수가 1보다 커, 많은 스레드가 접근할 수 있고, S를 접근가능한 스레드 수로 정의했을 때, 상호배제가 지켜지지 않습니다. 하지만 아래와 같이 다양한 용도로 사용할 수 있습니다.\n<ul>\n<li>이는 실행하는 스레드 수를 제한하는 Thread Throttling에 사용됩니다.  세마포어 변수를 통해 S개를 초과하는 스레드에 대해 Blocking해주면, 자주 사용되는 페이지 집합이 메모리 크기를 초과해 발생하는 Thrashing을 방지할수도 있고, 과도한 Context Switch로 인한 캐시 미스도 방지할 수 있습니다.</li>\n<li>다음 글에서 소개할 Producer/Consumer 문제에서 Buffer의 사용량을 체크하는 용도로 사용되기도 합니다.</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p><strong>OSTEP: Operating Systems: Three Easy Pieces</strong> - <a href=\"https://pages.cs.wisc.edu/~remzi/OSTEP/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://pages.cs.wisc.edu/~remzi/OSTEP/</a></p>\n<p><strong>HPC Lab. KOREATECH, OS Lecture-</strong> <a href=\"https://www.youtube.com/playlist?list=PLBrGAFAIyf5rby7QylRc6JxU5lzQ9c4tN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.youtube.com/watch?v=es3WGii_7mc&#x26;list=PLBrGAFAIyf5rby7QylRc6JxU5lzQ9c4tN</a></p>","id":"9d4c2b85-54e2-5814-917e-23580010455f","fields":{"slug":"운영체제-세마포어-원리"},"frontmatter":{"date":"2023-04-02","title":"운영체제 세마포어 원리","category":"tech","tags":["운영체제","운영체제 스터디"],"banner":null},"timeToRead":2},{"excerpt":"Thread와 동작원리 <이미지 출처 https://github.com/remzi-arpacidusseau/ostep-translations/tree/master/korean > Thread는 Process 내에서 분기하는 또 다른 실행 흐름입니다. 주소공간 멀티스레드 환경에서 프로세스의 주소공간은, 스레드의 개수만큼 스택 공간이 필요합니다. 이를 Thread-local, 또는 Thread-stack…","html":"<h1 id=\"thread와-동작원리\" style=\"position:relative;\"><a href=\"#thread%EC%99%80-%EB%8F%99%EC%9E%91%EC%9B%90%EB%A6%AC\" aria-label=\"thread와 동작원리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Thread와 동작원리</h1>\n<img width=\"768\" alt=\"멀티스레드/프로세스 메모리 구조\" src=\"https://github.com/lee95292/lee95292.github.io/assets/30853787/72ccb320-559b-4d78-8c05-766cbd01904c\">\n<p>&#x3C;이미지 출처 <a href=\"https://github.com/remzi-arpacidusseau/ostep-translations/tree/master/korean\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://github.com/remzi-arpacidusseau/ostep-translations/tree/master/korean</a> ></p>\n<p>Thread는 Process 내에서 분기하는 또 다른 실행 흐름입니다.</p>\n<p><strong>주소공간</strong></p>\n<p>멀티스레드 환경에서 프로세스의 주소공간은, 스레드의 개수만큼 스택 공간이 필요합니다. 이를 <strong>Thread-local</strong>, 또는 <strong>Thread-stack</strong>이라고 합니다.</p>\n<p>멀티스레드 모델에서 주소공간 배치의 안정성이 떨어졌지만, 일반적으로 Thread-local공간은 크기가 매우 작으므로, 주소 침범으로 인한 문제가 발생하는 경우는 거의 없습니다. (Recursion을 과도하게 많이 사용할 경우를 대비해 Recursion Limit을 설정합니다. )</p>\n<p><strong>문맥교환(Context Switch)</strong></p>\n<p>PC(Program Counter)가 프로세스별로 한 개였던 단일 스레드 기반 동작과 달리, 멀티스레드 방식에서는 각 스레드마다 PC를 가지고있습니다. PC레지스터 뿐만 아니라 실행시 스레드의 정보를 담고있는 다양한 레지스터를 TCB(Thread Control Block)에 저장합니다. 이는 PCB와 마찬가지로 커널 메모리영역에 저장됩니다.</p>\n<p>스레드간의 문맥 교환은 TCB 에 있는 데이터를 CPU 레지스터로 로드하면서 시작됩니다. TCB를 독자적으로 가졌던것과 달리, 주소공간은 공유하므로 Page Table은 그대로 사용합니다.</p>\n<p><strong>멀티스레드의</strong> <strong>장점</strong></p>\n<hr>\n<p><strong>응답성</strong> 측면에서는 병렬실행을 통한 장점을 가져올 수 있습니다. 일부 스레드가 I/O작업을 처리할때 다른 스레드가 사용자 요청을 처리합니다.</p>\n<p><strong>캐시친화적</strong> 측면에서는 가장 큰 공간을 차지하는 힙 영역을 공유하므로, 캐시 히트 확률이 올라갑니다.</p>\n<p><strong>자원 활용율</strong> 측면에서, 멀티프로세서(CPU)로 구동 시 프로세서 활용률이 높아집니다.</p>\n<h2 id=\"멀티스레드의-동시성-관리\" style=\"position:relative;\"><a href=\"#%EB%A9%80%ED%8B%B0%EC%8A%A4%EB%A0%88%EB%93%9C%EC%9D%98-%EB%8F%99%EC%8B%9C%EC%84%B1-%EA%B4%80%EB%A6%AC\" aria-label=\"멀티스레드의 동시성 관리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>멀티스레드의 동시성 관리</h2>\n<p>앞서 살펴본것처럼 멀티 스레드는 성능측면에서 많은 장점이 있습니다. 높은 성능을 가져오는 주된 이유는 “자원 공유”이지만, 자원을 공유해 사용할때는 <strong>동시성 문제</strong>에 대한 관리를 적절히 해주어야 합니다.</p>\n<p><strong>동시성 문제란?</strong></p>\n<p>스레드는 <strong>비동기적</strong>으로 동작합니다. 이들은 다른 스레드의 동작과 무관하게 동작하고, 다른 스레드가 어떤 자원을 변경하는지 모릅니다.</p>\n<p>그렇기에 경쟁상태(race condition)에 있는 스레드들의 실행 결과는 <strong>비결정적</strong>입니다. Timer Interrupt로 인해 프로그램 입장에서 랜덤한 시간에 발생하는 스케쥴링 때문입니다.</p>\n<p><strong>경쟁상태의 스레드들이 비결정적으로 동작하는 예시</strong></p>\n<p>간단하게 설명하자면, A,B 스레드가 money값(100)을 읽어(Read) 200을 더하고(Add) 저장하는(Save) 과정을 수행한다고 합시다. 여기에서 동작하는 Read, Add, Save과정은 일괄적으로 처리되지 않습니다.</p>\n<p>앞서 설명했듯, 스레드의 동작과는 상관없이 동작하는 Scheduling으로 인해 Atomic하지 않습니다. 아래와 같이 동작할 수도 있습니다.</p>\n<p>→ A스레드의 Read(100), Add(300),</p>\n<p><strong>→ A에서 B스레드로 Context Switch(Scheduled)</strong></p>\n<p>→ B스레드의 Read(100), Add(300), Save(400)</p>\n<p><strong>→ B에서 A스레드로 Context Switch(Scheduled)</strong></p>\n<p>→ A 스레드의 Save(400)</p>\n<p>위 과정에서 A,B 두 스레드가 100인 money값을 각각 300씩 더해주었지만, 저장된 값은 400으로, <strong>스케줄링 타이밍에 따라 공유자원인 money를 수정하는 스레드의 동작을 예측할 수 없습니다.</strong></p>\n<p>이를 동시성이 보장되지 않은 상태라고 합니다.</p>\n<p><strong>동시성을 보장하는 방법</strong></p>\n<p>아래 조건을 만족하면 동시성이 보장되었다고 합니다.</p>\n<ol>\n<li>\n<p><strong>상호배제(Mutual Exclusion): 임계구역에는 단 하나의 실행흐름만이 동작할 수 있다.</strong></p>\n<p>임계구역이란, 공유자원을 수정하는 코드 영역을 일컫습니다. 상호배제는 동시성 프로그래밍의 가장 기본조건으로, 임계구역에서 공유자원을 수정하는 스레드는 하나여야함을 말합니다.</p>\n</li>\n<li>\n<p><strong>진행(Progress): 임계구역에 존재하는 실행흐름만이 임계구역으로의 접근을 막을 수 있다.</strong></p>\n<p>에를 들어, 임계구역에 아무 프로세스도 존재하지 않는데 진입하지 못하는 경우가 있을 수 있습니다.</p>\n</li>\n<li>\n<p><strong>한정대기(Bounded Waiting, for Fairness) : 임계구역에 접근하기 위해 대기하는 시간은 한정적이어야 한다.</strong></p>\n<p>다른 스레드의 임계구역 접근때문에 무한히 대기하는 스레드가 생길 수 있습니다.</p>\n</li>\n</ol>\n<p>동시성 프로그래밍의 구체적인 에시를 살펴보겠습니다.</p>\n<h3 id=\"변수를-통한-동시성-보장-방법\" style=\"position:relative;\"><a href=\"#%EB%B3%80%EC%88%98%EB%A5%BC-%ED%86%B5%ED%95%9C-%EB%8F%99%EC%8B%9C%EC%84%B1-%EB%B3%B4%EC%9E%A5-%EB%B0%A9%EB%B2%95\" aria-label=\"변수를 통한 동시성 보장 방법 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>변수를 통한 동시성 보장 방법</h3>\n<p>Thread-safe하게 동작하는것은 굉장히 복잡합니다. 아래 예시들을 통해 동시성이 보장된것같지만 그렇지 않은 예시들을 살펴보겠습니다.</p>\n<ol>\n<li>turn을 통한 할당</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"c\"><pre class=\"language-c\"><code class=\"language-c\"># <span class=\"token punctuation\">[</span>Thread <span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">while</span> turn <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token operator\">:</span> repeat\n<span class=\"token comment\">//critical section //</span>\nturn <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n\n# <span class=\"token punctuation\">[</span>Thread <span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">while</span> turn <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token operator\">:</span> repeat\n<span class=\"token comment\">//critical section //</span>\nturn <span class=\"token operator\">=</span> <span class=\"token number\">0</span></code></pre></div>\n<p><strong>Progress조건을 위배합니다</strong>. 하나의 스레드가 두 번 임계영역에 접근하고자 할 때, 임계구역에 어떤 스레드도 없지만 진입할 수 없습니다.</p>\n<ol>\n<li>flag를 통한 할당</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"c\"><pre class=\"language-c\"><code class=\"language-c\"># <span class=\"token punctuation\">[</span>Thread <span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\nflag<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> True\n<span class=\"token keyword\">while</span> flag<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> True<span class=\"token operator\">:</span> repeat\n<span class=\"token comment\">//critical section //</span>\nflag<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> False\n\n# <span class=\"token punctuation\">[</span>Thread <span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\nflag<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> True\n<span class=\"token keyword\">while</span> flag<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> True<span class=\"token operator\">:</span> repeat\n<span class=\"token comment\">//critical section //</span>\nflag<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> False</code></pre></div>\n<p>(여기부터 스케쥴링이 등장)</p>\n<p><strong>한정대기 조건을 위배</strong>합니다. flag[x] = True 이후 <strong>preemption</strong>된다면, 두 스레드 모두 flag를 할당받기 때문에, 무한대기 상태에 빠집니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"c\"><pre class=\"language-c\"><code class=\"language-c\"># <span class=\"token punctuation\">[</span>Thread <span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">while</span> flag<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> True<span class=\"token operator\">:</span> repaet\nflag<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> True\n<span class=\"token comment\">//critical section //</span>\nflag<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> False\n\n# <span class=\"token punctuation\">[</span>Thread <span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">while</span> flag<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> True<span class=\"token operator\">:</span> repaet\nflag<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> True\n<span class=\"token comment\">//critical section //</span>\nflag<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> False</code></pre></div>\n<p>이를 방지하기 위해 flag[x]=True구문을 while구문 아래에 넣게 된다면, while구문 이후에 preemption되었을 때,  두 스레드 모두 임계구역에 들어올 수 있어 <strong>상호배제 조건을 위배합니다.</strong></p>\n<h1 id=\"동시성-문제의-해결방법-hw-support\" style=\"position:relative;\"><a href=\"#%EB%8F%99%EC%8B%9C%EC%84%B1-%EB%AC%B8%EC%A0%9C%EC%9D%98-%ED%95%B4%EA%B2%B0%EB%B0%A9%EB%B2%95-hw-support\" aria-label=\"동시성 문제의 해결방법 hw support permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>동시성 문제의 해결방법: HW support</h1>\n<ol>\n<li>Dekker’s, Dijkstra’s 알고리즘 등 앞선 SW 해결 방식에서는 preemption으로 인해 동시성 보장이 확실시되지 않으며,</li>\n<li>Spin Lock(Busy Waitting)기반으로 자원 점유를 기다리기때문에 효율성 측면에서 오버헤드가 발생합니다.</li>\n<li>구현이 복잡합니다.</li>\n</ol>\n<p>이에 HW또는 OS측면에서 동시성 보장을 보장하기도 합니다.</p>\n<h3 id=\"tas--testandset-instruction-\" style=\"position:relative;\"><a href=\"#tas--testandset-instruction-\" aria-label=\"tas  testandset instruction  permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TAS ( TestAndSet Instruction )</h3>\n<div class=\"gatsby-highlight\" data-language=\"c\"><pre class=\"language-c\"><code class=\"language-c\">boolean <span class=\"token function\">TestAndSet</span><span class=\"token punctuation\">(</span>boolean<span class=\"token operator\">*</span> lock<span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n\tboolean old <span class=\"token operator\">=</span> <span class=\"token operator\">*</span>lock<span class=\"token punctuation\">;</span>\n\t<span class=\"token operator\">*</span>lock <span class=\"token operator\">=</span> true<span class=\"token punctuation\">;</span>\n\t<span class=\"token keyword\">return</span> old<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>TAS(Test And Set Instruction) CPU level에서 구현되어, 기계적으로 Atomic하게 수행하는것을 보장하는 명령집합입니다. 불특정 시간에 Preemption되는 상황에서도 상호배제가 지켜집니다!</p>\n<div class=\"gatsby-highlight\" data-language=\"c\"><pre class=\"language-c\"><code class=\"language-c\"><span class=\"token keyword\">while</span><span class=\"token punctuation\">(</span><span class=\"token function\">TAS</span><span class=\"token punctuation\">(</span>lock<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token keyword\">break</span>\nend <span class=\"token keyword\">while</span>\n<span class=\"token char\">''</span>'\nCRITICAL SECTION\n<span class=\"token char\">''</span>'\nlock <span class=\"token operator\">=</span> false</code></pre></div>\n<p><strong>TAS를 통해 상호배제를 보장하는 방법</strong></p>\n<p>TAS는 현재 값을 출력함과 동시에 Flag값을 True로 변경합니다.</p>\n<p>lock 전역변수에는 False,True가 들어있으며, <strong>False의경우 대기, True의 경우 점유</strong>라는 의미를 갖습니다.</p>\n<p>스레드들 중, TAS가 수행되는 동안 lock변수가 True여서 점유할 수 있게 되면, TAS명령어는 Atomic하게 True를 리턴함과 동시에 전역 Lock변수를 False로 바꿔줍니다.</p>\n<p>TAS명령은 Interrupt를 받지 않아 선정당하지 않고 Atomic하게 동작하고, 앞선 SW를 통한 해결방법보다 간단합니다.</p>\n<p><strong>TAS를 통한 동시성 제어의 제한점</strong></p>\n<p>이 방법은 상호배제와 진행을 충족하지만, 여러 스레드에서 동작할 때 <strong>공정성 측면의 한정대기는 지켜지지 않습니다.</strong></p>\n<p>Lock을 요청한 순서가 고려되어있지 않기 때문에 특정 스레드가 Lock을 계속 획득하지 못해 응답시간이 지연되는 starvation이 발생하기 때문입니다.</p>\n<p>또한 여러 개 스레드의 동시성을 제어하기 위해서는 추가적인 제어가 필요하며, Spin Lock기반이라는 점은 SW방법과 크게 다르지 않습니다.</p>\n<p>(++)</p>\n<hr>\n<p>세마포어 방식에서 사용하는 Sleep Wakeup:\nSleep 상태에서 락에 블로킹당하면 Wait큐로 들어갔다가 Ready Queue로 가기때문에, 실행순서 보장 안됨</p>\n<p>Yield의 경우, Ready Queue로 돌아가기때문에, 스케줄링 순서 보장 (공정한 스케줄링 보장)</p>\n<p>스케줄링 효율성과 공정성에 대한 등가교환 존재</p>\n<hr>\n<p>Thread throttling vs Thread pool</p>\n<p>Thread throttling과 thread pool은 모두 다중 스레드 환경에서 효율적인 자원 관리를 위해 사용되는 기술입니다.</p>\n<p>Thread throttling은 작업 수행에 필요한 리소스(보통은 CPU)를 효율적으로 활용하기 위해 작업의 실행을 지연시키는 것입니다. 예를 들어, 일정 시간 동안 특정 수의 작업만 허용하는 방식으로 스레드를 제어할 수 있습니다. 이렇게 하면 실행 중인 작업의 수가 일정하게 유지되므로 CPU 사용률이 향상되고 전체 시스템 성능이 향상될 수 있습니다.</p>\n<p>Thread pool은 스레드를 사전에 생성하고 작업을 처리할 때마다 사용 가능한 스레드 중 하나를 선택하여 할당하는 것입니다. 이렇게 하면 작업 수행에 필요한 스레드 생성 및 삭제의 오버헤드를 줄일 수 있습니다. Thread pool은 일반적으로 대규모 애플리케이션에서 사용되며, 많은 양의 요청을 처리할 때 유용합니다.</p>\n<p>따라서, Thread throttling은 실행중인 작업의 수를 제어하여 CPU 사용률을 조절하고 전체 시스템 성능을 향상시키는 반면, Thread pool은 스레드 생성 및 삭제 오버헤드를 줄이고 작업 처리를 더 효율적으로 처리할 수 있도록 돕습니다.</p>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p><strong>OSTEP: Operating Systems: Three Easy Pieces</strong> - <a href=\"https://pages.cs.wisc.edu/~remzi/OSTEP/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://pages.cs.wisc.edu/~remzi/OSTEP/</a></p>\n<p><strong>HPC Lab. KOREATECH, OS Lecture-</strong> <a href=\"https://www.youtube.com/playlist?list=PLBrGAFAIyf5rby7QylRc6JxU5lzQ9c4tN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.youtube.com/watch?v=es3WGii_7mc&#x26;list=PLBrGAFAIyf5rby7QylRc6JxU5lzQ9c4tN</a></p>","id":"a63297cb-e2dd-5ad9-bd01-3b96e82a52d5","fields":{"slug":"운영체제-멀티스레드와-동시성-문제"},"frontmatter":{"date":"2023-03-22","title":"운영체제 멀티스레드와 동시성 문제","category":"tech","tags":["운영체제","운영체제 스터디"],"banner":null},"timeToRead":4},{"excerpt":"물리메모리를 필요로 하는 프로세스가 N개 있다고 가정합시다.\nN개의 프로세스는 각각 꽤 큰 크기의 물리메모리를 필요로 해서 프로세스들이 필요한 가상공간의 크기 총 합이 물리메모리의 크기보다 커지면 우리는 N개의 프로그램을 동시에 실행하지 못할 것입니다. Swap Space 이러한 물리메모리의 크기 한계를 극복하기 위해 HDD,SSD 등 보조기억장치를 임시 저장공간인 Swap Space로 사용합니다. 이런 Swap Space…","html":"<p>물리메모리를 필요로 하는 프로세스가 N개 있다고 가정합시다.\nN개의 프로세스는 각각 꽤 큰 크기의 물리메모리를 필요로 해서 프로세스들이 필요한 가상공간의 크기 총 합이 물리메모리의 크기보다 커지면 우리는 N개의 프로그램을 동시에 실행하지 못할 것입니다.</p>\n<h3 id=\"swap-space\" style=\"position:relative;\"><a href=\"#swap-space\" aria-label=\"swap space permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Swap Space</h3>\n<p>이러한 물리메모리의 크기 한계를 극복하기 위해 HDD,SSD 등 보조기억장치를 임시 저장공간인 Swap Space로 사용합니다. 이런 Swap Space에는 자주 사용되지 않는 페이지가 위치합니다.</p>\n<p>물리메모리에서 자주 사용되지 않는 페이지가 Swap Space로 옮기는것을 Swap-out,</p>\n<p>반대로 Swap Space에 존재하는 페이지를 사용하기 위해 물리 메모리에 옮기는것을 Swap-in</p>\n<p>이라고 합니다.</p>\n<h3 id=\"가상-메모리-지원을-위한-방법\" style=\"position:relative;\"><a href=\"#%EA%B0%80%EC%83%81-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EC%A7%80%EC%9B%90%EC%9D%84-%EC%9C%84%ED%95%9C-%EB%B0%A9%EB%B2%95\" aria-label=\"가상 메모리 지원을 위한 방법 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>가상 메모리 지원을 위한 방법</h3>\n<p>이렇듯 스왑 공간까지 사용해 메모리를 더 큰것처럼 사용할 수 있도록 하는 방법을 가상 메모리(VIrtual Memory)라고 합니다.</p>\n<p>가상 메모리를 사용을 지원하기 위해서는 Swap-in 또는 Swap-out 시 참조할 <strong>디스크상 페이지 주소</strong>를 알고있어야 합니다. 두번째로는 <strong>Present Bit</strong>를 알고있어야 합니다. Present Bit는 페이지 테이블 상의 페이지가 실제 물리메모리에 적재되어있는지 여부를 나타내는 데이터입니다.</p>\n<p><strong>Present Bit가 1인 경우</strong></p>\n<p>물리메모리에 데이터가 존재합니다. 이 경우 일반적인 페이징 방법처럼 PFN을 MMU로 전달해 CPU가 메모리에 접근 할 수 있습니다.</p>\n<p><strong>Present Bit가 0인 경우</strong></p>\n<p>해당 페이지 엔트리는 물리메모리에 없고 Swap Space에 존재함을 의미합니다. 이를 <strong>Page Fault</strong>라고 합니다.</p>\n<p>이 때 MMU는 인터럽트(Page Fault Trap)을 발생시켜 Page Fault Handler를 동작하고 여기서 페이지 교체 작업이 발생합니다.</p>\n<p>Page Fault Handler는 Page Table Entry의 Present Bit를 1로 변경하고, 디스크 데이터를 물리메모리로 적재하는 I/O작업을 수행합니다.</p>\n<p><img src=\"https://user-images.githubusercontent.com/30853787/226093270-5092c56f-513e-4842-8bd9-320ed0dc6557.png\" alt=\"1\"></p>\n<p>앞서 Page Fault Handler를 통해 디스크에서 물리 메모리에 페이지를 적재한다고 했습니다. 그렇다면 위 그림을 보고 의문점이 생겨야 합니다.</p>\n<p><strong>Swap out을 언제 실행해야 하는가?</strong></p>\n<p>프로그램이 언제든 새로 시작될 수 있을 뿐만 아니라 운영체제는 특성상 항상 어느정도의 여유공간을 확보하고 있어야합니다. 이러한 운영체제 특성상 물리메모리가 가득 찼을 때만 Swap out을 하게되면 많은 문제점들이 발생합니다.</p>\n<p>이때문에 운영체제는 메모리 여유공간의 **최댓값(High watermark), 최솟값(Low watermark)**을 가지고있습니다. <strong>여유공간이 최솟값보다 적어지면 여유공간의 크기가 최댓값보다 작을때까지 여유공간을 확보</strong>합니다.  해당 스레드는 페이지 데몬(page daemon), 스왑 데몬(swap daemon)이라고 불리며, 충분한 여유공간이 확보될때까지 동작하다가 확보되면 백그라운드 스레드로 돌아갑니다.</p>\n<p><strong>Swap-out을 수행하는데, 어떤 페이지를 Swap Out 해야하는가</strong></p>\n<p>뒤이어 페이지 교체 정책에서 설명합니다.</p>\n<h2 id=\"페이지-교체-정책\" style=\"position:relative;\"><a href=\"#%ED%8E%98%EC%9D%B4%EC%A7%80-%EA%B5%90%EC%B2%B4-%EC%A0%95%EC%B1%85\" aria-label=\"페이지 교체 정책 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>페이지 교체 정책</h2>\n<p>페이지 교체 정책에 대해 이야기하기 전에 교체 정책의 성능을 측정하는 방법에 대해 알아보아야 합니다.</p>\n<p><strong>AMAT(Average Memory Access Time): 평균 메모리 접근시간 = P(Hit) * T(M) + P(Miss) * T(D)</strong></p>\n<p>설명하자면, 스왑공간을 사용하는 가상 메모리 시스템의 평균 메모리 접근시간은 아래와 같습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">P(Hit): 캐시 히트 확률 * T(M): 메모리 접근 시간을 곱해준 값 +\nP(Miss):페이지 폴트 확률과 T(D): 디스크 접근 시간</code></pre></div>\n<h3 id=\"최적-교체-방식-optimal-replacement-policy\" style=\"position:relative;\"><a href=\"#%EC%B5%9C%EC%A0%81-%EA%B5%90%EC%B2%B4-%EB%B0%A9%EC%8B%9D-optimal-replacement-policy\" aria-label=\"최적 교체 방식 optimal replacement policy permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>최적 교체 방식 (Optimal Replacement Policy)</h3>\n<p>최적 교체방식의 원리는 간단합니다. <strong>“가장 나중에 참조할 페이지를 축출한다”</strong> 입니다.</p>\n<p>최적 교체방식은 이상적인 방법이지만, 가장 나중에 참조할 페이지 찾기라는 <strong>미래를 예측하는 불가능한 과정을 포함</strong>합니다.</p>\n<p>최적의 방법은 비교 기준으로만 사용되며, 비교하고자 하는 알고리즘이 정답에 얼마나 가까운지 알 수 있습니다.</p>\n<h3 id=\"lruleast-recently-used\" style=\"position:relative;\"><a href=\"#lruleast-recently-used\" aria-label=\"lruleast recently used permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>LRU(Least Recently Used)</h3>\n<p>LRU방식은 과거 메모리 접근에 대한 정보를 사용합니다. 이름 그대로 <strong>가장 먼 시점에 사용된 페이지를 교체합니다.</strong></p>\n<p>메모리 접근 정보 중에서 **최근성(recency)**를 사용한 방법입니다. 얼마나 최근에 접근했는지에 대한 정보를 가지고있습니다. 더 최근에 접근한 페이지일수록 가까운 시점에 다시 접근할 확률 이 높다는 특성인 **캐시 지역성의 원칙(Principle of locality)**이라는 특성에 기반을 둡니다.</p>\n<p>이처럼 메모리 접근 정보에는 빈도(frequency)도 있지만, MFU(Most Frequently Used)알고리즘은 캐시의 지역성 특징과 맞지 않으므로 효율적으로 동작하지 않습니다.</p>\n<p>예를들어 100번째 페이지를 5000회 접근한 이후 한번도 접근하지 않는다면 빈도수는 높아서 계속 물리메모리에 남아있지만 사용되지는 않습니다.</p>\n<p>LRU는 메모리 교체 방식중 효율이 가장 좋은 방법으로, 주로 사용되는 페이지 교체 알고리즘입니다.</p>\n<h3 id=\"간단한-방식들-fifo-random-select\" style=\"position:relative;\"><a href=\"#%EA%B0%84%EB%8B%A8%ED%95%9C-%EB%B0%A9%EC%8B%9D%EB%93%A4-fifo-random-select\" aria-label=\"간단한 방식들 fifo random select permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>간단한 방식들( FIFO, Random Select)</h3>\n<p><strong>First In First Out : 선입선출</strong></p>\n<p>먼저 들어온것이 먼저 나갑니다. 매우 간단한 알고리즘이지만 성능이 떨어집니다.</p>\n<p><strong>Ramdom Select: 무작위 선택</strong></p>\n<p>무작위로 Swap out될 페이지를 선택합니다. 해당 방법은 그때마다 수행 결과가 달라집니다.</p>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p><a href=\"%5Bhttps://pages.cs.wisc.edu/~remzi/OSTEP/%5D(https://pages.cs.wisc.edu/~remzi/OSTEP/)\">OSTEP: Operating Systems: Three Easy Pieces</a></p>\n<p>[<strong>HPC Lab. KOREATECH, OS Lecture]<a href=\"https://www.youtube.com/watch?v=r1JVA7yOPAM&#x26;\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">(</a></strong><a href=\"https://www.youtube.com/playlist?list=PLBrGAFAIyf5rby7QylRc6JxU5lzQ9c4tN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.youtube.com/watch?v=es3WGii_7mc&#x26;list=PLBrGAFAIyf5rby7QylRc6JxU5lzQ9c4tN</a><strong>)</strong></p>","id":"17750e88-7178-50d4-b121-377268c8ac01","fields":{"slug":"페이지-교체와-정책-swap"},"frontmatter":{"date":"2023-03-09","title":"페이지 교체와 정책 (Swap)","category":"tech","tags":["운영체제","운영체제 스터디"],"banner":null},"timeToRead":2},{"excerpt":"페이징 기법의 문제점 앞선 글에서 소개한 페이징 기법에서는 페이지의 크기를 4KB로 가정했습니다. 그러나 현대에는 메모리의 크기가 4GB를 넘어 64GB까지도 사용됩니다. 이런 컴퓨터에서 4KB의 페이지를 사용한다면 페이지 개수가 10^6 ~ 10^…","html":"<h3 id=\"페이징-기법의-문제점\" style=\"position:relative;\"><a href=\"#%ED%8E%98%EC%9D%B4%EC%A7%95-%EA%B8%B0%EB%B2%95%EC%9D%98-%EB%AC%B8%EC%A0%9C%EC%A0%90\" aria-label=\"페이징 기법의 문제점 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>페이징 기법의 문제점</h3>\n<p>앞선 글에서 소개한 페이징 기법에서는 페이지의 크기를 4KB로 가정했습니다. 그러나 현대에는 메모리의 크기가 4GB를 넘어 64GB까지도 사용됩니다.</p>\n<p>이런 컴퓨터에서 4KB의 페이지를 사용한다면 페이지 개수가 10^6 ~ 10^7까지도 커지게 됩니다.</p>\n<p>페이지 테이블은 각 프로세스마다 가지는 자료구조이고, <strong>“커널메모리”에 저장</strong>되는 자료이다 보니, <strong>페이지 테이블이 커지면 커질수록</strong> <strong>메모리 가용역역이 작아집니다.</strong></p>\n<p>또한, Segmentation에서는 해결된 메모리의 보호와 공유가 어렵다는 문제가 남아있습니다.</p>\n<h3 id=\"페이지-테이블-크기-문제-해결방법\" style=\"position:relative;\"><a href=\"#%ED%8E%98%EC%9D%B4%EC%A7%80-%ED%85%8C%EC%9D%B4%EB%B8%94-%ED%81%AC%EA%B8%B0-%EB%AC%B8%EC%A0%9C-%ED%95%B4%EA%B2%B0%EB%B0%A9%EB%B2%95\" aria-label=\"페이지 테이블 크기 문제 해결방법 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>페이지 테이블 크기 문제 해결방법</h3>\n<p><strong>(1) 더 큰 페이지 크기</strong></p>\n<p>단순하게 생각하면 페이지 크기를 더 키우면 페이지 테이블 사이즈는 작아집니다.</p>\n<p>이를 통해 <strong>(1)디스크 접근횟수를 줄이고 (2)페이지 테이블크기를 줄이는</strong> 효과를 얻을 수 있습니다.</p>\n<p>메모리 크기가 커짐에 따라 페이지 사이즈를 키울수록 이 방법은 몇 가지 <strong>단점</strong>이 있습니다</p>\n<ol>\n<li>내부 단편화가 더 크게 발생합니다.</li>\n<li>큰 페이지를 로드했지만, 사용되는 비율이 적어 <strong>메모리 사용률이 줄어듭니다</strong>.</li>\n</ol>\n<p><strong>(2) Multi Level Paging 방법</strong></p>\n<p><img src=\"https://user-images.githubusercontent.com/30853787/226093248-29394fe1-480b-41af-8c30-ed6745922558.png\" alt=\"1\"></p>\n<p>Multi Level Paging기법에서는 페이지 디렉터리를 통해 하나의 레벨을 추가합니다.</p>\n<p>또한 페이지 디렉터리 테이블(PDT)에는 valid bit가 존재합니다. 앞선 페이징 방법에서는 Heap공간에서 사용중인 페이지를 valid bit로 판별했던 반면, <strong>PDT에서의 valid bit는 PDE가 가르키는 페이지 테이블의 엔트리들 중 하나라도 유효한지에 대한 여부입니다(중요) → Heap 또는 Stack의 빈공간으로 인해 사용되는 메모리 낭비를 없애줌.</strong></p>\n<p><strong>장단점</strong></p>\n<p>페이징에서는 페이지 번호를 통해 페이지 테이블에 접근했으므로, 해당 페이지가 스왑 스페이스에 있어도 하나의 페이지  테이블을 가지고있어야 했습니다.</p>\n<p><strong>Multi Level Paging방법에서는 PDT의 valid bit가 1인 PMT에 대해서만 메모리 공간을 할당하므로 메모리 공간 효율성이 뛰어납니다.</strong></p>\n<p>그러나 Multi Level로 페이지 테이블이 존재하는 경우 가상주소 변환에 있어 메모리 접근을 N회 해야한다는 단점이 있습니다. (TLB로 완화할 수 있습니다)</p>\n<p>이처럼 MultiLevel Paging에는 시간-공간 등가교환이 존재합니다.</p>\n<p><strong>(번외) Segmentation/Paging Hybrid 방법</strong></p>\n<p><img src=\"https://user-images.githubusercontent.com/30853787/226093250-bb5c0f90-8f66-4cc1-8b47-ab1a13a3f84b.png\" alt=\"2\"></p>\n<p>Hybrid기법은 Segmentattion과 Paging기법을 혼합한 방법입니다.</p>\n<p>가상 메모리를 논리 단위의 세그먼트로 분할한 뒤, 이를 또 다시 페이지로 나눕니다.</p>\n<p>그렇기에 (그림 우측 상단의)가상 메모리 주소는 세그먼트 비트, 가상 페이지 번호인 Virtual Page Number,와 페이지 내에서의 Offset으로 이루어져 있습니다.</p>\n<p>즉, (S,P,D)값을 통해 물리 메모리 주소를 얻는것인데요, 방법은 아래와 같습니다.</p>\n<p><strong>1) 세그먼트 매핑 테이블 접근</strong></p>\n<p>세그먼트별로 존재하는 SMT에서 S번째 엔트리를 찾아갑니다. 여기서는 <strong>세그먼트 길이 검증, Protection Bit를 통해 자원의 공유와 보호를 수행</strong>합니다.</p>\n<p>또한 세그먼트에 대한 페이징 정보를 가지고있는 페이지 테이블 주소를 MMU에 전달합니다.</p>\n<p>물리메모리에는 Page 단위로 올라가므로 Residence bit는 존재하지 않습니다.</p>\n<p><strong>2) 페이지 매핑 테이블 접근</strong></p>\n<p>SMT에서 얻은 S(j)의 PMT 주소와 가상 페이지 번호인 VPN을 통해 물리 메모리에서 페이지의 주소를 획득합니다.</p>\n<p>이 때 Residence bit를 확인해 페이지가 존재하는지 확인하고 존재하지 않는다면 Page Fault Trap을 발생시켜 페이지 교체 알고리즘을 수행합니다.</p>\n<p><strong>3) PFN 획득 및 메모리 접근</strong></p>\n<p>PMT에서는 PFN을 얻었고, 여기에 페이지 크기를 곱하면 물리 메모리상 주소를 알 수 있습니다.</p>\n<p>Hybrid 기법은 페이징을 통해 메모리 사용률을 높혀준다는 장점과 세그멘테이션을 통해 보호와 공유를 용이하게 해준다는 장점이 있습니다.</p>\n<p>그러나 Hybrid방법에도 한계점은 존재합니다.</p>\n<ol>\n<li>여전히 페이지 테이블 크기가 많은 메모리 공간을 차지한다는 단점과</li>\n<li>Direct Mapping의 경우 가상 메모리 변환 시, 3회의 메모리 접근이 필요하다는 점입니다.\n<ol>\n<li>이는 TLB 활용으로 극복 가능합니다.</li>\n</ol>\n</li>\n</ol>\n<p>Fact Check</p>\n<ul>\n<li>\n<p>Protection Bit가 세그먼트에서 더 효율적인 이유</p>\n<p>→ 횟수에따른 용이성일것으로 생각, paging에서는 다음주소 참조시에도 또 확인해야해서</p>\n</li>\n<li>\n<p>Page Directory Table에서 또는 Page Table에서 Valid bit가 0인경우 swap공간에 있기는 한지?</p>\n<ul>\n<li>Multi Level Paging에서는 valid 가 0인 경우에 대해서 Page를 할당하지도 않는다! 따라서 swap공간에 있는게 아니라 사용하게되면 페이지를 다시 할당함.</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p><a href=\"%5Bhttps://pages.cs.wisc.edu/~remzi/OSTEP/%5D(https://pages.cs.wisc.edu/~remzi/OSTEP/)\">OSTEP: Operating Systems: Three Easy Pieces</a></p>\n<p>[<strong>HPC Lab. KOREATECH, OS Lecture]<a href=\"https://www.youtube.com/watch?v=r1JVA7yOPAM&#x26;\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">(</a></strong><a href=\"https://www.youtube.com/playlist?list=PLBrGAFAIyf5rby7QylRc6JxU5lzQ9c4tN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.youtube.com/watch?v=es3WGii_7mc&#x26;list=PLBrGAFAIyf5rby7QylRc6JxU5lzQ9c4tN</a><strong>)</strong></p>","id":"dfda67c2-6b6f-5a74-9ce7-bd696f306d49","fields":{"slug":"다양한-페이징-기법-hybrid-multi-level-paging"},"frontmatter":{"date":"2023-03-08","title":"다양한 페이징 기법 [ Hybrid, Multi Level Paging]","category":"tech","tags":["운영체제","운영체제 스터디"],"banner":null},"timeToRead":2},{"excerpt":"불연속 메모리 할당기법 세그멘테이션, 페이징은 대표적인 불연속 메모리 할당기법입니다. 각각 세그먼트, 페이지라는 단위로 프로그램을 나누고 페이지/세그먼트 테이블을 통해 가상/물리 메모리를 매핑, 연속적인 가상 주소공간을 사용할 수 있도록 합니다. 특징 및 연속 할당기법과의 차이 1 여전히 명령어는 가상주소를 기반으로 실행됩니다. Segmentation 프로그램을 의미있는 단위인 Heap, Stack, Code, Data…","html":"<h2 id=\"불연속-메모리-할당기법\" style=\"position:relative;\"><a href=\"#%EB%B6%88%EC%97%B0%EC%86%8D-%EB%A9%94%EB%AA%A8%EB%A6%AC-%ED%95%A0%EB%8B%B9%EA%B8%B0%EB%B2%95\" aria-label=\"불연속 메모리 할당기법 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>불연속 메모리 할당기법</h2>\n<p><strong>세그멘테이션, 페이징</strong>은 대표적인 불연속 메모리 할당기법입니다. 각각 세그먼트, 페이지라는 단위로 프로그램을 나누고 페이지/세그먼트 테이블을 통해 가상/물리 메모리를 매핑, 연속적인 가상 주소공간을 사용할 수 있도록 합니다.</p>\n<h3 id=\"특징-및-연속-할당기법과의-차이\" style=\"position:relative;\"><a href=\"#%ED%8A%B9%EC%A7%95-%EB%B0%8F-%EC%97%B0%EC%86%8D-%ED%95%A0%EB%8B%B9%EA%B8%B0%EB%B2%95%EA%B3%BC%EC%9D%98-%EC%B0%A8%EC%9D%B4\" aria-label=\"특징 및 연속 할당기법과의 차이 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>특징 및 연속 할당기법과의 차이</h3>\n<p><img src=\"https://user-images.githubusercontent.com/30853787/226093229-eeb1540a-35fd-4f8c-905a-e454c845160a.png\" alt=\"1\"></p>\n<p>여전히 명령어는 가상주소를 기반으로 실행됩니다.</p>\n<p><strong>Segmentation</strong></p>\n<p>프로그램을 의미있는 단위인 Heap, Stack, Code, Data등 프로그램을 구성하는 논리적 단위인 “세그먼트”로 분할해 메모리에 적재하는 방법입니다.</p>\n<p><strong>Paging</strong></p>\n<p>프로세스를 고정된 크기(intel x86의 경우 4kb)의 page block으로 프로그램을 나눠 물리 메모리에 할당하는 방법</p>\n<h2 id=\"물리메모리-매핑-과정\" style=\"position:relative;\"><a href=\"#%EB%AC%BC%EB%A6%AC%EB%A9%94%EB%AA%A8%EB%A6%AC-%EB%A7%A4%ED%95%91-%EA%B3%BC%EC%A0%95\" aria-label=\"물리메모리 매핑 과정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>물리메모리 매핑 과정</h2>\n<p><strong>가상 주소 공간과 실제 메모리 주소의 매핑은 각각 페이지와 세그먼트 매핑 테이블 (PMT, SMT)가 담당합니다.</strong></p>\n<h3 id=\"페이징-기법에서-매핑과정-direct-mapping\" style=\"position:relative;\"><a href=\"#%ED%8E%98%EC%9D%B4%EC%A7%95-%EA%B8%B0%EB%B2%95%EC%97%90%EC%84%9C-%EB%A7%A4%ED%95%91%EA%B3%BC%EC%A0%95-direct-mapping\" aria-label=\"페이징 기법에서 매핑과정 direct mapping permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>페이징 기법에서 매핑과정: Direct Mapping</h3>\n<p><img src=\"https://user-images.githubusercontent.com/30853787/226093232-74c55ebc-45cb-4529-b1c9-5843031ed337.png\" alt=\"2\"></p>\n<p><strong>기본 가정</strong></p>\n<p>32bit 컴퓨터로 가정합니다 → 하나의 명령이 처리할 수 있는 데이터 양(word)가 32bit, 한 워드에 최대로 표시할 수 있는 메모리 주소는 2^32 byte이므로 최대 메모리가 4GB 입니다.</p>\n<p>이 때 페이지 크기를 설정해봅시다. 페이지 크기는 내부 단편화 및 로드 속도를 고려해 정하게 되는데, 윈도우 시스템에서는 4KB로 사용한다고 합니다.</p>\n<p>그렇다면 이론상으로는 4GB(2^32 Byte)의 메모리상에 4KB(2^12 Byte)의 페이지가  2^20개 존재할 수 있습니다.</p>\n<p><strong>(1) 명령어 실행</strong></p>\n<p>그렇기에 명령어 32bit는 그림 우측 상단처럼 <strong>20bit의 VPN과 12bit의 Offset</strong>(페이지 내 데이터 위치)로 구분할 수 있습니다. 이를 각각 P,D라고 칭합니다.</p>\n<p><strong>(2)PPN(Physical Page Number) 조회</strong></p>\n<p>1에서 얻은 가상 페이지 주소(P)는 페이지 테이블의 행 번호입니다. 페이지 테이블에서는 VPN(가상페이지번호)을 통해 PPN(물리메모리 페이지번호)을 얻을 수 있습니다.</p>\n<p><strong>(3) 물리 메모리 주소 반환</strong></p>\n<p>2과정에서 얻은 PPN(Z)과 1과정에서 얻은 페이지 내 변위 Offset(D)를 통해 물리 메모리 주소를 정확하게 알 수 있습니다 ( = Z + D ) 해당 주소의 명령은 CPU로 전달됩니다.</p>\n<p>가상/물리 메모리에서 Page Number는 바뀌기때문에 PPN, VPN으로 구분하지만 <strong>Offset은 Page 내에서 상대적인 위치이므로 물리메모리에서도 동일하게 사용할 수 있습니다.</strong></p>\n<p><strong>단점</strong></p>\n<p>Page Table은 프로세스별로 하나씩 가지고있으며 이는 <strong>커널 메모리(PCB)에 존재</strong>합니다.</p>\n<p><strong>따라서 메모리 데이터를 얻기 위해 메모리를 2회 접근하는 오버헤드가 발생합니다.</strong></p>\n<h3 id=\"페이징-기법에서-매핑과정-associate-mapping--tlb\" style=\"position:relative;\"><a href=\"#%ED%8E%98%EC%9D%B4%EC%A7%95-%EA%B8%B0%EB%B2%95%EC%97%90%EC%84%9C-%EB%A7%A4%ED%95%91%EA%B3%BC%EC%A0%95-associate-mapping--tlb\" aria-label=\"페이징 기법에서 매핑과정 associate mapping  tlb permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>페이징 기법에서 매핑과정: Associate Mapping  (TLB)</h3>\n<p><img src=\"https://user-images.githubusercontent.com/30853787/226093235-7d5b2f89-6936-467f-a74b-5162bdae3305.png\" alt=\"3\"></p>\n<p>출처 : <a href=\"http://slideplayer.com/slide/5823226/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">http://slideplayer.com/slide/5823226/</a></p>\n<p>CPU칩셋 내부에 고속 하드웨어 서포트가 추가됩니다. TLB (Translation Lookaside Buffer)는 Page Table과 비슷한 구조를 띠지만, CPU 내에 위치해 병렬적으로 테이블을 탐색해 VPN → PPN 전환 속도를 더욱 빠르게 해줍니다.</p>\n<h3 id=\"페이징-기법에서-매핑과정-hybrid-small-tlb\" style=\"position:relative;\"><a href=\"#%ED%8E%98%EC%9D%B4%EC%A7%95-%EA%B8%B0%EB%B2%95%EC%97%90%EC%84%9C-%EB%A7%A4%ED%95%91%EA%B3%BC%EC%A0%95-hybrid-small-tlb\" aria-label=\"페이징 기법에서 매핑과정 hybrid small tlb permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>페이징 기법에서 매핑과정: Hybrid (Small TLB)</h3>\n<p>TLB는 가격이 비싼 하드웨어이므로, 모든 페이지 테이블 정보를 담을만큼 충분한 크기를 가질 수 없습니다.</p>\n<p>시간 및 공간 지역성원리를 활용해, LRU로 교체되는 작은 TLB를 사용합니다.</p>\n<p>TLB 미스가 날 경우 TLB접근시간 + 메모리 접근 및 교체시간이 추가로 소요됩니다.</p>\n<h3 id=\"세그먼테이션-기법에서-매핑-과정\" style=\"position:relative;\"><a href=\"#%EC%84%B8%EA%B7%B8%EB%A8%BC%ED%85%8C%EC%9D%B4%EC%85%98-%EA%B8%B0%EB%B2%95%EC%97%90%EC%84%9C-%EB%A7%A4%ED%95%91-%EA%B3%BC%EC%A0%95\" aria-label=\"세그먼테이션 기법에서 매핑 과정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>세그먼테이션 기법에서 매핑 과정</h3>\n<p><img src=\"https://user-images.githubusercontent.com/30853787/226093237-af52f4d4-1353-4652-a3e6-f48cb6951695.png\" alt=\"4\"></p>\n<p><strong>페이징 방법과의 차이</strong></p>\n<p>페이징에서 방법과 많은 부분이 유사합니다. 그러나 의미 단위인 “세그먼트”로 메모리를 나누었으므로 가상주소에서 최상위 N개 비트를 세그먼트 번호로 사용하면 됩니다.</p>\n<p>또한 페이징에서는 페이지가 고정 크기이므로 PPN을 통해 메모리에 접근할 수 있었지만 물리 메모리에서 세그먼트는 시작주소가 일정하지 않습니다. 그러므로 시작 주소를 직접 가지고있고, 세그먼트 길이도 제각각이므로 세그먼트 테이블에서 관리해 허용되지 않는 영역에 접근하는지 체크합니다. 즉, <strong>Offset이 세그먼트 길이보다 크면 Segmentation Fault를 발생시킵니다.</strong></p>\n<p><strong>세그먼트 크기</strong></p>\n<p>스택,힙,데이터, 코드의 대표적인 세그먼트 분류로 나누게 되면 최상위 2개 비트만으로 프로세스의 모든 세그먼트를 표현할 수 있습니다. 이를 <strong>대단위 세그먼트</strong> 라고 합니다.</p>\n<p>대단위 세그먼트에서는 외부 단편화 문제가 더 두드러지게 나타나고 세그먼트 로드 속도가 느리고 자주 사용되지 않는 데이터도 함께 로드되는 단점이 있습니다. 이를 위해 세그먼트를 더 세부적인 단위로 나누는 방법을 <strong>소단위 세그먼트</strong>라고 합니다.</p>\n<p>소단위 세그먼트는 프로세스당 세그먼트 수가 더 많으므로 세그먼트 테이블이 더 커진다는 단점이 있지만, 미사용 세그먼트를 구분해 메모리 사용률을 높일 수 있다는 장점이 있습니다.</p>\n<h3 id=\"전반적인-비교--segmentation-vs-paging\" style=\"position:relative;\"><a href=\"#%EC%A0%84%EB%B0%98%EC%A0%81%EC%9D%B8-%EB%B9%84%EA%B5%90--segmentation-vs-paging\" aria-label=\"전반적인 비교  segmentation vs paging permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>전반적인 비교 : Segmentation Vs Paging</h3>\n<p>세그멘테이션은 가변 길이의 세그먼트로 가상주소를 분리했으므로 외부 단편화가 발생할 수 있지만 논리 단위의 데이터 공유 및 보호가 용이합니다. 대단위 세그먼트로 분리하는 경우 메모리 사용률이 적어진다는 단점이 있지만, 소단위 세그먼트를 통해 극복할 수 있습니다. ( 세그먼트 테이블 크기와 Trade-Off )</p>\n<p>페이징은 고정 크기의 페이지로 가상 주소를 분리했으므로 내부 단편화가 발생할 수 있고 보호/공유 측면에서 복잡성이 존재하지만, 메모리 사용률 측면에서 높은 성능을 보이며 페이지 테이블</p>\n<h2 id=\"매핑-테이블로-알아보는-페이지세그먼트-변환\" style=\"position:relative;\"><a href=\"#%EB%A7%A4%ED%95%91-%ED%85%8C%EC%9D%B4%EB%B8%94%EB%A1%9C-%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94-%ED%8E%98%EC%9D%B4%EC%A7%80%EC%84%B8%EA%B7%B8%EB%A8%BC%ED%8A%B8-%EB%B3%80%ED%99%98\" aria-label=\"매핑 테이블로 알아보는 페이지세그먼트 변환 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>매핑 테이블로 알아보는 페이지/세그먼트 변환</h2>\n<p>앞선 그림에서 확인한 세그먼트/페이지 매핑 테이블에는 주소 매핑을 위한 정보 말고도 각각을 설명하는 많은 정보를 담고있고 보호 및 효율을 위해 추가적인 동작을 합니다.</p>\n<p><strong>공통 구성요소</strong></p>\n<ul>\n<li>Present Bit : 물리메모리 상에 로드되어있는지 (Swap-in 여부, Swap Device에 존재할 경우 0 )</li>\n<li>Valid Bit : 스택 또는 힙의 미사용 공간은 invalid한 공간으로, 접근할 수 없음. 이를 마킹해 트랩을 통해 잘못된 영역으로의 접근을 막는다.</li>\n<li>Dirty Bit: 페이지/세그먼트가 메모리에 로드된 이후 변경되었는지 체킹해 이 비트가 세팅된 데이터는 주기적으로 메모리로 Flush작업을 한다.</li>\n<li>Protection Bit: 프로세스별로 해당 페이지에 RWX Access 권한을 마킹한 비트, 페이지 공유 및 보호를 가능하게 함.</li>\n<li>Swap Address: Swap device상에서 주소</li>\n</ul>\n<p><strong>페이지 테이블  구성요소</strong></p>\n<ul>\n<li>PPN: 물리메모리 페이지 번호</li>\n</ul>\n<p><strong>세그먼트 테이블 구성요소</strong></p>\n<ul>\n<li>Segment Address: 세그먼트 주소</li>\n<li>Segement Length: 세그먼트 크기</li>\n</ul>\n<h3 id=\"질문\" style=\"position:relative;\"><a href=\"#%EC%A7%88%EB%AC%B8\" aria-label=\"질문 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>질문</h3>\n<p>세그멘테이션에서 가변 데이터인 스택, 힙에 대해 추가공간이 필요하면 어떻게할까?</p>\n<p>→ 런타임에서 길이가 증가/감소, 추가적인 빈 공간 리스트에 할당</p>\n<p>세그먼트 테이블은 프로세스별로 존재하는가?</p>\n<p>→Yes</p>\n<p>Valid bit가 Segmentation table 에서도 있는지 확인</p>\n<h3 id=\"\" style=\"position:relative;\"><a href=\"#\" aria-label=\" permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p><a href=\"%5Bhttps://pages.cs.wisc.edu/~remzi/OSTEP/%5D(https://pages.cs.wisc.edu/~remzi/OSTEP/)\">OSTEP: Operating Systems: Three Easy Pieces</a></p>\n<p>[<strong>HPC Lab. KOREATECH, OS Lecture]<a href=\"https://www.youtube.com/watch?v=r1JVA7yOPAM&#x26;\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">(</a></strong><a href=\"https://www.youtube.com/playlist?list=PLBrGAFAIyf5rby7QylRc6JxU5lzQ9c4tN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.youtube.com/watch?v=es3WGii_7mc&#x26;list=PLBrGAFAIyf5rby7QylRc6JxU5lzQ9c4tN</a><strong>)</strong></p>\n<p><a href=\"https://talkingaboutme.tistory.com/entry/Memory-Sample-Memory-System\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://talkingaboutme.tistory.com/entry/Memory-Sample-Memory-System</a></p>","id":"e833f569-08c9-5577-a07b-57804ec11128","fields":{"slug":"세그멘테이션과-페이징-비교"},"frontmatter":{"date":"2023-02-27","title":"세그멘테이션과 페이징 (+ 비교 )","category":"tech","tags":["운영체제","운영체제 스터디"],"banner":null},"timeToRead":3},{"excerpt":"프로세스에게 메모리를 할당해주는 방식의 발전과정과, CPU가 안전하게 메모리에 접근하기 위해 주소공간을 가상화하는 방법을 설명합니다. 주소공간 1 컴퓨터공학 수업들을 들으며 수없이 봐왔던 주소공간입니다. 이는 프로세스 하나가 실행될때 만들어지는 가상의 주소공간이고, 프로그램 코드 영역에서는…","html":"<p>프로세스에게 메모리를 할당해주는 방식의 발전과정과, CPU가 안전하게 메모리에 접근하기 위해 주소공간을 가상화하는 방법을 설명합니다.</p>\n<h1 id=\"주소공간\" style=\"position:relative;\"><a href=\"#%EC%A3%BC%EC%86%8C%EA%B3%B5%EA%B0%84\" aria-label=\"주소공간 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>주소공간</h1>\n<p><img src=\"https://user-images.githubusercontent.com/30853787/226093193-30acf0ce-093c-41b6-aacd-b9b791c2ff85.png\" alt=\"1\"></p>\n<p>컴퓨터공학 수업들을 들으며 수없이 봐왔던 주소공간입니다.</p>\n<p>이는 프로세스 <strong>하나가 실행될때 만들어지는 가상의 주소공간</strong>이고, 프로그램 코드 영역에서는 <strong>0을 기준</strong>으로 주소를 참고합니다.  이같은 주소공간은 물리메모리상에 프로세스의 개수만큼 존재합니다.</p>\n<p>현대의 컴퓨터들은 메모리 영역을 가상화하기 위해 “주소공간”이라는 개념을 만들어 명령어를 실행할 때 명령어의 물리메모리상 실제 위치를 알고있지 않아도 되도록 구성했습니다.</p>\n<p>운영체제에서 프로세스를 실행할 때 <strong>주소변환을 통한 가상화</strong>로 다른 프로세스로부터 <strong>보호와 고립</strong>이 가능하도록 합니다.</p>\n<h2 id=\"주소변환-baselimit-방법-연속할당-방법에서-사용\" style=\"position:relative;\"><a href=\"#%EC%A3%BC%EC%86%8C%EB%B3%80%ED%99%98-baselimit-%EB%B0%A9%EB%B2%95-%EC%97%B0%EC%86%8D%ED%95%A0%EB%8B%B9-%EB%B0%A9%EB%B2%95%EC%97%90%EC%84%9C-%EC%82%AC%EC%9A%A9\" aria-label=\"주소변환 baselimit 방법 연속할당 방법에서 사용 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>주소변환: base/limit 방법 (연속할당 방법에서 사용)</h2>\n<p><img src=\"https://user-images.githubusercontent.com/30853787/226093194-a99d68fe-1d74-4b80-b0c5-6dc4006860e4.png\" alt=\"2\"></p>\n<p>주소변환을 통해 명령어를 실행할 때 물리메모리 주소에 대해 생각하지 않아도 되는 메모리 가상화가 가능해집니다.</p>\n<p>CPU는 base, limit레지스터를 가지고있어 <strong>가상주소가 limit을 넘어갈 경우</strong> 예외를 발생시켜 <strong>프로세스를 보호</strong>합니다. <strong>base레지스터는 physical address로 접근 시 주소를 변환</strong>하는데 사용합니다.</p>\n<p>또한 Context Switch시에는 base/limit을 PCB에서 불러와 갱신합니다.</p>\n<h1 id=\"연속-메모리-할당-방법\" style=\"position:relative;\"><a href=\"#%EC%97%B0%EC%86%8D-%EB%A9%94%EB%AA%A8%EB%A6%AC-%ED%95%A0%EB%8B%B9-%EB%B0%A9%EB%B2%95\" aria-label=\"연속 메모리 할당 방법 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>연속 메모리 할당 방법</h1>\n<p>연속 메모리할당 방법이란: 프로세스가 필요로 하는 데이터를 메모리에 연속적으로 할당하는 방식으로, 이후에 배울 발전된 방식인 “불연속 메모리 할당”과 대비되는 개념입니다.</p>\n<p>(관계 정리)</p>\n<p>Continuous Memory Allocation: 연속 메모리 할당</p>\n<ul>\n<li>Uni Programming</li>\n<li>Multi Programming\n<ul>\n<li>Fixed Allocation: 고정 할당</li>\n<li>Variable Allocation: 가변 할당</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/30853787/226093195-92e059e3-2461-4979-92c9-60e0ebfb77a2.png\" alt=\"3\"></p>\n<h3 id=\"uni-programming\" style=\"position:relative;\"><a href=\"#uni-programming\" aria-label=\"uni programming permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Uni Programming</h3>\n<p><strong>Uni Programming</strong>은 운영체제 개발 초기에 단일 사용자가 단일 프로그램을 사용하는 모델에서 개발된 할당방식입니다.</p>\n<p>하나의 PC에서 하나의 프로그램만 메모리를 할당받을 수 있었죠. 아래와 같은 문제점이 있습니다.</p>\n<ul>\n<li>CPU활용도 낮음</li>\n<li>메모리 활용도 낮음(공간의 낭비가 큼)</li>\n</ul>\n<h3 id=\"multi-programming\" style=\"position:relative;\"><a href=\"#multi-programming\" aria-label=\"multi programming permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Multi Programming</h3>\n<p>Uni Programming은 위같은 문제점들과 다중 사용자 니즈에 맞춰 점차 사라졌습니다.</p>\n<p>이후 여러 프로세스를 메모리에 할당할 수 있는 방법인 Multi Programming이 등장하고, CPU를 시분할 방식으로 사용해 다양한 프로세스를 동시에 사용하는것처럼 동작할 수 있게 되었습니다.</p>\n<p><strong>Multi Programming: Fixed Allocation (고정 할당 방법)</strong></p>\n<p>여러 프로세스가 사용할 수 있는 공간을 고정된 크기로 나누는 방법입니다.</p>\n<ul>\n<li><strong>내부 단편화가 발생합니다</strong>:  5kb만큼 필요한 프로세스가 있더라도 고정된 크기(예를 들어 10MB)를 할당받아, 파티션 내부에서 낭비하는공간이 발생합니다.</li>\n<li>프로세스가 고정 파티션 크기보다 클 수 있습니다.</li>\n</ul>\n<p><strong>Multi Programming: Variable Allocation (가변 할당 방법)</strong></p>\n<p>프로세스가 사용할 공간을 프로세스의 크기에 맞춰 나누는 방법입니다.  프로세스가 시작할때, 종료할때 Allocation Table을 변경하면서 파티션을 관리합니다.</p>\n<p><strong>가변 할당 정책</strong>에 따라 운영체제에서 관리하는 가용공간 리스트를 탐색해 메모리를 할당합니다.</p>\n<p>Best-fit: 가용 공간을 탐색 후 프로세스가 필요한메모리와 가장 차이가 적은 파티션에 할당</p>\n<p>First-fit: 메모리 크기만큼 할당할 수 있는 첫 파티션에 할당</p>\n<p>Worst-fit: 메모리 크기를 할당할 수 있는 가장 큰 파티션에 할당</p>\n<p>속도: First > Best, Worst</p>\n<p>공간효율: Best > First, Worst</p>\n<p>Fixed Allocation의 문제점들을 다소 극복했지만 아직 문제점이 남아있습니다.</p>\n<ul>\n<li><strong>외부 단편화가 발생합니다:</strong> 크기가 작은 프로세스가 종료해 메모리에서 해제되면 사용중인 파티션 사이에 사용하지 못하는 공간이 발생</li>\n<li>Allocation Table을 순회해야하는 오버헤드 발생</li>\n</ul>\n<h3 id=\"연속-메모리할당-방법의-문제점\" style=\"position:relative;\"><a href=\"#%EC%97%B0%EC%86%8D-%EB%A9%94%EB%AA%A8%EB%A6%AC%ED%95%A0%EB%8B%B9-%EB%B0%A9%EB%B2%95%EC%9D%98-%EB%AC%B8%EC%A0%9C%EC%A0%90\" aria-label=\"연속 메모리할당 방법의 문제점 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>연속 메모리할당 방법의 문제점</h3>\n<p>앞서 설명한 여러 <strong>연속 메모리 할당 방법들에는 공통적인 문제</strong>가 남아있습니다.</p>\n<ul>\n<li>프로세스가 필요한 메모리를 시작하는 시점에 알 수 없음</li>\n<li>프로세스가 새로 시작할 때 프로그램 데이터를 모두 디스크 → 메모리로 데이터를 옮겨야하는데, 이는 상당히 느린 방법</li>\n<li>내/외부 단편화로 인한 메모리공간 낭비가 어떤 방식으로든 남아있음</li>\n</ul>\n<p>이런 문제점들은 이후 페이징, 세그멘테이션을 공부하며 해결할 수 있습니다.</p>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p><a href=\"%5Bhttps://pages.cs.wisc.edu/~remzi/OSTEP/%5D(https://pages.cs.wisc.edu/~remzi/OSTEP/)\">OSTEP: Operating Systems: Three Easy Pieces</a></p>\n<p>[<strong>HPC Lab. KOREATECH, OS Lecture]<a href=\"https://www.youtube.com/watch?v=r1JVA7yOPAM&#x26;\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">(</a></strong><a href=\"https://www.youtube.com/playlist?list=PLBrGAFAIyf5rby7QylRc6JxU5lzQ9c4tN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.youtube.com/watch?v=es3WGii_7mc&#x26;list=PLBrGAFAIyf5rby7QylRc6JxU5lzQ9c4tN</a><strong>)</strong></p>","id":"79df45f7-38b0-5842-9e5b-c64401618056","fields":{"slug":"연속메모리-할당과-주소-공간"},"frontmatter":{"date":"2023-02-20","title":"연속메모리 할당과 주소 공간","category":"tech","tags":["운영체제","운영체제 스터디"],"banner":null},"timeToRead":2},{"excerpt":"현대에는 4 또는…","html":"<p>현대에는 4 또는 8코어 등 멀티코어를 통해 성능을 극대화하는 시도들이 성공을 거두면서, 다중 코어 시스템을 쉽게 찾아볼 수 있게 되었습니다.</p>\n<p>명령어를 실행하는 코어가 여러개라니 다다익선이라고 생각할 수 있습니다.</p>\n<ul>\n<li>\n<p>병렬화의 한계: 병렬화 할 수 있는 작업이 한정적이고, 많은 수의 작업을 병렬화하더라도 이를 병합하는데 오버헤드가 발생합니다.</p>\n<p><strong>하지만  병렬화에도 한계가 존재합니다. (컴퓨터구조론에서 자세히 다룹니다)</strong></p>\n</li>\n<li>\n<p>캐시/메모리 병목: 공유자원인 캐시 및 메모리의 특정 자원에 여러 코어가 접근하면 Lock등을 사용해 동시성을 확보해야 합니다.</p>\n<p>Lock에 의해 프로세서가 대기하는것을 Blocking이라고 하는데, 코어 수가 높을수록 같은 자원에 접근할 확률이 높아져 Blocking시간이 길어집니다.</p>\n<p>잘못된 동기화 알고리즘을 사용할 경우 성능이 급격하게 안좋아질 수 있습니다.</p>\n</li>\n</ul>\n<h2 id=\"멀티프로세서의-문제점\" style=\"position:relative;\"><a href=\"#%EB%A9%80%ED%8B%B0%ED%94%84%EB%A1%9C%EC%84%B8%EC%84%9C%EC%9D%98-%EB%AC%B8%EC%A0%9C%EC%A0%90\" aria-label=\"멀티프로세서의 문제점 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>멀티프로세서의 문제점</h2>\n<p>앞서 언급한 병렬화의 한계에서는 코어가 늘어날수록 성능이 비례하지 않는 이유에 관한 내용이었습니다.</p>\n<p>아래의 멀티프로세서 구조를 참고해 어떤 치명적인 문제가 있을지 알아보겠습니다.</p>\n<p><img src=\"https://user-images.githubusercontent.com/30853787/226093159-1d3965f3-a3fd-4b46-95b5-4b02559d09a0.png\" alt=\"1\"></p>\n<ul>\n<li>일반적인 Personal Computer에서는 L3캐시까지 사용되는게 일반적입니다.</li>\n<li>L2캐시까지만 존재하는 경우도 있으며 Intel칩셋 역시 몇몇 모델에 공유 캐시가 존재함을 확인할 수 있습니다.\n<ul>\n<li>(<a href=\"https://en.wikipedia.org/wiki/Intel_Core\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://en.wikipedia.org/wiki/Intel_Core</a>)</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"캐시-일관성-문제-cache-coherance-problem\" style=\"position:relative;\"><a href=\"#%EC%BA%90%EC%8B%9C-%EC%9D%BC%EA%B4%80%EC%84%B1-%EB%AC%B8%EC%A0%9C-cache-coherance-problem\" aria-label=\"캐시 일관성 문제 cache coherance problem permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>캐시 일관성 문제 (Cache coherance problem)</strong></h3>\n<p>캐시는  메인 메모리에서 자주 사용되는 정보를 저장해놓는 데이터의 복사본입니다.</p>\n<p>각각의 코어는 근처에 L1, L2코어가 있고 L3 코어부터는 메모리 주변에 위치해있습니다.</p>\n<p><strong>프로세서에서 데이터 조회</strong>는 L1캐시에서 데이터를 조회하고 존재하지 않을 시 L2 ~ Main Memory까지 조회하는 방법을 사용하고,</p>\n<p><strong>프로세서가 데이터를 저장</strong>할때는 위치가 가까운 L1, L2캐시에는 쉽게 데이터를 저장할 수 있지만 L3캐시나 메인 메모리에는 쓰기 비용이 많이 들어 한번에 작성합니다.</p>\n<p>만약 Core 1이 A라는 데이터를 A’로 수정했다면, L1,L2캐시에 반영될 것입니다. 그런데 이 때 Core2가 A의 위치에서 데이터를 가져오고자 한다면 수정된 A’이 아니라 이전 데이터인 A를 가져오게 됩니다.</p>\n<p>이를 <strong>캐시 일관성 문제</strong> 라고 합니다.</p>\n<p>이는 데이터 버스를 모니터링하는 MESI등의 프로토콜을 사용해 캐시 접근을 감시해 캐시 불일치를 잡아내고, 무효화(캐시에서 삭제)하거나 원본 캐시 플러시를 통해 해결합니다.</p>\n<p>이를 <strong>버스 스누핑이라고 합니다. (</strong><a href=\"https://en.wikipedia.org/wiki/Bus_snooping\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://en.wikipedia.org/wiki/Bus_snooping</a>) ****</p>\n<h3 id=\"원자성-보장-문제-atomicity-problem\" style=\"position:relative;\"><a href=\"#%EC%9B%90%EC%9E%90%EC%84%B1-%EB%B3%B4%EC%9E%A5-%EB%AC%B8%EC%A0%9C-atomicity-problem\" aria-label=\"원자성 보장 문제 atomicity problem permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>원자성 보장 문제 (Atomicity problem)</h3>\n<p>(캐시 일관성 문제가 해결되어, 캐시에 있는 정보는 믿을 수 있다고 가정합니다)</p>\n<p>CPU는 병렬적으로 실행되므로 같은 데이터에 대해 접근하는 스레드가 여러개일 수 있습니다.</p>\n<p>이로 인한 동시성 문제가 생길 수 있고, 이는 운영체제 레벨에서 Lock을 제공해야 해결할 수 있습니다.</p>\n<p>또한 앞서 말했듯 프로세서 수가 많아질수록 Lock의 Blocking으로 인한 오버헤드가 발생합니다.</p>\n<h3 id=\"캐시-친화성-문제-cache-affinity-problem\" style=\"position:relative;\"><a href=\"#%EC%BA%90%EC%8B%9C-%EC%B9%9C%ED%99%94%EC%84%B1-%EB%AC%B8%EC%A0%9C-cache-affinity-problem\" aria-label=\"캐시 친화성 문제 cache affinity problem permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>캐시 친화성 문제 (Cache affinity problem)</h3>\n<p>캐시의 기본 원리는 “더 자주 사용하는 소수의 데이터를 더 가까이 둔다” 입니다.</p>\n<p>또한  다수의 일반적인 프로그램은 어떤 경향성을 보입니다.</p>\n<ul>\n<li><strong>시간 지역성: 최근에 사용한 데이터를 다시 참조할 가능성이 높음(예시:반복문에서 동일변수 참조)</strong></li>\n<li><strong>공간 지역성: 최근에 사용한 데이터의 주변에 있는 데이터를 참조할 가능성이 높음(예시: 배열 순회)</strong></li>\n</ul>\n<p>위 가정들 때문에 캐시에는 다음에 참조할 데이터가 존재할 확률이 높은것이죠.</p>\n<p>만약 다수의 프로세서(CPU)에게 레디 큐에 있는 프로세스를 무작위로 실행한다면,</p>\n<p>A프로세스를 실행하기 위해 로드한 캐시들이 B 프로세스를 사용한다면 또다시 B 프로세스를 위한 캐시들을 로드해야 할 것이고, 심각한 성능 하락으로 이어집니다. (이를 Cache warm up이라고 합니다)</p>\n<h2 id=\"멀티프로세서에서의-스케줄링\" style=\"position:relative;\"><a href=\"#%EB%A9%80%ED%8B%B0%ED%94%84%EB%A1%9C%EC%84%B8%EC%84%9C%EC%97%90%EC%84%9C%EC%9D%98-%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81\" aria-label=\"멀티프로세서에서의 스케줄링 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>멀티프로세서에서의 스케줄링</h2>\n<h3 id=\"단일-큐-멀티프로세서-스케줄링-sqms\" style=\"position:relative;\"><a href=\"#%EB%8B%A8%EC%9D%BC-%ED%81%90-%EB%A9%80%ED%8B%B0%ED%94%84%EB%A1%9C%EC%84%B8%EC%84%9C-%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81-sqms\" aria-label=\"단일 큐 멀티프로세서 스케줄링 sqms permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>단일 큐 멀티프로세서 스케줄링 SQMS</h3>\n<p>단일 큐 멀티프로세서 스케줄링 SQMS ( Single Queue Multiprocessor Scheduling )은 이름 그대로 <strong>프로세서가 여러개더라도 하나의 스케줄링 큐를 사용하는 것입니다.</strong></p>\n<p>이는 간단하게 생각해도 여러가지 문제가 있습니다.</p>\n<ol>\n<li>Ready Queue도 공유자원입니다. 여러 프로세스가 동시에 하나의 프로세스를 실행하고자 큐에서 빼면, 실제로는 하나의 프로세서만 동작하게 되기에, <strong>락을 걸어서 Queue를 임계구역으로 설정</strong>해야 합니다.</li>\n<li>Ready Queue를 임계구역으로 설정해 Lock을 적용하면, 심각한 성능 저하가 발생합니다.</li>\n<li>캐시에 친화적이지 않습니다.</li>\n</ol>\n<h3 id=\"멀티-큐-스케줄링-mqms\" style=\"position:relative;\"><a href=\"#%EB%A9%80%ED%8B%B0-%ED%81%90-%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81-mqms\" aria-label=\"멀티 큐 스케줄링 mqms permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>멀티 큐 스케줄링 MQMS</h3>\n<p>멀티 큐 스케줄링 MQMS (Multi-Queue Multiprocessor Scheduling)은 <strong>CPU별로 Ready Queue를 두고, 프로세서별 스케줄링 큐에 작업을 균등하게 할당하는 방식입니다.</strong></p>\n<p><img src=\"https://user-images.githubusercontent.com/30853787/226093162-d1eed259-c233-4529-9df5-c59d8b7b740a.png\" alt=\"2\"></p>\n<p><strong>해결된 문제</strong></p>\n<ul>\n<li>SQMS에서는 Ready Queue가 공유자원이었는데, 이제 프로세서별로 하나의 큐가 있으므로 Lock에 의한 오버헤드가 사라졌습니다.</li>\n<li>프로세서는 무작위의 프로세스를 실행하지 않고 특정 프로세스만을 실행하므로 캐시 친화성이 떨어지는 문제가 해결되었습니다.</li>\n</ul>\n<p><strong>새로운 문제점과 해결방법</strong></p>\n<p><strong>워크로드 불균형</strong>: 만약 CPU 1에 할당된 프로세스 A가 엄청나게 오래 동작한다면? CPU1의 Ready Queue에는 많은 프로세스가 쌓이는 반면, CPU0은 큐에 프로세스가 없어 놀아버리는 사태가 발생합니다.</p>\n<h3 id=\"질문-목록\" style=\"position:relative;\"><a href=\"#%EC%A7%88%EB%AC%B8-%EB%AA%A9%EB%A1%9D\" aria-label=\"질문 목록 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>질문 목록</h3>\n<p>(진짜 질문) 워크로드 불균형 문제는 작업 할당 시 할당된 작업이 적은 프로세서에게 할당하면 해결되는것 아닌가?</p>\n<p>(진짜질문) 데드락을 발생시키지 않는 Locking 방법이 있는지? ( 아직 진도 안나갔지만, Spin Lock이 멀티프로세서에서 어떻게 동작할지 생각해오기)</p>\n<p>싱글코어에서는 운영체제가 동기화를 위해 락을 사용하지 않아도 될까?</p>\n<ul>\n<li>\n<p>정답</p>\n<p>싱글코어 컨텍스트 스위칭 역시 인터럽트 기반으로 동작하고, 인터럽트는 실행중이던 마이크로 오퍼레이션까지만 실행한다. 마이크로 오퍼레이션이란, CPU Instruction이 포함하는 Fetch Decode Excecute Memory WriteBack보다 더 작은 단위이다.</p>\n<p><a href=\"https://ko.wikipedia.org/wiki/%EB%A7%88%EC%9D%B4%ED%81%AC%EB%A1%9C_%EC%98%A4%ED%8D%BC%EB%A0%88%EC%9D%B4%EC%85%98\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://ko.wikipedia.org/wiki/마이크로_오퍼레이션</a></p>\n<p>→ 당연히 동시성을 보장해주지 않는다</p>\n</li>\n</ul>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p><a href=\"%5Bhttps://pages.cs.wisc.edu/~remzi/OSTEP/%5D(https://pages.cs.wisc.edu/~remzi/OSTEP/)\">OSTEP: Operating Systems: Three Easy Pieces</a></p>\n<p>[<strong>HPC Lab. KOREATECH, OS Lecture CH.5 Lecture 5. Process Scheduling]<a href=\"https://www.youtube.com/watch?v=r1JVA7yOPAM&#x26;\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">(**https://www.youtube.com/watch?v=jZuTw2tRT7w</a> <a href=\"https://www.youtube.com/watch?v=r1JVA7yOPAM&#x26;list=PLBrGAFAIyf5rby7QylRc6JxU5lzQ9c4tN&#x26;index=9\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"></a></strong>)**</p>\n<h3 id=\"sub-reference\" style=\"position:relative;\"><a href=\"#sub-reference\" aria-label=\"sub reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Sub Reference</h3>\n<p>TLB <a href=\"https://wpaud16.tistory.com/304\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://wpaud16.tistory.com/304</a></p>","id":"71591062-f239-5250-88e1-ff83b143ce00","fields":{"slug":"멀티프로세서-스케줄링과-동기화"},"frontmatter":{"date":"2023-02-15","title":"멀티프로세서 스케줄링과 동기화","category":"tech","tags":["운영체제","운영체제 스터디"],"banner":null},"timeToRead":3},{"excerpt":"개요 스케쥴링이란, CPU 자원을 계획에 따라 여러 프로세스에게 나누어주는 방법입니다. 여러가지 스케쥴링 항목에 대해 공부하기 전에, 왜 스케쥴러를 사용하는지에 대해 생각하면 더 편하게 이해할 수 있습니다. 앞서 공부한 프로세스의 상태 중, CPU를 할당받기 위해 Ready → Running 상태의 전이를 담당하는것이 스케쥴링입니다. 그래서 기본적으로 Ready Queue…","html":"<h3 id=\"개요\" style=\"position:relative;\"><a href=\"#%EA%B0%9C%EC%9A%94\" aria-label=\"개요 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>개요</h3>\n<p>스케쥴링이란, CPU 자원을 계획에 따라 여러 프로세스에게 나누어주는 방법입니다. 여러가지 스케쥴링 항목에 대해 공부하기 전에, 왜 스케쥴러를 사용하는지에 대해 생각하면 더 편하게 이해할 수 있습니다.</p>\n<p>앞서 공부한 프로세스의 상태 중, CPU를 할당받기 위해 <strong>Ready → Running</strong> 상태의 전이를 담당하는것이 스케쥴링입니다. 그래서 기본적으로 Ready Queue에 여러 프로세스가 대기중이고, 스케쥴링 정책은 이 큐에 있는 프로세스를 어떻게 실행할지에 대한 이야기라고 생각하면 됩니다.</p>\n<p>운영체제는 목적에 따라 여러 종류가 있습니다. 대화형 시스템, 배치 시스템 등..</p>\n<p>대화형 시스템에서는 CPU의 활용성이 조금 떨어지더라도 유저의 요청에 <strong>반응하는 시간</strong>이 빨라야하고,</p>\n<p>대규모 데이터를 처리하는 배치 시스템에서는 응답시간보다는 <strong>처리량</strong>이 우선일 것입니다.</p>\n<p>응답시간, 처리량같이 운영체제별로 스케쥴링의 목적이 있고, 이외에도 공평성, 무한대기 방지, 활용률 등 다양한 평가항목이 있어, 스케쥴링 알고리즘을 선택할 때 고려해야 합니다.</p>\n<h3 id=\"스케쥴링-성능평가-용어-정리\" style=\"position:relative;\"><a href=\"#%EC%8A%A4%EC%BC%80%EC%A5%B4%EB%A7%81-%EC%84%B1%EB%8A%A5%ED%8F%89%EA%B0%80-%EC%9A%A9%EC%96%B4-%EC%A0%95%EB%A6%AC\" aria-label=\"스케쥴링 성능평가 용어 정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>스케쥴링 성능평가 용어 정리</h3>\n<p><img src=\"https://user-images.githubusercontent.com/30853787/226093035-ef33201e-3ca0-4f2b-b94a-d3414eb4bc3c.png\" alt=\"1\"></p>\n<ul>\n<li><strong>Response Time, 응답시간 / T(response) - T(arrival) :</strong> 레디큐에 도착해 처음으로 스케쥴될때까지 걸린 시간</li>\n<li><strong>Waiting Time, 대기시간 / T(sum of waiting) :</strong> 레디큐에 도착해 running이 되기까지 걸린 시간의 합\n<ul>\n<li><strong>응답시간은 Ready Queue도착에서 첫 스케쥴까지 걸린시간, 대기시간은 프로세스가 종료되기까지 Ready Queue에 있는 시간의 총 합을 의미합니다.</strong></li>\n</ul>\n</li>\n<li><strong>Burst Time, 실행시간 / T(completion) - T(start)</strong> : CPU를 할당받아 실행한 시간</li>\n<li><strong>Turnaround Time, 반환시간 / T(completion)- T(arrival) :</strong> 레디큐에 도착해 작업을 완료하기까지 걸린 시간</li>\n</ul>\n<p>위와 같은 기준들로 <strong>“성능”</strong> 을 평가할 수 있으며, 여러 프로세스가 번갈아가며 실행하므로, 일반적으로는 반환시간 또는 대기시간의 <strong>평균</strong>을통해 스케쥴링의 적합성을 판단합니다.</p>\n<p>또한, <strong>공정성</strong>도 중요한 평가요소 중 하나입니다. 스케쥴링 방법을 공부하다보면 알겠지만, 일반적인 경우 처리량과 공정성은 등가교환 관계이기 때문에 주의해야 합니다.</p>\n<h2 id=\"스케쥴링-방법들\" style=\"position:relative;\"><a href=\"#%EC%8A%A4%EC%BC%80%EC%A5%B4%EB%A7%81-%EB%B0%A9%EB%B2%95%EB%93%A4\" aria-label=\"스케쥴링 방법들 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>스케쥴링 방법들</h2>\n<p><strong>먼저 알고가야 할것. 선점형 vs 비선점형</strong></p>\n<p>유저 이벤트로 인한 프로세스 시작이나 I/O 종료 인터럽트로 인해 Ready Queue에 다양한 프로세스들이 들어옵니다.</p>\n<p>이 때, 새로운 프로세스가 즉시 CPU 할당을 받아서(뺏어와서) 실행할 수 있는 스케쥴링 종류를 선점형(Preemitive), 그렇지 않고 해당 프로세스의 Burst Time이 끝나는것을 기다려하는 스케쥴링 종류를 비선점형(Non-Preemitive)라고 합니다</p>\n<h3 id=\"fcfs-또는-fifo-알고리즘\" style=\"position:relative;\"><a href=\"#fcfs-%EB%98%90%EB%8A%94-fifo-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98\" aria-label=\"fcfs 또는 fifo 알고리즘 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>FCFS (또는 FIFO) 알고리즘</h3>\n<p>First Come First Service (First In First Out) 즉, 선착순/선입선출 알고리즘입니다. Ready Queue에 들어온 순서대로 CPU를 할당해줍니다. 비선점형 스케쥴링 알고리즘입니다</p>\n<p>일상생활에서는 공평하게 처리하기 위해 자주 사용되는 알고리즘입니다. 매우 간단하고 얼핏보면 공평해보이지만, 아래의 경우를 확인해보면 비효율적인 알고리즘인걸 알 수 있습니다.</p>\n<table>\n<thead>\n<tr>\n<th>프로세스</th>\n<th>A</th>\n<th>B</th>\n<th>C</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>실행시간</td>\n<td>60</td>\n<td>10</td>\n<td>10</td>\n</tr>\n<tr>\n<td>도착시간</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n</tr>\n<tr>\n<td>반환시간</td>\n<td>60</td>\n<td>70</td>\n<td>80</td>\n</tr>\n</tbody>\n</table>\n<p>만약 A,B,C가 거의 동시에 도착해 A,B,C순으로 처리한다고 할 때, 평균 반환시간을 체크해보면</p>\n<p><strong>Average Turnaround Time : (60 + 70 + 80) /3  = 70</strong>  으로, 굉장히 비효율적입니다.</p>\n<p>라면 하나를 사려고 계산대에 줄을 섰는데, 앞에서 엄청 많은 물건을 계산하고있는 상황을 생각해보면 편할겁니다.</p>\n<p>이처럼 짧은 시간동안 자원을 사용하는 프로세스가 오랜 시간동안 할당을 기다려야 하는 현상을 <strong>Convoy Effect</strong>라고 합니다.</p>\n<h3 id=\"sjf-알고리즘--non-preemitive\" style=\"position:relative;\"><a href=\"#sjf-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98--non-preemitive\" aria-label=\"sjf 알고리즘  non preemitive permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>SJF 알고리즘 / Non Preemitive</h3>\n<p>Shortest Job First 즉, 짧은 작업을 우선해서 처리하는 알고리즘입니다.</p>\n<p>비선점형으로 동작하는 경우부터 살펴보겠습니다.</p>\n<p>FCFS에서는 실행시간이 짧은 프로세스가 앞서 실행되는 긴 프로세스의 실행을 기다려하는 Convoy Effect가 문제였습니다.</p>\n<p>SJF에서는 레디큐에 있는 Job들 중, <strong>짧은것을 우선적으로 실행</strong>합니다.</p>\n<p>마트에서 줄이 짧은 사람을 먼저 계산하게 해줍니다!</p>\n<table>\n<thead>\n<tr>\n<th>프로세스</th>\n<th>B</th>\n<th>C</th>\n<th>A</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>실행시간</td>\n<td>10</td>\n<td>10</td>\n<td>60</td>\n</tr>\n<tr>\n<td>도착시간</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n</tr>\n<tr>\n<td>반환시간</td>\n<td>10</td>\n<td>20</td>\n<td>80</td>\n</tr>\n</tbody>\n</table>\n<p>앞선 FIFO의 예시입니다. A,B,C가 동시에 도착하면  B,C가 먼저 스케쥴되어 반환시간을 계산하면</p>\n<p><strong>Average Turnaround Time :(10+20+80) / 3  = 36.6</strong> , 반환시간이 절반정도로 줄어든걸 확인할 수 있습니다.</p>\n<p><strong>SJF 문제점</strong></p>\n<p>비선점형이라는 것을 고려하면 아래와 같이 동작합니다.</p>\n<p><img src=\"https://user-images.githubusercontent.com/30853787/226093037-73ffbddf-8875-4583-81d7-03c9aaf5c377.png\" alt=\"2\"></p>\n<p>B,C는 time:10에 도착했으므로 이미 실행중인 A를 종료시키지 못하고, time:60까지 기다립니다. 이 경우 반환시간은</p>\n<table>\n<thead>\n<tr>\n<th>프로세스</th>\n<th>A</th>\n<th>B</th>\n<th>C</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>실행시간</td>\n<td>60</td>\n<td>10</td>\n<td>10</td>\n</tr>\n<tr>\n<td>도착시간</td>\n<td>0</td>\n<td>10</td>\n<td>10</td>\n</tr>\n<tr>\n<td>반환시간</td>\n<td>60</td>\n<td>60</td>\n<td>70</td>\n</tr>\n</tbody>\n</table>\n<p><strong>Average TurnAround Time =  (60+60+70)/3 = 63.3으로, 앞선 FSFS와 큰 차이가 없습니다.</strong></p>\n<h3 id=\"srtf또는-sctf-알고리즘\" style=\"position:relative;\"><a href=\"#srtf%EB%98%90%EB%8A%94-sctf-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98\" aria-label=\"srtf또는 sctf 알고리즘 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>SRTF(또는 SCTF) 알고리즘</h3>\n<p>SRTF: Shortes Remaining Time First (= SCTF: Shortest Time to Completion First)는 <strong>최소 잔여시간이 적은 프로세스를 선점형으로 실행</strong>하는 알고리즘입니다.</p>\n<p><img src=\"https://user-images.githubusercontent.com/30853787/226093039-804b66a5-2dee-48b4-985d-ad66c1171e54.png\" alt=\"3\"></p>\n<p>앞선 SJF와 비교해보면 B,C가 도착한 time: 10시점에 <strong>더 짧게 남은 잡을 계산해 CPU를 선점한다는걸 확인할 수 있습니다</strong>.</p>\n<p>이 경우 반환시간을 계산해보겠습니다.</p>\n<table>\n<thead>\n<tr>\n<th>프로세스</th>\n<th>A</th>\n<th>B</th>\n<th>C</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>실행시간</td>\n<td>60</td>\n<td>10</td>\n<td>10</td>\n</tr>\n<tr>\n<td>도착시간</td>\n<td>0</td>\n<td>10</td>\n<td>10</td>\n</tr>\n<tr>\n<td>반환시간</td>\n<td>80</td>\n<td>20</td>\n<td>30</td>\n</tr>\n</tbody>\n</table>\n<p><strong>Average TurnAround Time =  (80+20+30)/3 = 43.3으로, B,C가 늦게 도착한 경우에 평균 반환시간을 개선할 수 있었습니다.</strong></p>\n<p><strong>SRTF 문제점</strong></p>\n<p><strong>SRTF에도 공정성, 응답시간 측면에서 문제점이 있습니다.</strong></p>\n<p>만약 실행시간이 10인 프로세스가 레디 큐에 계속 들어온다면, 남은 실행시간이 20인 프로세스는 CPU를 할당받지 못하는 상태가 되고(Starvation), 응답시간이 계속 늘어납니다.</p>\n<p>또한 <strong>운영체제는 Ready Queue에 있는 프로세스의 실행시간을 알지 못합니다.</strong></p>\n<h3 id=\"round-robin-알고리즘\" style=\"position:relative;\"><a href=\"#round-robin-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98\" aria-label=\"round robin 알고리즘 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Round Robin 알고리즘</h3>\n<p>Round Robin알고리즘은 일정 Time Quantum을 기점으로 Ready Queue에 있는 모든 프로세스들에게 공정하게 실행시간을 배분해주는 알고리즘을 말합니다.</p>\n<p><img src=\"https://user-images.githubusercontent.com/30853787/226093040-38af8a4a-e01d-4f0b-a85e-62aa5b91541e.png\" alt=\"4\"></p>\n<p><strong>문제점 해결</strong></p>\n<p>해당 방식으로 실행하면 SRTF에서 실행시간이 많이 남은 프로세스가 CPU를 계속 할당받지 못하는 공평성 문제가 해결되고, 응답시간이 대폭 개선됩니다.</p>\n<p><strong>특징</strong></p>\n<p>대화형 시스템에 적합합니다.</p>\n<p>새로 Ready상태가 되거나 실행시간을 마친 Job은  Ready Queue의 <strong>맨 뒤로</strong> 갑니다.</p>\n<ul>\n<li>A가 실행되고 나서 C가 Ready상태가 되었다면,  …. → A → C 순으로 실행됩니다.</li>\n<li>반대로 C가 Ready Queue에 도착하고 A의 실행이 끝난다면, …→ C → A 순으로 실행됩니다.</li>\n</ul>\n<p><strong>새로운 문제점</strong></p>\n<p>평균 반환시간 관점으로 보았을 때, 최악의 알고리즘입니다.</p>\n<p>또한 적절한 Time Quantum을 설정해야합니다. 잦은 Context Switch는 성능 저하를 불러옵니다.</p>\n<h2 id=\"정리\" style=\"position:relative;\"><a href=\"#%EC%A0%95%EB%A6%AC\" aria-label=\"정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>정리</h2>\n<p>반환시간, 응답시간, 공평성은 등가교환 관계입니다.</p>\n<p>SJF, SRTF는 반환시간이 개선되지만 응답시간, 공정성 측면에서는 비효율적이고</p>\n<p>RR의 경우 응답시간과 공평성은 해결했지만 반환시간이 비효율적입니다.</p>\n<p>뒤이어 배울 MLFQ등을 통해 각각의 장점을 절충하는 스케쥴러의 동작을 공부해보겠습니다.</p>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p><a href=\"%5Bhttps://pages.cs.wisc.edu/~remzi/OSTEP/%5D(https://pages.cs.wisc.edu/~remzi/OSTEP/)\">OSTEP: Operating Systems: Three Easy Pieces</a></p>\n<p>[<strong>HPC Lab. KOREATECH, OS Lecture CH.5 Lecture 5. Process Scheduling]<a href=\"https://www.youtube.com/watch?v=r1JVA7yOPAM&#x26;\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">(**https://www.youtube.com/watch?v=jZuTw2tRT7w</a> <a href=\"https://www.youtube.com/watch?v=r1JVA7yOPAM&#x26;list=PLBrGAFAIyf5rby7QylRc6JxU5lzQ9c4tN&#x26;index=9\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"></a></strong>)**</p>","id":"90477195-e249-580a-9f20-cf0887f0663b","fields":{"slug":"기본-cpu-스케쥴링-fcfs-sjf-srtf-rr"},"frontmatter":{"date":"2023-02-14","title":"기본 CPU 스케쥴링 [ FCFS, SJF, SRTF, RR]","category":"tech","tags":["운영체제","운영체제 스터디"],"banner":null},"timeToRead":3},{"excerpt":"OSTEP에서 본문에 해당하는 챕터 제목이 “Limited Directed Execution: 제한된 직접 실행 원리” 입니다. 책에서는 인터럽트의 한 종류인 trap에 대해서만 다루지만, 인터럽트에 대해 포괄적으로 알기 위해 관련내용도 정리했습니다. 제한된 직접실행 개요 먼저 Limited가 없는 직접 실행이라는 부분에 대해 알아보자면 , 운영체제가 프로그램의 실행에 관여하지 않고 CPU…","html":"<p>OSTEP에서 본문에 해당하는 챕터 제목이 “Limited Directed Execution: 제한된 직접 실행 원리” 입니다.</p>\n<p>책에서는 인터럽트의 한 종류인 trap에 대해서만 다루지만, 인터럽트에 대해 포괄적으로 알기 위해 관련내용도 정리했습니다.</p>\n<h2 id=\"제한된-직접실행-개요\" style=\"position:relative;\"><a href=\"#%EC%A0%9C%ED%95%9C%EB%90%9C-%EC%A7%81%EC%A0%91%EC%8B%A4%ED%96%89-%EA%B0%9C%EC%9A%94\" aria-label=\"제한된 직접실행 개요 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>제한된 직접실행 개요</h2>\n<p>먼저 Limited가 없는 직접 실행이라는 부분에 대해 알아보자면 , 운영체제가 프로그램의 실행에 관여하지 않고 CPU는 사용자 코드에서 진입점을 찾아 직접 실행함을 의미합니다. 이 경우 몇가지 문제가 발생합니다.</p>\n<p>프로세서(CPU)가 프로세스로 자원을 나눠줄 때 고려해야할 부분으로 크게 세 가지 중요한 요소가 있습니다.</p>\n<ol>\n<li><strong>제어권</strong>: 운영체제가 <strong>CPU 및 자원에 대한 제어권을 가진 상태로 프로세스를 실행</strong>해야 합니다. 제어권을 상실할 경우 프로세스가 자원을 무기한 점유하는 상황이 발생할 수도 있기 때문이죠.</li>\n<li><strong>성능:</strong> CPU앞서 말했듯 CPU는 초당 처리속도가 다른 하드웨어 기기에 비해 월등히 빠릅니다. 메모리 또는 하드디스크에서 데이터를 가져오는동안 CPU는 정말 많은 시간을 기다려야하겠죠. <strong>운영체제가 이런 I/O작업을 하는 프로세스의 제어권을 뺏고 다른 프로세스를 실행해 CPU활용률을 극대화</strong>합니다.</li>\n<li><strong>자원 보호:</strong> 제한없이 실행되는 프로세스는 전체 디스크,메모리를 읽고 쓸 수 있으므로, 이 부분에 대한 제어가 꼭 필요하다 <strong>( System Call Interface를 통한 User/Kernal Mode 분기)</strong></li>\n</ol>\n<p>요약하자면, 다른 장치에 비해 빠른 CPU의 <strong>성능</strong>을 최대한 <strong>안전하게</strong> 활용하기 위해 운영체제가 CPU의 제어권을 갖는 개념을 Limited Directed Execution: 제한된 직접 실행이라고 합니다.</p>\n<p><strong>쉽게 말하자면</strong></p>\n<p>운영체제가 인터럽트를 통해 하드웨어 리소스에 대한 제어권을 가져올 수 있어야 “성능, 자원보호, 제어권 주도” 등의 이점을 가져올 수 있다는 이야기입니다.</p>\n<p>다른 장치에 비해 빠른 CPU의 <strong>성능</strong>을 최대한 <strong>안전하게</strong> 활용하기 위해 운영체제가 CPU의 제어권을 갖는 개념을 Limited Directed Execution: 제한된 직접 실행이라고 합니다.</p>\n<h3 id=\"인터럽트의-종류\" style=\"position:relative;\"><a href=\"#%EC%9D%B8%ED%84%B0%EB%9F%BD%ED%8A%B8%EC%9D%98-%EC%A2%85%EB%A5%98\" aria-label=\"인터럽트의 종류 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>인터럽트의 종류</h3>\n<p><strong>Hardware Inturrupt : 외부 기기 또는 사용자, 입/출력에 의한 불특정 시간에 발생해 Asynchronous Interrupt라고도 불립니다.</strong></p>\n<ul>\n<li>Clock Interrupt: 한 스레드가 프로세스를 과도하게 점유하는것을 막기 위해 지정된 시간마다 발생하는 인터럽트</li>\n<li>I/O Interrupt: 사용자의 입/출력(또는 예상치못한 외부 이벤트)에 의한 인터럽트</li>\n<li>Machine Check Interrupt: 기기 결함이 발견되었을 때 발생하는 인터럽트</li>\n</ul>\n<p><strong>Software Interrupt (or Trap, Synchronous Interrupt): SW의 예외 핸들링 또는 제어권을 얻기 위해 발생시키는 인터럽트입니다.</strong></p>\n<ul>\n<li>Supervisor Call(System Call Interrupt): 사용자 프로그램이 하드웨어 자원을 사용하기 위해 유저모드에서 커널모드로 들어갈 때 발생시키는 인터럽트.</li>\n<li>Program Check Interrupt: 0으로 나누기, 스택오버플로/언더플로같은 S.W Exception처리하는 인터럽트.</li>\n</ul>\n<h3 id=\"인터럽트의-실행과정\" style=\"position:relative;\"><a href=\"#%EC%9D%B8%ED%84%B0%EB%9F%BD%ED%8A%B8%EC%9D%98-%EC%8B%A4%ED%96%89%EA%B3%BC%EC%A0%95\" aria-label=\"인터럽트의 실행과정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>인터럽트의 실행과정</h3>\n<p>프로세스가 CPU의 제어권을 갖고있는 상태에서 제어권을 얻기 위해선 인터럽트를 통해 제어권을 뺏어와야 합니다.</p>\n<p>인터럽트 발생: MCU(또는 PIC)라는 장비에 IDT(인터럽트 종류, ISR위치, 우선순위)를 전달하면서 시작됩니다.</p>\n<p>→ <strong>(하드웨어)프로세스 중단</strong></p>\n<ul>\n<li>Context Saving 발생: CPU register를 <strong>커널 스택</strong>에 대피시킨다.</li>\n<li>커널모드로 이동.</li>\n</ul>\n<p>→ <strong>(운영체제)인터럽트 처리(Interrupt Handling)</strong></p>\n<ul>\n<li>인터럽트를 요청한 장치 또는 메모리 주소, 인터럽트의 원인을 확인하고 ISR 주소로 이동해 ISR을 실행한다.</li>\n</ul>\n<p><strong>인터럽트 서비스 루틴 실행</strong> : 예를들어 마우스로 음악 프로그램을 더블클릭 해 인터럽트가 발생했다면, 해당 프로그램을 프로세스 레디 큐에 등록하는 작업을 한다.</p>\n<p>→ <strong>(하드웨어)상태 복구: 커널 스택에 저장된 CPU레지스터들을 불러오고</strong>, 복구한 PC레지스터로 이동해 원래 프로세스 실행</p>\n<p>→ (프로그램): 복구한 PC레지스터부터 다시 실행하므로, 기존 실행시점에서 다시 동작합니다.</p>\n<h3 id=\"interrupt로-context-switch가일어나는-경우\" style=\"position:relative;\"><a href=\"#interrupt%EB%A1%9C-context-switch%EA%B0%80%EC%9D%BC%EC%96%B4%EB%82%98%EB%8A%94-%EA%B2%BD%EC%9A%B0\" aria-label=\"interrupt로 context switch가일어나는 경우 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Interrupt로 Context Switch가일어나는 경우</h3>\n<p>만약 Timer Interrupt가 발생하고 그로인해 ISR에서 스케쥴러로 분기 →  Process A의 버스트 시간이 끝나 Ready상태로 바꾸는 상황을 가정해보겠습니다.</p>\n<p>(아직 스케줄러에 대해 배우지 않았지만 참고로, 스케쥴러 알고리즘은 매 타임 퀀텀마다, I/O로 인한 블록마다 동작하도록 ISR에 정의되어있습니다.  새로운 프로세스가 등록될때에도 비교를 위해 동작합니다. )</p>\n<p><img src=\"https://user-images.githubusercontent.com/30853787/226093145-c874af7d-2608-4373-97ec-94798ef0ea46.png\" alt=\"Interrupt_And_ContextSwitch drawio\"></p>\n<p>인터럽트가 동작하는 구조는 같지만, 내부에서 동작하는 스케쥴링 처리로 인해 ISR이후 Process(j)로 실행됩니다.</p>\n<p><strong>(하드웨어)</strong></p>\n<ul>\n<li>Process(i)를 중단하고 Process(i)실행시점의 <strong>레지스터를 커널 스택으로 대피</strong>합니다.</li>\n<li>커널모드로 변경합니다.</li>\n</ul>\n<p><strong>(운영체제의 Timer Interrupt에 대한 ISR 동작)</strong></p>\n<ul>\n<li>커널 스택에 있는 Process(i)의 레지스터를 Process(i)의 PCB에 저장해줍니다.</li>\n<li>j의 PCB에 저장된 Process(j)의 레지스터를 커널스택으로 옮깁니다.</li>\n<li>j프로세스의 실행주소(PC)로 return from trap합니다.</li>\n</ul>\n<p><strong>(하드웨어)</strong></p>\n<ul>\n<li>Process(j)의 커널스택에 있는 레지스터를 CPU로 복구합니다.</li>\n<li>유저모드로 변경합니다.</li>\n</ul>\n<p><strong>(프로그램)</strong></p>\n<p>Process(j)를 실행</p>\n<h3 id=\"인터럽트의-우선순위\" style=\"position:relative;\"><a href=\"#%EC%9D%B8%ED%84%B0%EB%9F%BD%ED%8A%B8%EC%9D%98-%EC%9A%B0%EC%84%A0%EC%88%9C%EC%9C%84\" aria-label=\"인터럽트의 우선순위 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>인터럽트의 우선순위</h3>\n<p><strong>전원 이상(Power fail) > 기계 착오(Machine Check) > 외부 신호(External) > 입출력(I/O) > 명령어 잘못 > 프로그램 검사(Program Check) > SVC(SuperVisor Call)</strong></p>\n<p>만약 우선순위가 낮은 인터럽트를 수행하는 중에 우선순위가 높은 인터럽트가 발생하면 우선적으로 처리한 뒤 다시 낮은 순위의 ISR로 돌아가 처리합니다. (재귀적 우선순위 처리)</p>\n<h3 id=\"질문목록\" style=\"position:relative;\"><a href=\"#%EC%A7%88%EB%AC%B8%EB%AA%A9%EB%A1%9D\" aria-label=\"질문목록 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>질문목록</h3>\n<p>Interrupt, Trap, Exception의 차이를 시스템 관점에서</p>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p><a href=\"%5Bhttps://pages.cs.wisc.edu/~remzi/OSTEP/%5D(https://pages.cs.wisc.edu/~remzi/OSTEP/)\">OSTEP: Operating Systems: Three Easy Pieces</a></p>\n<p>[<strong>HPC Lab. KOREATECH, OS Lecture CH.4 Process Management](</strong><a href=\"https://www.youtube.com/watch?v=jZuTw2tRT7w\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.youtube.com/watch?v=jZuTw2tRT7w</a> <strong>)</strong></p>\n<p>(sub reference)</p>\n<p><a href=\"https://raisonde.tistory.com/entry/%EC%9D%B8%ED%84%B0%EB%9F%BD%ED%8A%B8Interrupt%EC%9D%98-%EA%B0%9C%EB%85%90%EA%B3%BC-%EC%A2%85%EB%A5%98\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://raisonde.tistory.com/entry/인터럽트Interrupt의-개념과-종류</a></p>\n<p><a href=\"https://justzino.tistory.com/4\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://justzino.tistory.com/4</a></p>\n<p><a href=\"https://wiki.osdev.org/Interrupt_Service_Routine\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://wiki.osdev.org/Interrupt_Service_Routine</a></p>\n<p>커널의 메모리구조 - <a href=\"https://kariskan.tistory.com/52\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://kariskan.tistory.com/52</a></p>","id":"d18acb80-a184-5ffd-a668-8349d3729d5f","fields":{"slug":"인터럽트와-제한된-직접-실행"},"frontmatter":{"date":"2023-02-14","title":"인터럽트와 제한된 직접 실행","category":"tech","tags":["운영체제","운영체제 스터디"],"banner":null},"timeToRead":3},{"excerpt":"프로세스의 개념 프로세스는 프로그램이 실행중인 상태 라고 정의합니다. 프로그램 자체는 디스크에 적재되어있는 상태로, 아무런 동작을 하지 않습니다. 프로그램이 메모리에 적재되고, CPU를 점유해 사용하는 주체를 “프로세스”라고 합니다. 조금 더 구체적으로는 아래와 같이 정의할 수 있습니다. 커널에 등록되고 커널의 관리 하에 있는 작업 → 프로세스 관리 블록(PCB)을 할당받은 프로그램 각종 자원을 요청하고 할당받을 수 있는 개체 CPU…","html":"<h3 id=\"프로세스의-개념\" style=\"position:relative;\"><a href=\"#%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EC%9D%98-%EA%B0%9C%EB%85%90\" aria-label=\"프로세스의 개념 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>프로세스의 개념</h3>\n<p>프로세스는 <strong>프로그램이 실행중인 상태 라고 정의합니다.</strong></p>\n<p>프로그램 자체는 디스크에 적재되어있는 상태로, 아무런 동작을 하지 않습니다. 프로그램이 메모리에 적재되고, CPU를 점유해 사용하는 주체를 “프로세스”라고 합니다.</p>\n<p>조금 더 구체적으로는 아래와 같이 정의할 수 있습니다.</p>\n<ul>\n<li>커널에 등록되고 커널의 관리 하에 있는 작업\n<ul>\n<li>→ <strong>프로세스 관리 블록(PCB)을 할당받은 프로그램</strong></li>\n</ul>\n</li>\n<li>각종 자원을 요청하고 할당받을 수 있는 개체</li>\n</ul>\n<h3 id=\"cpu-가상화와-프로세스--이건-cpu-가상화에-대한-설명\" style=\"position:relative;\"><a href=\"#cpu-%EA%B0%80%EC%83%81%ED%99%94%EC%99%80-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4--%EC%9D%B4%EA%B1%B4-cpu-%EA%B0%80%EC%83%81%ED%99%94%EC%97%90-%EB%8C%80%ED%95%9C-%EC%84%A4%EB%AA%85\" aria-label=\"cpu 가상화와 프로세스  이건 cpu 가상화에 대한 설명 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>CPU 가상화와 프로세스 → 이건 CPU 가상화에 대한 설명..</h3>\n<p>이런 “프로세스”는 실제 맥이나 윈도우같은 운영체제를 사용하면서 확인할 수 있는데, 한눈에 봐도 우리는 수십개의 프로그램을 동시에 사용할 수 있다는것을 알 수 있습니다. 마치 <strong>프로그램 하나가 CPU하나를 점유하듯</strong>, 노래를 들으며 워드를 사용하고, 백신 프로그램을 돌리는 등, 여러가지 작업을 한번에 수행 할 수 있죠.</p>\n<p>이것은 모두 “<strong>CPU 가상화</strong>”에 기초합니다. 운영체제는 “<strong>시분할</strong>”을 통해 여러 프로세스가 하나의 CPU를 나눠 사용할 수 있도록 합니다.</p>\n<p>또한 운영체제는 **과거 정보( 자주 실행된 프로그램, 실행된 프로그램의 유형)**과 **목적(처리량, 응답시간)**을 바탕으로 어떤 프로세스가 언제 CPU를 사용할지에 대한 “<strong>스케쥴링 정책</strong>”을 가지고있습니다.</p>\n<p>위같은 정책이나 시분할 기법은 프로세스가 온전히 하나의 CPU를 사용하는것”처럼” 하게 해주며, 이를 가상화 라고 부릅니다.</p>\n<h3 id=\"컴퓨터-구조와-프로세스\" style=\"position:relative;\"><a href=\"#%EC%BB%B4%ED%93%A8%ED%84%B0-%EA%B5%AC%EC%A1%B0%EC%99%80-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4\" aria-label=\"컴퓨터 구조와 프로세스 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>컴퓨터 구조와 프로세스</h3>\n<p>프로세스의 실행을 조금 더 가까이에서 살펴보겠습니다. 메모리와 CPU사이에 캐시, MMU, 레지스터 등 다양한 주변기기가 있지만, 설명에서는 생략합니다.</p>\n<p>앞서 프로세스의 “실행”은 시분할과 이를 제어하는 스케쥴링 기법을 통한 CPU 가상화를 통해 이뤄진다고 말씀드렸습니다. 우리가 program.c로 작성해 program.exe파일로  컴파일된 <strong>“파일” 이 어떻게 실행중인 “프로세스”로 변경</strong>되는지 이해하기 위해서는 아래 그림에 대한 설명이 필요합니다.</p>\n<p><img src=\"https://user-images.githubusercontent.com/30853787/226092562-a562242a-d948-46cd-8b5e-d68edcd3d0c0.png\" alt=\"1\"></p>\n<p>프로그래머가 작성한 소스코드는 파일로 저장되며, 언어에 따라 컴파일을 통해 실행 프로그램으로 변경됩니다.</p>\n<p>변경된 프로그램은 실행 시 메인 메모리에 적재되고, 프로그램 코드와 정적 데이터를 저장하며 <strong>실행중 사용할 수 있는 공간인 스택과 힙을 할당</strong>받아 명령어에 필요한 데이터를 사용하거나 명령어를 수행한 결과를 저장합니다.</p>\n<p>사실. 밑에서 공부할 프로세스의 상태에서는 CPU,Memory등을 할당받지 못한(Swap된) 상태도 있기때문에, 메모리에 적재된 프로그램만 프로세스라고 부르기에는 애매합니다. PCB도 조금 이따 볼거지만, “<strong>커널에 PCB가 저장된 프로그램</strong>”을 프로세스로 보시는게 더 정확합니다.</p>\n<p>여기서 중요한 개념 중 하나인 <strong>메모리 가상화</strong>가 등장합니다.</p>\n<p>메모리 가상화는 많은 역시 “<strong>많은프로세스가 자신의 독립된 주소 공간을 갖는것처럼 행동</strong>\"할 수 있도록 해주며, MMU가 실제 주소와 가상 주소를 저장한 테이블을 통해 변환해 각각의 프로세스가 주소공간을 서로 침범하지 않고 독립적으로 실행됩니다.</p>\n<p>(컴퓨터구조 여담)</p>\n<p>위 그림에서 왼쪽이 CPU와 고속처리장치(메모리컨트롤러, GPU, PCI 16x)들을 담당하는 노스브릿지(North Bridge), 오른쪽에서 메모리 아랫쪽이 저속처리장치(디스크, PCI 1x, USB, SATA 등)를 담당하는 사우스브릿지(South Bridge)인데, 주변장치와 데이터 버스를 통해 처리되던 노스브릿지 장치들이 CPU로 통합되면서 최신 CPU에는 노스브릿지 영역이 없는 형태의 CPU가 대부분이라고 합니다.</p>\n<h2 id=\"프로세스-상태\" style=\"position:relative;\"><a href=\"#%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-%EC%83%81%ED%83%9C\" aria-label=\"프로세스 상태 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>프로세스 상태</h2>\n<p><img src=\"https://user-images.githubusercontent.com/30853787/226092567-88d743d6-7d8e-483b-b183-c352a67b440b.png\" alt=\"2\"></p>\n<p>프로세스는 “스케쥴링 정책”을 통해 CPU와 메모리를 할당받는지 여부에 따라 아래와 같은 상태를 갖습니다.</p>\n<ul>\n<li><strong>Created:</strong> 커널에 PCB가 할당되고, <strong>가용 메모리공간을 체크해 Ready상태 또는 Suspend-Ready상태로 전이</strong>합니다.</li>\n<li><strong>Ready</strong>: 프로세서(CPU) 할당을 대기하는 상태로, 즉시 실행 가능한 상태입니다.\n<ul>\n<li><strong>Schedule(또는 dispatch)</strong>: 스케쥴링 정책에 의해 Running상태로 전이합니다.</li>\n</ul>\n</li>\n<li><strong>Running</strong>:  프로세서를 포함해 필요한 자원을 모두 할당받아 동작하는 상태입니다.\n<ul>\n<li>timer run-out: Running상태의 프로세스가 스케쥴 계획에 있던 시간을 모두 버스트해 종료합니다.</li>\n<li><strong>Block/sleep:</strong> I/O자원할당을 위해 잠시 대기합니다.</li>\n</ul>\n</li>\n<li><strong>Asleep(Block)</strong>: I/O가 끝나기를 기다리는 상태입니다. 자원별로 Block-Queue를 가지며, 할당이 끝나기를 기다리는 프로세스가 큐에 있습니다.\n<ul>\n<li><strong>Wake up</strong>: 자원할당을 마치고 ready queue로 들어갑니다.</li>\n</ul>\n</li>\n<li><strong>Suspended State: 메모리를 할당받지 못하고, 디스크(Swap device)에 메모리 이미지를 저장한 상태</strong>\n<ul>\n<li>Swap in: 스왑 이미지를 메모리에 적재해 Ready 또는 Asleep 상태로 변경</li>\n<li>Swap out: 적재된 메모리  영역을 스왑 디바이스에 이미지로 저장</li>\n</ul>\n</li>\n<li><strong>Terminate:</strong> 프로세스 수행이 끝나 모든 자원 반납 후 PCB만 커널 내에 남아있는 상태입니다.\n<ul>\n<li>커널이 이후 비슷한 프로세스를 실행할 때, PCB정보를 참고한다고 합니다.</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"pcb를-통한-프로세스의-관리\" style=\"position:relative;\"><a href=\"#pcb%EB%A5%BC-%ED%86%B5%ED%95%9C-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EC%9D%98-%EA%B4%80%EB%A6%AC\" aria-label=\"pcb를 통한 프로세스의 관리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>PCB를 통한 프로세스의 관리</h3>\n<p>PCB: Process Control Block - <strong>실행중인 프로그램(프로세스)들을 제어하는데 필요한 정보</strong>를 가지고있는 자료구조 입니다.</p>\n<p>시작/종료가 많은 프로세스의 특성 상 PCB 리스트 역시 삽입/삭제가 많은 데이터이므로,  <strong>커널 영역에서 LinkedList를 통해 관리됩니다.</strong></p>\n<ul>\n<li>PCB의 구성요소: 운영체제별로 다릅니다.</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>구성요소</th>\n<th>설명</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>PID: Process Identification Number</td>\n<td>프로세스를 고유하게 식별하는 번호</td>\n</tr>\n<tr>\n<td>스케쥴링 정보</td>\n<td>우선순위 등 스케쥴링을 위해 필요한 정보</td>\n</tr>\n<tr>\n<td>메모리 관리 정보</td>\n<td>할당된 페이지, 세그먼트에 대한 정보</td>\n</tr>\n<tr>\n<td>입출력상태 정보</td>\n<td>할당받은 입출력 장치</td>\n</tr>\n<tr>\n<td>문맥 저장 영역</td>\n<td>CPU 레지스터 저장, 문맥 교환 시 load/store하는 부분</td>\n</tr>\n<tr>\n<td>계정정보</td>\n<td>프로세스의 소유자</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>멀티프로세스보다 멀티스레드가 빠른 “실질적인” 이유</p>\n</blockquote>\n<p>프로세스 A의 실행정보라고 불리는 <strong>스택과 힙</strong>에 대해 이야기해봅시다. <strong>컴파일타임에 메모리를 할당받는 스택</strong>의 경우, 일반적으로 1MB를 사용하고 최대 10MB정도인 반면, <strong>힙영역은 런타임에 할당되고 최대 256MB</strong>또는 설정에 따라 메모리의 최대크기에 따라 더 커질수도 있습니다.</p>\n<p>프로세스 A의 PCB에는 A가 실행될 때의 레지스터 정보들을 가지고있습니다. 또한, CPU와 근접해있는 L1, L2캐시에도 프로세스 A의 실행정보들이 <strong>캐싱</strong>되어있습니다. 만약 프로세스 A가 B로 Context Switch할때는 레지스터 정보를 교체하겠지만, <strong>이후에는 L1,L2뿐만아니라 다른 캐시, 심지에 페이지 교체까지 일어납니다.</strong></p>\n<p>스레드의 경우는 어떨까요~? 스레드는 프로세스 내에서 독립적인 스택포인터(스택)을 갖지만, <strong>실행정보에 대부분을 차지하는 힙,코드,데이터영역을 공유합니다</strong>. 스레드의 정보를 저장한 TCB의 정보를 레지스터에 옮기는 시간은 있겠지만, 캐시,페이지 미스가 많이 일어나지 않기때문에, 훨씬 더 빠릅니다.</p>\n<p>+) 멀티스레드는 공유자원인 힙, 데이터에 대해 동시성 문제가 발생하므로, 동기화 문제를 꼭 핸들링해주어야 합니다!</p>\n<h3 id=\"키워드--질문-목록\" style=\"position:relative;\"><a href=\"#%ED%82%A4%EC%9B%8C%EB%93%9C--%EC%A7%88%EB%AC%B8-%EB%AA%A9%EB%A1%9D\" aria-label=\"키워드  질문 목록 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>키워드 &#x26; 질문 목록</h3>\n<p>PCB어떤 자료구조로 관리되며, 왜 해당 자료구조를 사용하는지 설명해주세요</p>\n<p>프로세스의 상태와 각 상태별로 사용하고있는 자원의 종류에 대해 설명해주세요</p>\n<p>멀티프로세스보다 멀티스레드가 빠른 이유를 설명해주세요</p>\n<p>문맥교환영역에 저장되는 CPU 레지스터 종류?</p>\n<p>PC (Program Counter) : 다음 인출(Fetch) 될 명령어의 주소를 가지고 있는 레지스터</p>\n<p>AC (Accumulator) : 연산 결과 데이터를 일시적으로 저장하는 레지스터</p>\n<p>IR (Instruction Register) : 가장 최근에 인출된 명령어(현재 실행 중인 명령어)가 저장되어 있는 레지스터</p>\n<p>SR (Status Register) : 현재 CPU 의 상태를 가지고 있는 레지스터</p>\n<p>MAR (Memory Address Register) : PC 에 저장된 명령어 주소가 사용되기 전에 일시적으로 저장되는 주소 레지스터</p>\n<p>MBR (Memory Buffer Register) : 기억장치에 저장될 데이터 혹은 읽혀진 데이터가 일시적으로 저장되는 버퍼 레지스터</p>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<p>[<strong>HPC Lab. KOREATECH, OS Lecture CH.3 Process](</strong><a href=\"https://www.youtube.com/watch?v=jZuTw2tRT7w\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.youtube.com/watch?v=jZuTw2tRT7w</a> <strong>)</strong></p>\n<p><a href=\"%5Bhttps://pages.cs.wisc.edu/~remzi/OSTEP/%5D(https://pages.cs.wisc.edu/~remzi/OSTEP/)\">OSTEP: Operating Systems: Three Easy Pieces</a></p>\n<p>이글은 꼭 이해하면 좋을것같다. 까먹으면 다시보자! → <a href=\"https://quasarzone.com/bbs/qn_hardware/views/818208\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://quasarzone.com/bbs/qn_hardware/views/818208</a></p>","id":"96b52839-d38a-577a-a1f1-5a12ac062586","fields":{"slug":"프로세스의-개념과-상태-변화"},"frontmatter":{"date":"2023-02-06","title":"프로세스의 개념과 상태 변화","category":"tech","tags":["운영체제","운영체제 스터디"],"banner":null},"timeToRead":3}],"tagName":"운영체제 스터디"}},"staticQueryHashes":[],"slicesMap":{}}