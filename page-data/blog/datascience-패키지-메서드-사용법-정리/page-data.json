{"componentChunkName":"component---src-templates-post-tsx","path":"/blog/datascience-패키지-메서드-사용법-정리","result":{"data":{"markdownRemark":{"html":"<h1 id=\"pandas\" style=\"position:relative;\"><a href=\"#pandas\" aria-label=\"pandas permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Pandas</h1>\n<h2 id=\"dataframeselect_dtypes\" style=\"position:relative;\"><a href=\"#dataframeselect_dtypes\" aria-label=\"dataframeselect_dtypes permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>DataFrame.select_dtypes()</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">train<span class=\"token punctuation\">.</span>select_dtypes<span class=\"token punctuation\">(</span>exclude<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'object'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># or</span>\ntrain<span class=\"token punctuation\">.</span>select_dtypes<span class=\"token punctuation\">(</span>include<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'object'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>dtype이 맞는 컬럼만 골라낸다.</p>\n</blockquote>\n<p>p.s 아래와 같이 구현할수도 있다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">cols <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>col <span class=\"token keyword\">for</span> col <span class=\"token keyword\">in</span> train <span class=\"token keyword\">if</span> train<span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dtypes <span class=\"token operator\">==</span><span class=\"token string\">'object'</span> <span class=\"token punctuation\">]</span></code></pre></div>\n<h2 id=\"read_csv\" style=\"position:relative;\"><a href=\"#read_csv\" aria-label=\"read_csv permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>read_csv()</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">X_full <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">'../input/train.csv'</span><span class=\"token punctuation\">,</span> index_col<span class=\"token operator\">=</span><span class=\"token string\">'Id'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>csv파일을 Pandas.DataFrame으로 읽어들인다. </p>\n</blockquote>\n<ul>\n<li>index_col : index로 사용할 컬럼을 지정한다</li>\n</ul>\n<h2 id=\"dataframecopy\" style=\"position:relative;\"><a href=\"#dataframecopy\" aria-label=\"dataframecopy permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>DataFrame.copy</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">X <span class=\"token operator\">=</span> X_full<span class=\"token punctuation\">[</span>features<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>copy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>기존 데이터프레임을 새로 만들어 반환한다.</p>\n</blockquote>\n<h2 id=\"seriesunique\" style=\"position:relative;\"><a href=\"#seriesunique\" aria-label=\"seriesunique permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Series.unique</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token punctuation\">[</span><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span> <span class=\"token punctuation\">{</span>col <span class=\"token punctuation\">:</span> train<span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>unique<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span> end<span class=\"token operator\">=</span><span class=\"token string\">'\\n\\n'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> col <span class=\"token keyword\">in</span> cat_cols<span class=\"token punctuation\">]</span></code></pre></div>\n<blockquote>\n<p>컬럼의 유니크 요소 반환 </p>\n</blockquote>\n<p>결과</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">{&#39;MSZoning&#39;: array([&#39;RL&#39;, &#39;RM&#39;, &#39;C (all)&#39;, &#39;FV&#39;, &#39;RH&#39;], dtype=object)}\n\n{&#39;Street&#39;: array([&#39;Pave&#39;, &#39;Grvl&#39;], dtype=object)}\n\n{&#39;Alley&#39;: array([nan, &#39;Grvl&#39;, &#39;Pave&#39;], dtype=object)}\n\n{&#39;LotShape&#39;: array([&#39;Reg&#39;, &#39;IR1&#39;, &#39;IR2&#39;, &#39;IR3&#39;], dtype=object)}\n\n{&#39;LandContour&#39;: array([&#39;Lvl&#39;, &#39;Bnk&#39;, &#39;Low&#39;, &#39;HLS&#39;], dtype=object)}\n\n{&#39;Utilities&#39;: array([&#39;AllPub&#39;, &#39;NoSeWa&#39;], dtype=object)}\n\n{&#39;LotConfig&#39;: array([&#39;Inside&#39;, &#39;FR2&#39;, &#39;Corner&#39;, &#39;CulDSac&#39;, &#39;FR3&#39;], dtype=object)}\n\n{&#39;LandSlope&#39;: array([&#39;Gtl&#39;, &#39;Mod&#39;, &#39;Sev&#39;], dtype=object)}</code></pre></div>\n<h2 id=\"dataframenunique-seriesnunique\" style=\"position:relative;\"><a href=\"#dataframenunique-seriesnunique\" aria-label=\"dataframenunique seriesnunique permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>DataFrame.nunique, Series.nunique</h2>\n<h1 id=\"sklearn\" style=\"position:relative;\"><a href=\"#sklearn\" aria-label=\"sklearn permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Sklearn</h1>\n<h2 id=\"randomforestregressor\" style=\"position:relative;\"><a href=\"#randomforestregressor\" aria-label=\"randomforestregressor permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>RandomForestRegressor</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model <span class=\"token operator\">=</span> RandomForestRegressor<span class=\"token punctuation\">(</span>n_estimators<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span> criterion<span class=\"token operator\">=</span><span class=\"token string\">'mae'</span><span class=\"token punctuation\">,</span> random_state<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>RandomForest 회귀 모델을 생성한다. 자주 사용하는 파라미터는  아래와 같다.</p>\n</blockquote>\n<p>랜덤포레스트 모델은 여러 머신러닝 모델을 ensemble(결합)하여 만드는 모델이다.\n각 모델의 결합을 통해 오버피팅을 방지하는 효과를 가지고있으며,\n데이터를 sampling해서 만든 Decision tree 평가 결과치의 평균을 통해 계산한다.</p>\n<ul>\n<li>n_estimators: 생성할 트리 개수 </li>\n<li>max_features: 최대로 선택할 특징의 수</li>\n<li>max<em>depth: 트리의 최대 깊이 (max</em>features랑 비례)</li>\n<li>criterion: Error 산정 기준(mae, mse, mse 등등)</li>\n<li>random_state: 난수 시드</li>\n</ul>\n<h2 id=\"from-sklearnmodel_selection\" style=\"position:relative;\"><a href=\"#from-sklearnmodel_selection\" aria-label=\"from sklearnmodel_selection permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>(from sklearn.model_selection)</h2>\n<h3 id=\"traintestsplit\" style=\"position:relative;\"><a href=\"#traintestsplit\" aria-label=\"traintestsplit permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>train<em>test</em>split</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">X_train<span class=\"token punctuation\">,</span> X_valid<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> y_valid <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> train_size<span class=\"token operator\">=</span><span class=\"token number\">0.8</span><span class=\"token punctuation\">,</span> test_size<span class=\"token operator\">=</span><span class=\"token number\">0.2</span><span class=\"token punctuation\">,</span> random_state<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p>X,Y 값에 대한 train/test셋을 일정 비율로 나눈다. train: 모델 학습에 사용, test: 모델 검증에 사용</p>\n</blockquote>\n<ul>\n<li>X,Y:  각각 feature와 result data 셋을 넘긴다.</li>\n<li>train/test_size: 각각 train/test 비율을 넘겨야 하며, 합한 값은 1이 되어야 한다.</li>\n</ul>\n<h2 id=\"from-sklearnmetrics-meanabsoluteerror\" style=\"position:relative;\"><a href=\"#from-sklearnmetrics-meanabsoluteerror\" aria-label=\"from sklearnmetrics meanabsoluteerror permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>(from sklearn.metrics) mean<em>absolute</em>error</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">mean_absolute_error<span class=\"token punctuation\">(</span>y_v<span class=\"token punctuation\">,</span> preds<span class=\"token punctuation\">)</span></code></pre></div>\n<blockquote>\n<p> y_validation dataframe에 대한 pred의 mae를 리턴한다.</p>\n</blockquote>\n<h2 id=\"from-sklearnimputer\" style=\"position:relative;\"><a href=\"#from-sklearnimputer\" aria-label=\"from sklearnimputer permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>(from sklearn.imputer)</h2>\n<h3 id=\"simpleimputer\" style=\"position:relative;\"><a href=\"#simpleimputer\" aria-label=\"simpleimputer permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>SimpleImputer</h3>\n<blockquote>\n<p>결측치를 대체하기 위한 transformer 객체를 생성한다.</p>\n</blockquote>\n<ul>\n<li>strategy: mean | median | most<em>frequent | constant 등이 있고, constant는 fill</em>value 파라미터를 지정해 상수로 대체한다.</li>\n<li>\n<p>copy: default:  true. false인 경우, 파라미터로 들어온 dataframe을 복제하지 않고 해당 dataframe에서 실행한다..</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">my_imputer <span class=\"token operator\">=</span> SimpleImputer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nimputed_X_train <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>my_imputer<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nimputed_X_valid <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>my_imputer<span class=\"token punctuation\">.</span>transform<span class=\"token punctuation\">(</span>X_valid<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n</li>\n</ul>\n<h2 id=\"from-sklearnpipeline-pipeline\" style=\"position:relative;\"><a href=\"#from-sklearnpipeline-pipeline\" aria-label=\"from sklearnpipeline pipeline permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>(from sklearn.Pipeline) Pipeline</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">cat_transformer <span class=\"token operator\">=</span> Pipeline<span class=\"token punctuation\">(</span>steps<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">'impute'</span><span class=\"token punctuation\">,</span> SimpleImputer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">'ohe'</span><span class=\"token punctuation\">,</span> OneHotEncoder<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2 id=\"from-sklearncolumntransformer-columntransformer\" style=\"position:relative;\"><a href=\"#from-sklearncolumntransformer-columntransformer\" aria-label=\"from sklearncolumntransformer columntransformer permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>(from sklearn.ColumnTransformer) ColumnTransformer</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">preprocessor <span class=\"token operator\">=</span> ColumnTransformer<span class=\"token punctuation\">(</span>transformers<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">'num'</span><span class=\"token punctuation\">,</span> SimpleImputer<span class=\"token punctuation\">(</span>strategy<span class=\"token operator\">=</span><span class=\"token string\">'constant'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> numerical_cols<span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">'cat'</span><span class=\"token punctuation\">,</span> cat_transformer<span class=\"token punctuation\">,</span> catagorial_cols<span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h1 id=\"pytorch\" style=\"position:relative;\"><a href=\"#pytorch\" aria-label=\"pytorch permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>pytorch</h1>\n<h1 id=\"xgboost\" style=\"position:relative;\"><a href=\"#xgboost\" aria-label=\"xgboost permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>XGboost</h1>","fields":{"slug":"datascience-패키지-메서드-사용법-정리"},"frontmatter":{"title":"Datascience 패키지 메서드  사용법 정리","date":"20.09.2021","category":"data scrience","tags":["data science"],"banner":"/assets/bg/2.jpg"},"timeToRead":3}},"pageContext":{"slug":"datascience-패키지-메서드-사용법-정리","prev":{"excerpt":"House price prediction (top4% kernel) 필사. House price prediction 분석 아래는 캐글 집값예측 샘플데회에 대한 나의 코드이다. 보시다시피 EDA도 안하고 무작정 전처리 / 모델링이 끝이며, 스코어도 발산하는 코드이다. House price prediction 분석 -2 부터는 나의 기본코드를 개선할 것이다. House price prediction (top4% kernel…","html":"<p><a href=\"https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">House price prediction (top4% kernel)</a> 필사.</p>\n<h2 id=\"house-price-prediction-분석\" style=\"position:relative;\"><a href=\"#house-price-prediction-%EB%B6%84%EC%84%9D\" aria-label=\"house price prediction 분석 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>House price prediction 분석</h2>\n<p>아래는 캐글 집값예측 샘플데회에 대한 나의 코드이다. 보시다시피 EDA도 안하고 무작정 전처리 / 모델링이 끝이며, 스코어도 발산하는 코드이다.</p>\n<p>House price prediction 분석 -2 부터는 나의 기본코드를 개선할 것이다.</p>\n<p><a href=\"https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">House price prediction (top4% kernel)</a> 에서는 정규화, 대체, 인코딩 등의 전처리 과정을 사전 학습하고 상위 4%의 모델을 만드는 과정이 담긴 커널이다. </p>\n<p><a href=\"https://github.com/lee95292/houseprice-prediction-improve\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">집값예측문제 개선과정</a>을 git commit을 통해 남길 예정이니, 어떤 과정을 통해 개선했는지 궁금한 캐글러들은 확인해봐도 좋을듯 하다.</p>\n<p>아래는 나의 베이스라인 커널이다.</p>\n<h2 id=\"house-price-prediction-my_kernelipynb\" style=\"position:relative;\"><a href=\"#house-price-prediction-my_kernelipynb\" aria-label=\"house price prediction my_kernelipynb permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>House price prediction [My_kernel.ipynb]</h2>\n<p>House Pr</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token operator\">%</span>matplotlib inline</code></pre></div>\n<h2 id=\"house-price-prediction-exercise-1\" style=\"position:relative;\"><a href=\"#house-price-prediction-exercise-1\" aria-label=\"house price prediction exercise 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>House price prediction, exercise #1</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> xgboost\n<span class=\"token keyword\">import</span> sklearn\n<span class=\"token keyword\">import</span> seaborn <span class=\"token keyword\">as</span> sb\n<span class=\"token keyword\">import</span> math\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plot\n\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>pipeline <span class=\"token keyword\">import</span> Pipeline\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>compose <span class=\"token keyword\">import</span> ColumnTransformer\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>impute <span class=\"token keyword\">import</span> SimpleImputer\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>preprocessing <span class=\"token keyword\">import</span> OneHotEncoder<span class=\"token punctuation\">,</span> OrdinalEncoder<span class=\"token punctuation\">,</span> LabelEncoder\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> cross_val_score<span class=\"token punctuation\">,</span> train_test_split<span class=\"token punctuation\">,</span> GridSearchCV<span class=\"token punctuation\">,</span> KFold\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> mean_absolute_error<span class=\"token punctuation\">,</span> mean_squared_error\n<span class=\"token keyword\">from</span> xgboost <span class=\"token keyword\">import</span> XGBRegressor\n\ntrain <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">'./data/train.csv'</span><span class=\"token punctuation\">)</span>\ntest <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">'./data/test.csv'</span><span class=\"token punctuation\">)</span>\n\ntrain_y <span class=\"token operator\">=</span> train<span class=\"token punctuation\">[</span><span class=\"token string\">'SalePrice'</span><span class=\"token punctuation\">]</span>\ntrain<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span><span class=\"token string\">'SalePrice'</span><span class=\"token punctuation\">,</span>axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2 id=\"exploratory-data-analysis\" style=\"position:relative;\"><a href=\"#exploratory-data-analysis\" aria-label=\"exploratory data analysis permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Exploratory Data Analysis</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"></code></pre></div>\n<h2 id=\"preprocessing\" style=\"position:relative;\"><a href=\"#preprocessing\" aria-label=\"preprocessing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Preprocessing</h2>\n<ul>\n<li>(1) 1460개 행 중에서 1000개 이상의 결측값을 가진 열 삭제 </li>\n<li>(2) 수치형 변수와 범주형 변수로 나누어서 결측치 대체</li>\n<li>(3) 범주형 데이터는 카디널리티 10 기준으로 나누어서 각각 Oridinal, OneHot으로 인코딩</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># (1)</span>\nloss_cols  <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>col <span class=\"token keyword\">for</span> col <span class=\"token keyword\">in</span> train <span class=\"token keyword\">if</span> train<span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>isnull<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">></span> <span class=\"token number\">1000</span><span class=\"token punctuation\">]</span>\ntrain_f <span class=\"token operator\">=</span> train<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span>loss_cols<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\"># (2)</span>\ntrain_num_cols <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>col <span class=\"token keyword\">for</span> col <span class=\"token keyword\">in</span> train_f <span class=\"token keyword\">if</span> train_f<span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dtypes <span class=\"token operator\">!=</span><span class=\"token string\">'object'</span> <span class=\"token punctuation\">]</span>\nsim <span class=\"token operator\">=</span> SimpleImputer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ntrain_num <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>sim<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>train_f<span class=\"token punctuation\">[</span>train_num_cols<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span>train_num_cols<span class=\"token punctuation\">)</span>\n\ntrain_cat <span class=\"token operator\">=</span> train_f<span class=\"token punctuation\">.</span>select_dtypes<span class=\"token punctuation\">(</span>include<span class=\"token operator\">=</span><span class=\"token string\">'object'</span><span class=\"token punctuation\">)</span>\ncat_sim <span class=\"token operator\">=</span> SimpleImputer<span class=\"token punctuation\">(</span>strategy<span class=\"token operator\">=</span><span class=\"token string\">'most_frequent'</span><span class=\"token punctuation\">)</span>\ntrain_cat <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>cat_sim<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>train_cat<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span>train_cat<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># (3)</span>\nhigh_cardinal_cols <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>col <span class=\"token keyword\">for</span> col <span class=\"token keyword\">in</span> train_cat<span class=\"token punctuation\">.</span>columns <span class=\"token keyword\">if</span> train_cat<span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>nunique<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">>=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">]</span>\nlow_cardinal_cols <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>col <span class=\"token keyword\">for</span> col <span class=\"token keyword\">in</span> train_cat<span class=\"token punctuation\">.</span>columns <span class=\"token keyword\">if</span> train_cat<span class=\"token punctuation\">[</span>col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>nunique<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> <span class=\"token number\">10</span><span class=\"token punctuation\">]</span>\n\nore <span class=\"token operator\">=</span> OrdinalEncoder<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ntrain_ohe <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>get_dummies<span class=\"token punctuation\">(</span>train_cat<span class=\"token punctuation\">[</span>low_cardinal_cols<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>  prefix<span class=\"token operator\">=</span>low_cardinal_cols<span class=\"token punctuation\">,</span> prefix_sep<span class=\"token operator\">=</span><span class=\"token string\">'_'</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#pd.DataFrame(ohe.fit_transform(train_cat[low_cardinal_cols]))</span>\ntrain_ore <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>ore<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>train_cat<span class=\"token punctuation\">[</span>high_cardinal_cols<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> columns <span class=\"token operator\">=</span> high_cardinal_cols<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># # of joined dataframe's col is 223</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'====Validation===='</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_cat<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_num<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_ohe<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_ore<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_num<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Valid : \"</span> <span class=\"token punctuation\">,</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_ohe<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">)</span><span class=\"token operator\">+</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_ore<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">)</span><span class=\"token operator\">+</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_num<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token number\">223</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># concatenation</span>\ntrain_f<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span>train_cat<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\ntrain_f<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span>train_num<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\ntrain_f <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>concat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>train_num<span class=\"token punctuation\">,</span> train_ohe<span class=\"token punctuation\">,</span> train_ore<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">====Validation====\n39 37\n183 3 37\nValid :  True</code></pre></div>\n<h2 id=\"modeling\" style=\"position:relative;\"><a href=\"#modeling\" aria-label=\"modeling permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Modeling</h2>\n<ul>\n<li>\n<h1 id=\"1-traintestsplit\" style=\"position:relative;\"><a href=\"#1-traintestsplit\" aria-label=\"1 traintestsplit permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. train<em>test</em>split</h1>\n</li>\n<li>\n<h1 id=\"2-crossvalscore\" style=\"position:relative;\"><a href=\"#2-crossvalscore\" aria-label=\"2 crossvalscore permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Cross<em>val</em>score</h1>\n</li>\n<li>\n<h1 id=\"3-kfold\" style=\"position:relative;\"><a href=\"#3-kfold\" aria-label=\"3 kfold permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Kfold</h1>\n</li>\n<li>\n<h1 id=\"3-kfold--hyperparameter-tuninggcv\" style=\"position:relative;\"><a href=\"#3-kfold--hyperparameter-tuninggcv\" aria-label=\"3 kfold  hyperparameter tuninggcv permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. KFold + hyperparameter tuning(GCV)</h1>\n</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">flag <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n<span class=\"token keyword\">if</span> flag <span class=\"token operator\">==</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span> <span class=\"token comment\"># error : </span>\n    train_x<span class=\"token punctuation\">,</span> valid_x<span class=\"token punctuation\">,</span> train_y<span class=\"token punctuation\">,</span> valid_y <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>train_f<span class=\"token punctuation\">,</span>train_y<span class=\"token punctuation\">,</span> train_size<span class=\"token operator\">=</span><span class=\"token number\">0.8</span><span class=\"token punctuation\">,</span> test_size<span class=\"token operator\">=</span><span class=\"token number\">0.2</span><span class=\"token punctuation\">)</span>\n\n    model <span class=\"token operator\">=</span> XGBRegressor<span class=\"token punctuation\">(</span>eta<span class=\"token operator\">=</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> colsample_bytree<span class=\"token operator\">=</span><span class=\"token number\">0.75</span><span class=\"token punctuation\">,</span> max_depth<span class=\"token operator\">=</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> min_child_weight<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\n    model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>train_x<span class=\"token punctuation\">,</span>train_y<span class=\"token punctuation\">)</span>\n\n    pred <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>valid_x<span class=\"token punctuation\">)</span>\n\n    score <span class=\"token operator\">=</span> mean_squared_error<span class=\"token punctuation\">(</span>pred<span class=\"token punctuation\">,</span> valid_y<span class=\"token punctuation\">,</span> squared<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"mean_squared_error: \"</span><span class=\"token punctuation\">,</span>score<span class=\"token punctuation\">)</span>\n    \n<span class=\"token keyword\">elif</span> flag <span class=\"token operator\">==</span> <span class=\"token number\">2</span><span class=\"token punctuation\">:</span>  \n    model <span class=\"token operator\">=</span> XGBRegressor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    scores <span class=\"token operator\">=</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token operator\">*</span>cross_val_score<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span> train_f<span class=\"token punctuation\">,</span> train_y<span class=\"token punctuation\">,</span> cv<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> scoring<span class=\"token operator\">=</span><span class=\"token string\">'neg_mean_squared_error'</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"mean_squared_error mean: \"</span><span class=\"token punctuation\">,</span>scores<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">elif</span> flag <span class=\"token operator\">==</span> <span class=\"token number\">3</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">pass</span>\n<span class=\"token keyword\">elif</span> flag <span class=\"token operator\">==</span> <span class=\"token number\">4</span><span class=\"token punctuation\">:</span>\n    train_x<span class=\"token punctuation\">,</span> valid_x<span class=\"token punctuation\">,</span> train_y<span class=\"token punctuation\">,</span> valid_y <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>train_f<span class=\"token punctuation\">,</span> train_y<span class=\"token punctuation\">,</span> train_size<span class=\"token operator\">=</span><span class=\"token number\">0.8</span><span class=\"token punctuation\">,</span> test_size <span class=\"token operator\">=</span> <span class=\"token number\">0.2</span><span class=\"token punctuation\">)</span>\n    \n    model <span class=\"token operator\">=</span> XGBRegressor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    kf <span class=\"token operator\">=</span> KFold<span class=\"token punctuation\">(</span>random_state<span class=\"token operator\">=</span><span class=\"token number\">30</span><span class=\"token punctuation\">,</span> shuffle<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> n_splits<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\n    params <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'eta'</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">[</span><span class=\"token number\">0.05</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.15</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span><span class=\"token string\">'max_depth'</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">[</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span><span class=\"token number\">7</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'min_child_weight'</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'colsample_bytree'</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">[</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span><span class=\"token number\">0.75</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span>\n    \n    gcv <span class=\"token operator\">=</span> GridSearchCV<span class=\"token punctuation\">(</span>estimator<span class=\"token operator\">=</span>model<span class=\"token punctuation\">,</span> cv<span class=\"token operator\">=</span>kf<span class=\"token punctuation\">,</span> n_jobs<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> scoring<span class=\"token operator\">=</span><span class=\"token string\">'neg_mean_squared_error'</span><span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> param_grid<span class=\"token operator\">=</span>params<span class=\"token punctuation\">)</span>\n    \n    \n    gcv<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>train_x<span class=\"token punctuation\">,</span> train_y<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>gcv<span class=\"token punctuation\">.</span>best_params_<span class=\"token punctuation\">)</span>\n    \n    best_model <span class=\"token operator\">=</span> gcv<span class=\"token punctuation\">.</span>best_estimator_\n    pred <span class=\"token operator\">=</span> best_model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>valid_x<span class=\"token punctuation\">)</span>\n    score <span class=\"token operator\">=</span> mean_squared_error<span class=\"token punctuation\">(</span>pred<span class=\"token punctuation\">,</span> valid_y<span class=\"token punctuation\">,</span> squared<span class=\"token operator\">=</span>Fasle<span class=\"token punctuation\">)</span>\n    \n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"mean_squared_error: \"</span><span class=\"token punctuation\">,</span>score<span class=\"token punctuation\">)</span>\n<span class=\"token comment\">#     Fitting 10 folds for each of 8 candidates, totalling 80 fits</span>\n<span class=\"token comment\">#     {'colsample_bytree': 0.75, 'max_depth': 5, 'min_child_weight': 3}</span>\n<span class=\"token comment\">#     Mean_absolute_error:  17648.85913420377</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">mean_squared_error:  25757.824396836273</code></pre></div>","id":"81fff683-1ff7-5f96-980b-dd25b647f656","fields":{"slug":"kaggle-커널분석-notebook-house-price-prediction"},"frontmatter":{"date":"2021-08-25","title":"[Kaggle 커널분석 notebook] House price prediction","category":"datascience","tags":["datascience","machinelearning"],"banner":"/assets/bg/2.jpg"},"timeToRead":4},"next":{"excerpt":"","html":"","id":"d5f697d9-44af-51bf-932e-e9a329a1aefa","fields":{"slug":"kaggle-커널분석-notebook-house-price-prediction-2"},"frontmatter":{"date":"2021-10-12","title":"[Kaggle 커널분석 notebook] House price prediction -2","category":"datascience","tags":["datascience","machinelearning"],"banner":"/assets/bg/2.jpg"},"timeToRead":1}}},"staticQueryHashes":["3824141623"]}