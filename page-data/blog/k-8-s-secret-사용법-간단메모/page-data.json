{"componentChunkName":"component---src-templates-post-tsx","path":"/blog/k-8-s-secret-사용법-간단메모","result":{"data":{"markdownRemark":{"html":"<h1 id=\"쿠버네티스-시크릿이란\" style=\"position:relative;\"><a href=\"#%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4-%EC%8B%9C%ED%81%AC%EB%A6%BF%EC%9D%B4%EB%9E%80\" aria-label=\"쿠버네티스 시크릿이란 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>쿠버네티스 시크릿이란?</h1>\n<p>비밀번호와 같이 평문으로 저장되어서는 안되는 민감 정보를 보호하는 컴포넌트.</p>\n<h2 id=\"생성\" style=\"position:relative;\"><a href=\"#%EC%83%9D%EC%84%B1\" aria-label=\"생성 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>생성</h2>\n<p>kubectl create secret generic [name] --from-file=[field_name]=[file_name]</p>\n<h2 id=\"수정\" style=\"position:relative;\"><a href=\"#%EC%88%98%EC%A0%95\" aria-label=\"수정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>수정</h2>\n<p>kubectl edit secrets [name]</p>\n<ul>\n<li>data 필드를 수정해서 시크릿이 보유한 값을 수정할 수 있다.</li>\n<li>이 때, 값은 base64인코딩 포멧을 지켜야만 저장된다.</li>\n</ul>\n<p><strong>!! base64인코딩때문에 secret authentication failed가 뜨는경우가 많다 !!</strong><br>\n이때, data 필드 대신 stringData필드를 사용하면 해결된다.</p>\n<p>Ex)</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">apiVersion: v1\n# !!!!data 필드를 지우고, 대신 stringData 사용!!!\n#data:\n#  password: MXEydzNlNHIhCg==\nstringData:\n    password: 1q2w3e4r!\nkind: Secret\nmetadata:\n  creationTimestamp: \"2021-06-10T13:47:17Z\"\n  name: asd\n  namespace: asd\n  resourceVersion: \"***\"\n  uid: ******\ntype: Opaque\n</code></pre></div>\n<h2 id=\"삭제\" style=\"position:relative;\"><a href=\"#%EC%82%AD%EC%A0%9C\" aria-label=\"삭제 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>삭제</h2>\n<p>kubectl remove secrets [name]</p>\n<br> \n<h1 id=\"레퍼런스\" style=\"position:relative;\"><a href=\"#%EB%A0%88%ED%8D%BC%EB%9F%B0%EC%8A%A4\" aria-label=\"레퍼런스 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>레퍼런스</h1>\n<p>더 많은 secret의 활용사례는 <a href=\"https://kubernetes.io/ko/docs/concepts/configuration/secret/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">공식문서</a>를 참조하자.</p>","fields":{"slug":"k-8-s-secret-사용법-간단메모"},"frontmatter":{"title":"k8s secret 사용법 간단메모","date":"10.06.2021","category":"operation","tags":["kubernetes","secret"],"banner":"/assets/bg/2.jpg"},"timeToRead":1}},"pageContext":{"slug":"k-8-s-secret-사용법-간단메모","prev":{"excerpt":"Pagenation with slider 모바일버전 touchmove를 통해 pagenation 구현 Todo 앱과 연결 자체 구축 투두앱 위젯 부착 통계 개선 서드파티 애널리틱스 - GA 또는 Clarity 연동 사이드바에 목차 및 링크 표시 참고: 판다스아티클 오른쪽 사이드메뉴 : 대주제 클릭 시 소주제 unfold 시리즈 기능 계획 PWA…","html":"<h1 id=\"pagenation-with-slider\" style=\"position:relative;\"><a href=\"#pagenation-with-slider\" aria-label=\"pagenation with slider permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Pagenation with slider</h1>\n<p>모바일버전 touchmove를 통해 pagenation 구현</p>\n<h1 id=\"todo-앱과-연결\" style=\"position:relative;\"><a href=\"#todo-%EC%95%B1%EA%B3%BC-%EC%97%B0%EA%B2%B0\" aria-label=\"todo 앱과 연결 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Todo 앱과 연결</h1>\n<p>자체 구축 투두앱 위젯 부착</p>\n<h1 id=\"통계-개선\" style=\"position:relative;\"><a href=\"#%ED%86%B5%EA%B3%84-%EA%B0%9C%EC%84%A0\" aria-label=\"통계 개선 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>통계 개선</h1>\n<p>서드파티 애널리틱스 - GA 또는 Clarity 연동</p>\n<h1 id=\"사이드바에-목차-및-링크-표시\" style=\"position:relative;\"><a href=\"#%EC%82%AC%EC%9D%B4%EB%93%9C%EB%B0%94%EC%97%90-%EB%AA%A9%EC%B0%A8-%EB%B0%8F-%EB%A7%81%ED%81%AC-%ED%91%9C%EC%8B%9C\" aria-label=\"사이드바에 목차 및 링크 표시 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>사이드바에 목차 및 링크 표시</h1>\n<p>참고: <a href=\"https://pandas.pydata.org/pandas-docs/stable/user_guide/cookbook.html#multiindexing\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">판다스</a>아티클 오른쪽 사이드메뉴 : 대주제 클릭 시 소주제 unfold</p>\n<h1 id=\"시리즈-기능-계획\" style=\"position:relative;\"><a href=\"#%EC%8B%9C%EB%A6%AC%EC%A6%88-%EA%B8%B0%EB%8A%A5-%EA%B3%84%ED%9A%8D\" aria-label=\"시리즈 기능 계획 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>시리즈 기능 계획</h1>\n<p>PWA 및 메일 구독 가능한 시리즈 포스팅</p>\n<h1 id=\"포스팅-아래에-이어질만한-다른-것\" style=\"position:relative;\"><a href=\"#%ED%8F%AC%EC%8A%A4%ED%8C%85-%EC%95%84%EB%9E%98%EC%97%90-%EC%9D%B4%EC%96%B4%EC%A7%88%EB%A7%8C%ED%95%9C-%EB%8B%A4%EB%A5%B8-%EA%B2%83\" aria-label=\"포스팅 아래에 이어질만한 다른 것 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>포스팅 아래에 이어질만한 다른 것</h1>\n<ul>\n<li>댓글 또는 방명록</li>\n<li>같은 카테고리의 다른 글</li>\n</ul>","id":"7bcb727d-df51-5d2f-8f0e-417ef199777d","fields":{"slug":"blog-구현-todo"},"frontmatter":{"date":"2021-05-15","title":"Blog 구현 Todo","category":"operation","tags":["traefik","opensource"],"banner":"/assets/bg/2.jpg"},"timeToRead":1},"next":{"excerpt":"Machine Learning XGBoost 파라미터 설명_kaggle XGBoost 파라미터 설명 정규화된 선형회귀(ratsgo님 블로그) XGBoost 파라미터 설명_kaggle 번역 및 정리 General params 2.1.1 booster 부스터 파라미터는  어떤 부스터를 사용할것인지에 대한 파라미터 각각의 iteration에 어떤 부스터를 사용할지 지정할 수 있도록 함 gbtree, gblinear, dart…","html":"<ul>\n<li>Machine Learning\n<ul>\n<li><a href=\"https://www.kaggle.com/prashant111/a-guide-on-xgboost-hyperparameters-tuning\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">XGBoost 파라미터 설명_kaggle</a></li>\n<li><a href=\"https://xgboost.readthedocs.io/en/latest/parameter.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">XGBoost 파라미터 설명</a></li>\n<li><a href=\"https://ratsgo.github.io/machine%20learning/2017/05/22/RLR/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">정규화된 선형회귀(ratsgo님 블로그)</a></li>\n</ul>\n</li>\n</ul>\n<hr>\n<ul>\n<li>\n<p><a href=\"https://www.kaggle.com/prashant111/a-guide-on-xgboost-hyperparameters-tuning\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">XGBoost 파라미터 설명_kaggle</a> 번역 및 정리</p>\n<h2 id=\"general-params\" style=\"position:relative;\"><a href=\"#general-params\" aria-label=\"general params permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>General params</h2>\n<h3 id=\"211-booster\" style=\"position:relative;\"><a href=\"#211-booster\" aria-label=\"211 booster permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.1.1 booster</h3>\n<ul>\n<li>부스터 파라미터는  어떤 부스터를 사용할것인지에 대한 파라미터</li>\n<li>각각의 iteration에 어떤 부스터를 사용할지 지정할 수 있도록 함</li>\n<li><strong>gbtree, gblinear, dart</strong>  세개의 옵션이 있다.\n<ul>\n<li>gbtree, dart는 트리기반 모델이고, gblinear는 선형 모델이다</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"212-verbosity\" style=\"position:relative;\"><a href=\"#212-verbosity\" aria-label=\"212 verbosity permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.1.2 verbosity</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">기본값: 1</code></pre></div>\n<ul>\n<li>결과값을 출력하는지에 대한 파라미터 (0: 메시지없음, 1:경고메시지, 2:정보, 3:디버그)</li>\n</ul>\n<h3 id=\"213-nthread\" style=\"position:relative;\"><a href=\"#213-nthread\" aria-label=\"213 nthread permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.1.3 nthread</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">기본값: OS 설정값, 없다면 가용한 최대한의 스레드 수</code></pre></div>\n<ul>\n<li>XGBoost에서 사용하는 병렬 스레드의 개수</li>\n<li>시스템에서 사용할 코어와 스레드의 개수</li>\n<li>모든 코어를 사용하고싶다면, 기본값을 사용하기</li>\n</ul>\n<p><strong>disable_default_eval_metric[기본값 0], num_pbuffer[자동설정값], num_feature[자동설정값]</strong> 과 같은 여러 전역 파라미터들이 있다. 하지만, 이는 대부분 XGBoost가 자동으로 설정해주니 더이상 논의하지 않는다.</p>\n<h2 id=\"booster-parameters\" style=\"position:relative;\"><a href=\"#booster-parameters\" aria-label=\"booster parameters permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Booster Parameters</h2>\n<ul>\n<li>선형 부스터와 트리 부스터가 있다.</li>\n<li>선형 부스터에 비해 트리 부스터가 월등히 성능이 좋고 자주 쓰이므로, 트리 부스터에 대해서만 정리한다</li>\n</ul>\n<h3 id=\"221-eta\" style=\"position:relative;\"><a href=\"#221-eta\" aria-label=\"221 eta permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.2.1 eta</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">기본값 0.3, learning_rate와 같은 의미의 파라미터</code></pre></div>\n<ul>\n<li>GBM에서의 learning_rate와 유사한 파라미터이다.</li>\n<li>과적합 방지를 위한 스텝 크기를 축소하는 방식이다.</li>\n<li>각 부스팅 단계 후에 새로운 특징에 대한 가중치를 직접 가져올 수 있고, eta 변수는 부스팅 과정을 더 안전하게 만들기 위해 특징의 가중치를 축소시킬 수 있다.</li>\n<li>이는 각 스텝에서의 가중치를 줄여 모델이 조금 더 robust(무뎌지게)한다</li>\n<li>[0<del>1] 범위의 값이고, 보통 0.01</del>2사이의 값을 지정한다.</li>\n</ul>\n<h3 id=\"222-gamma\" style=\"position:relative;\"><a href=\"#222-gamma\" aria-label=\"222 gamma permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.2.2 gamma</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">기본값 0, min_split_loss와 비슷함</code></pre></div>\n<ul>\n<li>트리의 노드가 분할했을 경우, 손실함수에서 양의 감소가 있을경우에만 분할한다.</li>\n<li>Gamma는 노드가 분리되기 위한 최소의 감소값을 나타낸다</li>\n<li>큰 값일수록 알고리즘이 더 보수적으로 동작하도록 한다. 이는 손실함수에 다양하게 의존하기 때문에 그에 맞게 조절해야 한다.</li>\n<li>[0~무한대]의 값을 갖는다</li>\n</ul>\n<h3 id=\"223-max_depth\" style=\"position:relative;\"><a href=\"#223-max_depth\" aria-label=\"223 max_depth permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.2.3 max_depth</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">기본값 6, GBM에서와 같이 tree 깊이의 최댓값을 나타낸다</code></pre></div>\n<ul>\n<li>높은 값이 표본의 특정 값과의 관계까지 학습하게 하는것처럼, 과적합을 컨트롤할 수 있다.</li>\n<li>이 값을 올리는것은 모델을 복잡하고, 과적합의 가능성을 높힌다.</li>\n<li>The value 0 is only accepted in lossguided growing policy when tree_method is set as hist and it indicates no limit on depth.(손실유도정책에 관한 내용. 이해 X)</li>\n<li>이 값을 높게 설정하면, XGBoost가 깊은 레벨의 트리를 학습하기 위해 많은 메모리를 사용하므로, 주의해햐 함.</li>\n<li>0~무한의 범위</li>\n<li>CV를 사용해 튜닝하는것이 좋음</li>\n<li>통상적으로 3-10의 값을 갖는다</li>\n</ul>\n<h3 id=\"224-min_child_weight\" style=\"position:relative;\"><a href=\"#224-min_child_weight\" aria-label=\"224 min_child_weight permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.2.4 min_child_weight</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">기본값 1, 자식노드에 필요한 모든 노드 가중치의 최소 합을 지정.</code></pre></div>\n<ul>\n<li>GBM에서의 min_child_leaf와 유사하지만, 관측치의 개수가 아닌 관측치 합의 최솟값이라는것에서 차이가 있다.</li>\n<li>과적합을 막기 위해 사용한다</li>\n<li>높은 값을 설정해 트리를 위해 지나치게 특정지어진 값과의 관계를 학습하는것을 방지한다.</li>\n<li>너무 높은 값은 under-fitting(과소적합)을 일으킨다. 그러므로, CV를 통해 조절하자.</li>\n<li>min_child_weight값이 커질수록 보수적인 알고리즘이 된다.</li>\n<li>0~무한 값을 갖는다</li>\n</ul>\n<h3 id=\"225-max_delta_step\" style=\"position:relative;\"><a href=\"#225-max_delta_step\" aria-label=\"225 max_delta_step permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.2.5 max_delta_step</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">기본값 0, </code></pre></div>\n<h3 id=\"226-subsample\" style=\"position:relative;\"><a href=\"#226-subsample\" aria-label=\"226 subsample permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.2.6 subsample</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">기본값 1, 각 트리에서 임의로 샘플을 추출하기 위한 관측치의 비율을 나타낸다.</code></pre></div>\n<ul>\n<li>훈련 인스턴스의 하위표본의 비율.</li>\n<li>0.5로 설정하면 트리를 훈련시키기 이전에 훈련데이터의 절반을 랜덤하게 표본으로 추출한다. 이를 통해 과적합을 방지한다.</li>\n<li>__subsampling__은 부스팅 과정에서 매 반복외 1회 시행한다.</li>\n<li>낮은 값을 통해 알고리즘이 과적합을 막고, 보수적으로 동작할 수 있도록 하지만, 너무 적은 값은 과소추정을 발생시킨다.</li>\n<li>(0<del>1] 값을 가질 수 있으며, 보통 0.5</del>1의 값을 지정한다</li>\n</ul>\n<h3 id=\"227-colsample_bytree-colsample_bylevel-colsample_bynode\" style=\"position:relative;\"><a href=\"#227-colsample_bytree-colsample_bylevel-colsample_bynode\" aria-label=\"227 colsample_bytree colsample_bylevel colsample_bynode permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.2.7 colsample_bytree, colsample_bylevel, colsample_bynode</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">기본값: 1, 열(colums)의 subsampling을 하기 위한 파라미터 모음</code></pre></div>\n<ul>\n<li>\n<p>모든 colsample_by 파라미터는 (0,1] 값을 가질 수 있고, 1의 기본값을 가지며,  subsampling될 열의 비율을 결정한다.</p>\n</li>\n<li>\n<p><strong>colsample_bytree</strong> 는 각 트리가 생성될 때 이에 대해  subsampling할 열의 비율을 나타낸다.  subsampling은 트리가 생성될 때 한번 수행된다.</p>\n</li>\n<li>\n<p><strong>colsample_bylevel</strong> 은 각 레벨에서 열의 하위표본 비율이다.  subsampling은 트리에서 새로운 깊이 단계에 도달했을때마다 발생한다.</p>\n</li>\n<li>\n<p><strong>colsample_bynode</strong> 는 각 노드에서 열을  subsampling하는 비율이다.  subsampling은 분할이 일어날때마다 발생한다.</p>\n</li>\n<li>\n<p>각각 현재 트리,레벨,노드에 선택된 열 집합을  subsampling한다</p>\n</li>\n<li>\n<p>각 파라미터는 누산되는 방식으로 동작하며, 각각을 0.5로 지정한 상태에서 64개의 특징을 부여하면, 각 분할에서 8개의 특징만이 남게된다.</p>\n</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">파라미터 lambda와 alpha는 정규화항에 대한 파라미터이므로, 정규화에 관한 이해가 필수적이다.  \nhttps://ratsgo.github.io/machine%20learning/2017/05/22/RLR/ 를 통해 간단하게 정규화를 이해해보자.</code></pre></div>\n<h3 id=\"228-lambda\" style=\"position:relative;\"><a href=\"#228-lambda\" aria-label=\"228 lambda permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.2.8 lambda</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">기본값 1, 가중치에 대한 L2정규화 항( Ridge regression과 유사함)</code></pre></div>\n<ul>\n<li>XGBoost에서 정규화 파트를 담당</li>\n<li>이 값을 증가시키면, 모델을 보수적으로 만들 수 있음</li>\n</ul>\n<h3 id=\"229-alpha\" style=\"position:relative;\"><a href=\"#229-alpha\" aria-label=\"229 alpha permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.2.9 alpha</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">기본값 0, 가중치에 대한 L1 정규화 항 (Lasso regression과 유사함)</code></pre></div>\n<ul>\n<li>매우 높은 차원의 경우, 알고리즘이 더 빨리 동작하도록 구현할 수 있다.</li>\n<li>이 값을 증가시키면 모델을 보수적으로 만들 수 있음</li>\n</ul>\n<h3 id=\"2210-tree_method\" style=\"position:relative;\"><a href=\"#2210-tree_method\" aria-label=\"2210 tree_method permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.2.10 tree_method</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">기본값 auto(문자열), XGBoost에서 사용할 트리 생성 알고리즘.</code></pre></div>\n<ul>\n<li>XGBoost는 분산 훈련을 위한 approx, hist, gpu_hist 트리 메서드와, approx, gpu_hist를 통해 외부 메모리를 사용할 수 있도록 실험적으로 지원한다.</li>\n<li>[auto,exact,approx, hist,gpu_hist]를 사용할 수 있음</li>\n<li>auto: 휴리스틱 방법을 통해 가장 빠른 메서드를 사용함.\n<ul>\n<li>적가나 중간정도 크기의 데이셋은 exact greedy 메서드(exact)가 사용됨.</li>\n<li>매우 큰 데이터셋에는 approximate 알고리즘(approx)가 사용됨</li>\n<li>고전적인 방법으로, 단일 기기에서는 항상 exact greedy가 사용되기에, approximate 방법이 선택될 때 알림을 받게 된다.</li>\n</ul>\n</li>\n<li>exact: exact greedy algorithm</li>\n<li>approx: 대략적인 분위수와 기울기 히스토그램을 통한 approximate greedy algorithm</li>\n<li>hist: approximate greedy algorithm을 최적화한 빠른 히스토그램. bins caching과 같이 일부의 성능 개선방법을 사용함.</li>\n<li>gpu_hist: hist알고리즘에 대한 GPU버전 구현</li>\n</ul>\n<h3 id=\"2211-scale_post_weight\" style=\"position:relative;\"><a href=\"#2211-scale_post_weight\" aria-label=\"2211 scale_post_weight permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.2.11 scale_post_weight</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">기본값 1, 양과 음의 가중치 값의 균형을 조절한다</code></pre></div>\n<ul>\n<li>불균형한 클래스들이 있는 경우 유용하다.</li>\n<li>높은 클래스의 불균형이 있는경우, 0보다 큰 값을 사용해 빠르게 수렴하도록 해야한다.</li>\n<li>일반적으로 고려해야 하는 값 : <strong>sum(negative instances) / sum(positive instances)</strong></li>\n</ul>\n<h3 id=\"2212-max_leaves\" style=\"position:relative;\"><a href=\"#2212-max_leaves\" aria-label=\"2212 max_leaves permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.2.12 max_leaves</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">기본값 0, 추가하는 노드의 최댓값</code></pre></div>\n<ul>\n<li>grow_policy=lossguide일때만 유효하게 동작</li>\n</ul>\n<p>sketch_eps,updater, refresh_leaf, process_type, grow_policy, max_bin, predictor and num_parallel_tree 와 같은 다른 파라미터들이 있지만, <a href=\"https://xgboost.readthedocs.io/en/latest/parameter.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">XGBoost 공식문서(파라미터 설명)</a>을 참고하자.</p>\n<hr>\n</li>\n</ul>\n<h2 id=\"learning-task-parameters\" style=\"position:relative;\"><a href=\"#learning-task-parameters\" aria-label=\"learning task parameters permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Learning Task Parameters</h2>\n<ul>\n<li>이러한 파라미터들은각 단계에서 계산할 최적 목적함수 검증방법을  정의하는데 사용한다.</li>\n<li>이 파라미터들은 학습과정과 그에 상응하는 학습 목적함수를 구체화하는데 사용한다.</li>\n</ul>\n<h3 id=\"231-objective\" style=\"position:relative;\"><a href=\"#231-objective\" aria-label=\"231 objective permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.3.1 objective</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">objective, 기본값: \"reg:squerederror, 손실함수가 최소화해야하는 함수를 정의한다.</code></pre></div>\n<ul>\n<li>reg:squarederror: 손실값의 제곱으로 회귀</li>\n<li>reg:squaredlogerror: 로그 손실인 1/2[log(pred)+1 - log(label+1)] 값의 제곱으로 회귀. 모든 입력값은 -1보다 커야하는 조건이 있음.</li>\n<li>reg:logistic: 로지스틱 회귀.</li>\n<li>binary:logistic: 이진 분류를 위한 로지스틱 회귀. 확률값(0~1)을 결과로 가짐.</li>\n<li>binary:logitraw: 이진 분류를 위한 로지스틱 회귀, 로지스틱 변환 이전의 점수를 결과로 가짐.</li>\n<li>binary:hinge: 이진 분류를 위한 hinge 손실. 확률값을 만들지 않고, 0또는 1의 예측결과를 가짐.</li>\n<li>multi:softmax: 다중분류를 위한 softmax 손실. softmax를 통해 XGBoost가 다중 분류를 하고자 한다면, num_class값을 지정해야 한다.</li>\n<li>multi:softprob: 위의 softmax와 같이, ndata nclass 행렬로 변환할 수 있는 벡터를 결과로 가진다. 각 class에 속하는 데이터의 예측확률값을 포함한다.</li>\n</ul>\n<h3 id=\"232-eval_metric\" style=\"position:relative;\"><a href=\"#232-eval_metric\" aria-label=\"232 eval_metric permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.3.2 eval_metric</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">eval_metric, 목적함수에 따라 기본값이 정해짐.</code></pre></div>\n<ul>\n<li>데이터를 검증하기 위해 사용되는 지표.</li>\n<li>회귀에는 rmse, 분류에는 error, ranking에는 MAP(mean average prediction)이 기본값으로 지정된다.</li>\n<li>여러개의 검증 지표를 추가할 수 있다.</li>\n<li>파이썬 사용자는 지표들을 map이 아니라 list형태로 전달해야 한다.</li>\n<li>가장 보편적으로 사용되는 지표들이다.\n<ul>\n<li>rmse: <a href=\"https://en.wikipedia.org/wiki/Root-mean-square_deviation\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">root mean square error</a>, 제곱 평균의 루트값</li>\n<li>mae: <a href=\"https://en.wikipedia.org/wiki/Mean_absolute_error\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">mean absolute error</a>: 절댓값의 평균</li>\n<li>logloss: <a href=\"https://en.wikipedia.org/wiki/Likelihood_function#Log-likelihood\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">negative log-liklihood</a></li>\n<li>error: 이진 분류에서 오차 비율( &#x3C;= 0.5 ) #wrong cases / all cases 로 계산된다. 0.5보다 큰 인스턴스를 positive로 고려하고, 나머지를 negative instance로 고려할것이다.</li>\n<li>merror: 다중 분류에서 오차 비율이다. #wrong cases/ all cases로 계산된다.</li>\n<li>mlogloss: <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Multiclass logloss</a></li>\n<li>auc: <a href=\"https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_curve\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Area under the curve</a></li>\n<li>aucpr: <a href=\"https://en.wikipedia.org/wiki/Precision_and_recall\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Aread under the PR curve</a></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"233-seed\" style=\"position:relative;\"><a href=\"#233-seed\" aria-label=\"233 seed permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.3.3 seed</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">seed, 기본값 0.</code></pre></div>\n<ul>\n<li>난수 시드값.</li>\n<li>R 패키지에서는 무시되어 set.seed()가 대신 사용된다.</li>\n<li>재생산 가능한 결과를 만들거나 파라미터를 튜닝할때 사용된다.</li>\n</ul>","id":"fbd55a22-762c-5413-87ce-1e8a79fbb775","fields":{"slug":"데이터사이언스-링크-모음"},"frontmatter":{"date":"2021-08-22","title":"데이터사이언스 링크 모음","category":"데이터분석","tags":["데이터분석","machinelearning"],"banner":"/assets/bg/2.jpg"},"timeToRead":7}}},"staticQueryHashes":["3824141623"]}